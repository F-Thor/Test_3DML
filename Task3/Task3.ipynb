{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task3.ipynb","provenance":[],"mount_file_id":"1Qqm2WnsTEEQzeMRCugksikcUrio40u_z","authorship_tag":"ABX9TyNg9XzhSH7ak3d2GrS4jvpI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4nUXXfpBhVDk"},"source":["Описание задачи\n","Дан набор 3D примитивов. Необходимо решить задачу классификации объектов с помощью нейронной сети, представленных в форме облака точек.\n","\n","Набор данных разбит на три части: train, test, valid.\n","\n","Для этого нужно:\n","\n","Используя набор данных из категории train обучить модель классификации.\n","Оценить качество её работы на объектах из категории test. Для этого воспользоваться classification_report из scikit-learn. Провести финальную оценку на valid. Написать краткий отчёт по результатам оценки качества модели: насколько хорошо/плохо работает модель, насколько она обобщается на данные из valid набора, что можно сделать для улучшения результатов.\n","Задачу можно решать в Google Colab, если нет возможности использовать GPU."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_XVoZi_hGpt","executionInfo":{"status":"ok","timestamp":1627573914492,"user_tz":-180,"elapsed":4084,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"9ac4abbf-ce2d-4731-b577-52bb7a33aca1"},"source":["pip install pyntcloud"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyntcloud\n","  Downloading pyntcloud-0.1.4-py3-none-any.whl (346 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 92 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 153 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 174 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 184 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 215 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 225 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 235 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 245 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 256 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 266 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 276 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 286 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 296 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 307 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 317 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 327 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 337 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 346 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyntcloud) (1.1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyntcloud) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyntcloud) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyntcloud) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyntcloud) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyntcloud) (1.15.0)\n","Installing collected packages: pyntcloud\n","Successfully installed pyntcloud-0.1.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bn1iaNbBtUPV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627573917998,"user_tz":-180,"elapsed":3513,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"e761d4c9-6c62-4f21-b103-a89e23112a78"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","import os\n","import pyntcloud\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","if torch.cuda.is_available(): \n","  print('You got a GPU:', torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","You got a GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iTKNzOYU-Y4e"},"source":["# Модель реализация PointNet:"]},{"cell_type":"markdown","metadata":{"id":"AQHb2gwU_ijv"},"source":["Создаем блок T-net который кодирует наше облако точек в матрицы для Multi-Scale Grouping"]},{"cell_type":"code","metadata":{"id":"RsR6wJrBB2Xa"},"source":["class Tnet(nn.Module):\n","    def __init__(self, k=3):\n","        super().__init__()\n","        self.k=k\n","        self.conv1 = nn.Conv1d(k,64,1)\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","        self.fc1 = nn.Linear(1024,512)\n","        self.fc2 = nn.Linear(512,256)\n","        self.fc3 = nn.Linear(256,k*k)\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","        self.bn4 = nn.BatchNorm1d(512)\n","        self.bn5 = nn.BatchNorm1d(256)\n","\n","\n","    def forward(self, input):\n","        # input.shape == (bs,3,n)\n","        bs = input.size(0)\n","        xb = F.relu(self.bn1(self.conv1(input)))\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = F.relu(self.bn3(self.conv3(xb)))\n","        pool = nn.MaxPool1d(xb.size(-1))(xb)\n","        flat = nn.Flatten(1)(pool)\n","        xb = F.relu(self.bn4(self.fc1(flat)))\n","        xb = F.relu(self.bn5(self.fc2(xb)))\n","\n","        #initialize as identity\n","        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n","        if xb.is_cuda:\n","            init=init.cuda()\n","        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n","        return matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8erSIL3KamD"},"source":["Блок приобразования облака точек в матрицы для Multi-Scale Grouping "]},{"cell_type":"code","metadata":{"id":"MEt0Y7ycEC8Z"},"source":["class Transform(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.input_transform = Tnet(k=3)\n","        self.lower_feature_transform = Tnet(k=16)\n","        self.feature_transform = Tnet(k=64)\n","        \n","        self.conv1 = nn.Conv1d(3,16,1)\n","        self.conv2 = nn.Conv1d(16,64,1)\n","        self.conv3 = nn.Conv1d(64,128,1)\n","        self.conv4 = nn.Conv1d(128,1024,1)\n","\n","\n","        self.bn1 = nn.BatchNorm1d(16)\n","        self.bn2 = nn.BatchNorm1d(64)\n","        self.bn3 = nn.BatchNorm1d(128)\n","        self.bn4 = nn.BatchNorm1d(1024)\n","\n","    def forward(self, input):\n","        matrix3x3 = self.input_transform(input)\n","        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n","\n","        xb = F.relu(self.bn1(self.conv1(xb)))\n","\n","        matrix16x16 = self.lower_feature_transform(xb)\n","        xb = torch.bmm(torch.transpose(xb,1,2), matrix16x16).transpose(1,2)\n","\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","\n","        matrix64x64 = self.feature_transform(xb)\n","        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n","\n","        xb = F.relu(self.bn3(self.conv3(xb)))\n","        xb = self.bn4(self.conv4(xb))\n","        xb = nn.MaxPool1d(xb.size(-1))(xb)\n","        output = nn.Flatten(1)(xb)\n","\n","        return output, matrix3x3, matrix16x16, matrix64x64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19hBWWLUK9Q9"},"source":["Сборка модели блок Transform, внутри него T-Net. После них полносвязные слои с нормализацией по батчу и слоем Dropout для регуляризации. Из модели получаем вероятность класса через logsoftmax,  и длполнительно матрицы кодирования для оптимизации в функции потерь."]},{"cell_type":"code","metadata":{"id":"1MAox6HDECZy"},"source":["class PointNet(nn.Module):\n","    def __init__(self, classes = 6):\n","        super().__init__()\n","        self.transform = Transform()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, classes)\n","        \n","\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input):\n","        xb, matrix3x3, matrix16x16, matrix64x64 = self.transform(input)\n","        xb = F.relu(self.bn1(self.dropout(self.fc1(xb))))\n","        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n","        output = self.fc3(xb)\n","        return self.logsoftmax(output), matrix3x3, matrix16x16, matrix64x64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"By8Coy7YNaxh"},"source":["Функция потерь для pointnet, это функция NLLLoss с регуляризацией по матрицам кодирования."]},{"cell_type":"code","metadata":{"id":"ey06jlWhUEWP"},"source":["def pointnetloss(outputs, labels, m3x3, m16x16, m64x64, alpha = 0.0005):\n","    \n","    criterion = torch.nn.NLLLoss().to(device)\n","    bs=outputs.size(0)   \n","    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1).to(device)\n","    id16x16 = torch.eye(16, requires_grad=True).repeat(bs,1,1).to(device)\n","    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1).to(device)\n","    \n","    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n","    diff16x16 = id16x16-torch.bmm(m16x16,m16x16.transpose(1,2))\n","    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n","\n","    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)+torch.norm(diff16x16)) / float(bs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrAnQAwGUSaT"},"source":["Функция обучения модели, записываем историю для того что бы построить кривые обучения."]},{"cell_type":"code","metadata":{"id":"hyyjzZLmXlJ4"},"source":["def train(model, train_loader, val_loader=None,  n_epochs=1):\n","    \n","    start_time = time.time()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","    history = dict(train=[], val=[], val_acc=[])\n","\n","    for epoch in range(1, n_epochs + 1): \n","        model = model.train()\n","        train_losses = []\n","        \n","        for data in train_loader:\n","          optimizer.zero_grad()\n","          xyz, labels = data\n","          xyz = xyz.to(device)\n","          labels = labels.to(device)\n","          outputs, m3x3, m16x16, m64x64 = model(xyz)\n","          loss = pointnetloss(outputs, labels, m3x3, m16x16, m64x64)\n","          loss.backward()\n","          optimizer.step()\n","          train_losses.append(loss.item())\n","    \n","        val_losses = []\n","        val_accs = []\n","        correct = total = 0\n","        if val_loader:\n","          model = model.eval()\n","          with torch.no_grad():\n","            \n","            for data in val_loader:\n","              xyz, labels = data\n","              xyz = xyz.to(device)\n","              labels = labels.to(device)\n","              outputs, m3x3, m16x16, m64x64 = model(xyz)\n","              loss = pointnetloss(outputs, labels, m3x3, m16x16, m64x64)\n","              total += labels.size(0)\n","              _, predicted = torch.max(outputs.data, 1)\n","              correct += (predicted == labels).sum().item()\n","            val_accs.append(100. * correct / total)\n","            val_losses.append(loss.item())\n","          \n","        train_loss = np.mean(train_losses)\n","        val_loss = np.mean(val_losses)\n","        val_acc =np.mean(val_accs)\n","        history['train'].append(train_loss)\n","        history['val'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","        \n","        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss} Valid accuracy: {val_acc}', time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)))\n"," \n","    # save the model\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/pointnet.pth\")\n","    return model.eval(), history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ke4NKTLY-ukO"},"source":["# Данные создание Dataloader"]},{"cell_type":"markdown","metadata":{"id":"Z0rBiIWXWuAQ"},"source":["Создаем словарь классов, сможем его вводить в датасеты что бы не возникло путаницы при проверке."]},{"cell_type":"code","metadata":{"id":"j61KLkFcTb2p"},"source":["class_dict={}\n","lables=os.listdir(path='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/train')\n","for lable in lables:\n","  class_dict[lable]=lables.index(lable)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YWQbhu_eO1yj"},"source":["Создаем датасет из файлов obj метка класса название папки:"]},{"cell_type":"code","metadata":{"id":"gfcrqdHaaRjZ"},"source":["class PointCloudData(torch.utils.data.Dataset):\n","    def __init__(self, data_dir, class_dict, n_numb=10000):\n","        self.data_dir=data_dir\n","        self.samples = []\n","        self.lables=os.listdir(path=data_dir)\n","        self.n_numb=n_numb\n","        self.class_dict=class_dict\n","\n","        for lable in  self.lables:\n","          path_2_file=os.path.join(data_dir,lable)\n","          for file in os.listdir(path=path_2_file):\n","            self.samples.append((file,lable))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        \n","        data_path = os.path.join(self.data_dir, self.samples[idx][1],self.samples[idx][0])\n","        pc=pyntcloud.PyntCloud.from_file(data_path)       \n","        pc=pc.get_sample(\"mesh_random\", n=self.n_numb, rgb=False, normals=True, as_PyntCloud=True)\n","        xyz = pc.points[['x','y','z']].values\n","\n","       \n","        return (torch.swapdims(torch.tensor(xyz, dtype=torch.float32),0,1), self.class_dict[self.samples[idx][1]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSvtYa3zcqZp"},"source":["Определяем Train, Test и Valid DataLoader для подачи данных в модель батчами."]},{"cell_type":"code","metadata":{"id":"cqNkPDlQMq87"},"source":["trainloader = torch.utils.data.DataLoader(PointCloudData(data_dir='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/train', class_dict=class_dict), \n","                                          batch_size=16, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfeSEFAYc-PN"},"source":["testloader = torch.utils.data.DataLoader(PointCloudData(data_dir='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/test', class_dict=class_dict), \n","                                          batch_size=16, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGdjMvALdCu4"},"source":["validloader = torch.utils.data.DataLoader(PointCloudData(data_dir='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/valid', class_dict=class_dict), \n","                                          batch_size=16, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7mQj-AR-8BH"},"source":["# Обучение и оценка процесса обучения"]},{"cell_type":"code","metadata":{"id":"9Gu7A85XQajb"},"source":["point_net_model=PointNet()\n","point_net_model = point_net_model.to(device)\n","#point_net_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/pointnet.pth'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wadTW-L2dt0p","executionInfo":{"status":"ok","timestamp":1627623681828,"user_tz":-180,"elapsed":48489035,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"11817668-157d-4d65-d17a-5c262bdfb630"},"source":["point_net_model, history = train(point_net_model, trainloader, testloader, n_epochs=1500)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1: train loss 1.6512550926208496 val loss 1.777560830116272 Valid accuracy: 26.5 00:00:32\n","Epoch 2: train loss 1.4725602515538534 val loss 1.715743064880371 Valid accuracy: 27.833333333333332 00:01:04\n","Epoch 3: train loss 1.4063126293818156 val loss 1.8045216798782349 Valid accuracy: 24.333333333333332 00:01:37\n","Epoch 4: train loss 1.3672363996505736 val loss 1.758952260017395 Valid accuracy: 29.166666666666668 00:02:09\n","Epoch 5: train loss 1.3361603037516276 val loss 1.461746335029602 Valid accuracy: 27.666666666666668 00:02:41\n","Epoch 6: train loss 1.3129943402608235 val loss 1.663030743598938 Valid accuracy: 30.666666666666668 00:03:13\n","Epoch 7: train loss 1.2820537892977397 val loss 1.247894048690796 Valid accuracy: 31.166666666666668 00:03:46\n","Epoch 8: train loss 1.2535997748374939 val loss 1.472509503364563 Valid accuracy: 29.833333333333332 00:04:18\n","Epoch 9: train loss 1.2576570439338683 val loss 1.8277182579040527 Valid accuracy: 36.166666666666664 00:04:50\n","Epoch 10: train loss 1.25402144352595 val loss 1.6043932437896729 Valid accuracy: 31.833333333333332 00:05:23\n","Epoch 11: train loss 1.2243129714330037 val loss 1.7458140850067139 Valid accuracy: 38.0 00:05:55\n","Epoch 12: train loss 1.2268332743644714 val loss 1.292975902557373 Valid accuracy: 36.166666666666664 00:06:27\n","Epoch 13: train loss 1.2664587791760762 val loss 1.265584111213684 Valid accuracy: 35.166666666666664 00:06:59\n","Epoch 14: train loss 1.21564386288325 val loss 1.2907800674438477 Valid accuracy: 42.833333333333336 00:07:32\n","Epoch 15: train loss 1.1938789908091227 val loss 1.2799562215805054 Valid accuracy: 41.5 00:08:04\n","Epoch 16: train loss 1.1794230794906617 val loss 1.2772741317749023 Valid accuracy: 41.666666666666664 00:08:37\n","Epoch 17: train loss 1.229755504131317 val loss 1.3046092987060547 Valid accuracy: 40.666666666666664 00:09:09\n","Epoch 18: train loss 1.1655974682172139 val loss 1.450994849205017 Valid accuracy: 43.0 00:09:41\n","Epoch 19: train loss 1.1573422622680665 val loss 1.6813478469848633 Valid accuracy: 43.0 00:10:13\n","Epoch 20: train loss 1.1590808240572612 val loss 1.5327117443084717 Valid accuracy: 43.333333333333336 00:10:46\n","Epoch 21: train loss 1.1548842175801595 val loss 1.321016788482666 Valid accuracy: 38.5 00:11:18\n","Epoch 22: train loss 1.1463496661186219 val loss 1.1109870672225952 Valid accuracy: 41.666666666666664 00:11:50\n","Epoch 23: train loss 1.1276815191904703 val loss 1.6277540922164917 Valid accuracy: 42.5 00:12:23\n","Epoch 24: train loss 1.1268558708826701 val loss 1.185010552406311 Valid accuracy: 43.333333333333336 00:12:55\n","Epoch 25: train loss 1.139818099339803 val loss 1.3382869958877563 Valid accuracy: 43.0 00:13:27\n","Epoch 26: train loss 1.1215945585568745 val loss 1.2739241123199463 Valid accuracy: 43.666666666666664 00:14:00\n","Epoch 27: train loss 1.1440818786621094 val loss 1.5272929668426514 Valid accuracy: 44.833333333333336 00:14:32\n","Epoch 28: train loss 1.0824058961868286 val loss 1.7425564527511597 Valid accuracy: 45.5 00:15:04\n","Epoch 29: train loss 1.1238352704048156 val loss 1.4210667610168457 Valid accuracy: 44.0 00:15:36\n","Epoch 30: train loss 1.0849971143404642 val loss 1.5250927209854126 Valid accuracy: 43.5 00:16:09\n","Epoch 31: train loss 1.1036635700861612 val loss 1.6937494277954102 Valid accuracy: 47.333333333333336 00:16:42\n","Epoch 32: train loss 1.0903529930114746 val loss 1.734395146369934 Valid accuracy: 42.5 00:17:14\n","Epoch 33: train loss 1.1134624528884887 val loss 1.4542882442474365 Valid accuracy: 44.666666666666664 00:17:46\n","Epoch 34: train loss 1.0948317623138428 val loss 1.1921656131744385 Valid accuracy: 44.666666666666664 00:18:18\n","Epoch 35: train loss 1.102990387280782 val loss 1.1093443632125854 Valid accuracy: 43.166666666666664 00:18:51\n","Epoch 36: train loss 1.0665153257052105 val loss 1.2702767848968506 Valid accuracy: 45.0 00:19:23\n","Epoch 37: train loss 1.0643060890833538 val loss 1.533326268196106 Valid accuracy: 44.5 00:19:55\n","Epoch 38: train loss 1.0677819848060608 val loss 1.1717379093170166 Valid accuracy: 44.666666666666664 00:20:27\n","Epoch 39: train loss 1.053521835009257 val loss 1.5593109130859375 Valid accuracy: 46.333333333333336 00:20:59\n","Epoch 40: train loss 1.076482757727305 val loss 0.9766809344291687 Valid accuracy: 44.166666666666664 00:21:32\n","Epoch 41: train loss 1.04244300365448 val loss 1.3838603496551514 Valid accuracy: 44.666666666666664 00:22:04\n","Epoch 42: train loss 1.041954304377238 val loss 1.386075496673584 Valid accuracy: 44.166666666666664 00:22:36\n","Epoch 43: train loss 1.0336394627888998 val loss 1.0883378982543945 Valid accuracy: 43.666666666666664 00:23:08\n","Epoch 44: train loss 1.073138723373413 val loss 1.8076293468475342 Valid accuracy: 46.0 00:23:40\n","Epoch 45: train loss 1.0509221665064494 val loss 1.3327115774154663 Valid accuracy: 43.833333333333336 00:24:12\n","Epoch 46: train loss 1.0702031580607096 val loss 1.338431715965271 Valid accuracy: 41.333333333333336 00:24:44\n","Epoch 47: train loss 1.028297020594279 val loss 1.0774985551834106 Valid accuracy: 47.166666666666664 00:25:16\n","Epoch 48: train loss 1.029695560137431 val loss 1.2995039224624634 Valid accuracy: 45.666666666666664 00:25:48\n","Epoch 49: train loss 1.0580829699834189 val loss 1.422902226448059 Valid accuracy: 40.0 00:26:20\n","Epoch 50: train loss 1.028411602973938 val loss 1.283213496208191 Valid accuracy: 46.333333333333336 00:26:52\n","Epoch 51: train loss 1.0167067710558573 val loss 1.4995522499084473 Valid accuracy: 44.666666666666664 00:27:24\n","Epoch 52: train loss 0.9827468721071879 val loss 1.4137614965438843 Valid accuracy: 47.5 00:27:56\n","Epoch 53: train loss 1.0049195647239686 val loss 1.3423352241516113 Valid accuracy: 44.333333333333336 00:28:28\n","Epoch 54: train loss 1.0356818207105 val loss 1.154927372932434 Valid accuracy: 45.333333333333336 00:28:59\n","Epoch 55: train loss 1.019634075164795 val loss 1.721646785736084 Valid accuracy: 44.5 00:29:31\n","Epoch 56: train loss 1.000145080089569 val loss 1.628214716911316 Valid accuracy: 43.5 00:30:03\n","Epoch 57: train loss 0.9890486192703247 val loss 1.6349047422409058 Valid accuracy: 43.666666666666664 00:30:36\n","Epoch 58: train loss 1.0121122845013937 val loss 1.3377718925476074 Valid accuracy: 46.833333333333336 00:31:08\n","Epoch 59: train loss 1.0143527364730835 val loss 1.1135077476501465 Valid accuracy: 46.0 00:31:39\n","Epoch 60: train loss 1.029350442091624 val loss 1.538851261138916 Valid accuracy: 46.833333333333336 00:32:12\n","Epoch 61: train loss 0.9744976329803466 val loss 1.6118972301483154 Valid accuracy: 47.666666666666664 00:32:44\n","Epoch 62: train loss 1.0095167779922485 val loss 1.40287184715271 Valid accuracy: 47.0 00:33:16\n","Epoch 63: train loss 0.9474247813224792 val loss 1.1480456590652466 Valid accuracy: 47.0 00:33:48\n","Epoch 64: train loss 0.9852146212259928 val loss 1.2443232536315918 Valid accuracy: 43.0 00:34:20\n","Epoch 65: train loss 0.9916628249486288 val loss 1.2322561740875244 Valid accuracy: 46.666666666666664 00:34:52\n","Epoch 66: train loss 0.9761162304878235 val loss 1.1423009634017944 Valid accuracy: 46.0 00:35:24\n","Epoch 67: train loss 0.9935943754514058 val loss 1.6876614093780518 Valid accuracy: 45.333333333333336 00:35:56\n","Epoch 68: train loss 0.9684397371610006 val loss 1.1468331813812256 Valid accuracy: 46.166666666666664 00:36:27\n","Epoch 69: train loss 0.9856592559814453 val loss 1.7607821226119995 Valid accuracy: 46.833333333333336 00:36:59\n","Epoch 70: train loss 0.9822044754028321 val loss 1.7919305562973022 Valid accuracy: 46.333333333333336 00:37:31\n","Epoch 71: train loss 0.9557323590914408 val loss 1.6273232698440552 Valid accuracy: 48.0 00:38:03\n","Epoch 72: train loss 0.9216449002424876 val loss 1.448626160621643 Valid accuracy: 46.5 00:38:36\n","Epoch 73: train loss 0.9248639766375224 val loss 2.1578361988067627 Valid accuracy: 48.333333333333336 00:39:07\n","Epoch 74: train loss 0.9113591519991556 val loss 2.0302748680114746 Valid accuracy: 45.0 00:39:40\n","Epoch 75: train loss 0.9344254978497823 val loss 1.212433934211731 Valid accuracy: 47.333333333333336 00:40:11\n","Epoch 76: train loss 0.9532234915097555 val loss 1.0456749200820923 Valid accuracy: 46.666666666666664 00:40:43\n","Epoch 77: train loss 0.9399696564674378 val loss 1.601546049118042 Valid accuracy: 45.333333333333336 00:41:15\n","Epoch 78: train loss 0.9256355277697246 val loss 1.3656742572784424 Valid accuracy: 48.666666666666664 00:41:47\n","Epoch 79: train loss 0.9280014677842459 val loss 1.2120366096496582 Valid accuracy: 48.166666666666664 00:42:19\n","Epoch 80: train loss 0.9393734661738078 val loss 1.5829871892929077 Valid accuracy: 46.333333333333336 00:42:51\n","Epoch 81: train loss 0.9177386371294657 val loss 1.1844056844711304 Valid accuracy: 46.333333333333336 00:43:23\n","Epoch 82: train loss 0.9250260210037231 val loss 1.3398054838180542 Valid accuracy: 48.5 00:43:55\n","Epoch 83: train loss 0.8893910817305247 val loss 1.6166642904281616 Valid accuracy: 47.333333333333336 00:44:27\n","Epoch 84: train loss 0.9108266409238179 val loss 1.3137974739074707 Valid accuracy: 46.0 00:44:59\n","Epoch 85: train loss 0.9201991391181946 val loss 1.473722219467163 Valid accuracy: 49.0 00:45:31\n","Epoch 86: train loss 0.9473465259869893 val loss 1.5099400281906128 Valid accuracy: 43.666666666666664 00:46:03\n","Epoch 87: train loss 0.8965650574366252 val loss 1.7201308012008667 Valid accuracy: 45.333333333333336 00:46:35\n","Epoch 88: train loss 0.9344918203353881 val loss 1.1321635246276855 Valid accuracy: 48.166666666666664 00:47:07\n","Epoch 89: train loss 0.9101255905628204 val loss 1.2119648456573486 Valid accuracy: 48.166666666666664 00:47:39\n","Epoch 90: train loss 0.9491313314437866 val loss 0.8595127463340759 Valid accuracy: 45.333333333333336 00:48:11\n","Epoch 91: train loss 0.8856610524654388 val loss 1.6988717317581177 Valid accuracy: 47.833333333333336 00:48:43\n","Epoch 92: train loss 0.8905675435066223 val loss 0.8786423802375793 Valid accuracy: 49.0 00:49:15\n","Epoch 93: train loss 0.8840718817710876 val loss 1.7525169849395752 Valid accuracy: 48.833333333333336 00:49:47\n","Epoch 94: train loss 0.9146144374211629 val loss 1.2336249351501465 Valid accuracy: 48.333333333333336 00:50:19\n","Epoch 95: train loss 0.8688436826070149 val loss 1.1358070373535156 Valid accuracy: 48.666666666666664 00:50:51\n","Epoch 96: train loss 0.8901622502009073 val loss 1.1508870124816895 Valid accuracy: 46.666666666666664 00:51:23\n","Epoch 97: train loss 0.8594838416576386 val loss 1.05295991897583 Valid accuracy: 49.833333333333336 00:51:55\n","Epoch 98: train loss 0.8628246223926545 val loss 1.767451524734497 Valid accuracy: 47.0 00:52:27\n","Epoch 99: train loss 0.8599907636642456 val loss 1.1777573823928833 Valid accuracy: 48.166666666666664 00:52:59\n","Epoch 100: train loss 0.8566350773970286 val loss 1.656675100326538 Valid accuracy: 47.666666666666664 00:53:31\n","Epoch 101: train loss 0.8436095643043519 val loss 1.3209675550460815 Valid accuracy: 49.0 00:54:03\n","Epoch 102: train loss 0.9186817995707194 val loss 1.094575047492981 Valid accuracy: 48.166666666666664 00:54:35\n","Epoch 103: train loss 0.8594630893071492 val loss 1.2110238075256348 Valid accuracy: 46.833333333333336 00:55:06\n","Epoch 104: train loss 0.8866978295644125 val loss 1.1988742351531982 Valid accuracy: 48.666666666666664 00:55:39\n","Epoch 105: train loss 0.8516207408905029 val loss 0.9006677865982056 Valid accuracy: 48.833333333333336 00:56:10\n","Epoch 106: train loss 0.8569822533925374 val loss 1.600327730178833 Valid accuracy: 47.666666666666664 00:56:43\n","Epoch 107: train loss 0.8529429252942403 val loss 1.2804911136627197 Valid accuracy: 49.333333333333336 00:57:14\n","Epoch 108: train loss 0.8420220589637757 val loss 0.8273037672042847 Valid accuracy: 50.333333333333336 00:57:46\n","Epoch 109: train loss 0.8314703516165416 val loss 1.2958598136901855 Valid accuracy: 50.166666666666664 00:58:18\n","Epoch 110: train loss 0.8328840716679891 val loss 1.0285710096359253 Valid accuracy: 50.833333333333336 00:58:50\n","Epoch 111: train loss 0.8729945317904154 val loss 1.3616036176681519 Valid accuracy: 52.166666666666664 00:59:23\n","Epoch 112: train loss 0.7739334225654602 val loss 0.7304994463920593 Valid accuracy: 53.5 00:59:54\n","Epoch 113: train loss 0.8044102640946706 val loss 1.0798646211624146 Valid accuracy: 51.333333333333336 01:00:26\n","Epoch 114: train loss 0.8596961220105489 val loss 1.7597534656524658 Valid accuracy: 46.666666666666664 01:00:58\n","Epoch 115: train loss 0.8579575276374817 val loss 1.10763418674469 Valid accuracy: 49.666666666666664 01:01:30\n","Epoch 116: train loss 0.8248243856430054 val loss 1.0780963897705078 Valid accuracy: 49.166666666666664 01:02:02\n","Epoch 117: train loss 0.7706763740380606 val loss 0.9449310898780823 Valid accuracy: 47.333333333333336 01:02:34\n","Epoch 118: train loss 0.8006597383817037 val loss 1.173142910003662 Valid accuracy: 51.0 01:03:06\n","Epoch 119: train loss 0.7918922885258992 val loss 0.9371772408485413 Valid accuracy: 52.833333333333336 01:03:38\n","Epoch 120: train loss 0.7637240497271219 val loss 1.5049073696136475 Valid accuracy: 52.833333333333336 01:04:10\n","Epoch 121: train loss 0.7899745519955953 val loss 1.4705145359039307 Valid accuracy: 49.5 01:04:42\n","Epoch 122: train loss 0.7899387685457865 val loss 0.6176212430000305 Valid accuracy: 48.166666666666664 01:05:15\n","Epoch 123: train loss 0.7832952896753947 val loss 0.9936994314193726 Valid accuracy: 50.5 01:05:47\n","Epoch 124: train loss 0.8198010822137197 val loss 1.769141435623169 Valid accuracy: 52.666666666666664 01:06:19\n","Epoch 125: train loss 0.8219101246198018 val loss 1.659157156944275 Valid accuracy: 48.666666666666664 01:06:50\n","Epoch 126: train loss 0.7637070508797964 val loss 0.8493679761886597 Valid accuracy: 55.166666666666664 01:07:22\n","Epoch 127: train loss 0.7739165159066518 val loss 0.982915997505188 Valid accuracy: 52.666666666666664 01:07:54\n","Epoch 128: train loss 0.7789256246884664 val loss 0.963995635509491 Valid accuracy: 51.333333333333336 01:08:26\n","Epoch 129: train loss 0.7691750220457713 val loss 1.044450044631958 Valid accuracy: 51.833333333333336 01:08:58\n","Epoch 130: train loss 0.7996303331851959 val loss 1.280132532119751 Valid accuracy: 51.5 01:09:30\n","Epoch 131: train loss 0.7454047846794128 val loss 0.9935228824615479 Valid accuracy: 51.166666666666664 01:10:02\n","Epoch 132: train loss 0.7424586109320322 val loss 1.079936146736145 Valid accuracy: 53.666666666666664 01:10:34\n","Epoch 133: train loss 0.7224010809262593 val loss 1.4023265838623047 Valid accuracy: 55.166666666666664 01:11:05\n","Epoch 134: train loss 0.7445152223110199 val loss 1.3658440113067627 Valid accuracy: 57.5 01:11:38\n","Epoch 135: train loss 0.7400194708506266 val loss 1.8113199472427368 Valid accuracy: 52.833333333333336 01:12:09\n","Epoch 136: train loss 0.7705859657128652 val loss 0.7232136130332947 Valid accuracy: 55.833333333333336 01:12:42\n","Epoch 137: train loss 0.7276150369644165 val loss 1.0424225330352783 Valid accuracy: 53.0 01:13:13\n","Epoch 138: train loss 0.726706120967865 val loss 1.2931464910507202 Valid accuracy: 52.833333333333336 01:13:45\n","Epoch 139: train loss 0.7205035654703776 val loss 0.9424393177032471 Valid accuracy: 56.0 01:14:17\n","Epoch 140: train loss 0.7903658099969229 val loss 1.660306692123413 Valid accuracy: 54.0 01:14:49\n","Epoch 141: train loss 0.722288517554601 val loss 1.3357913494110107 Valid accuracy: 53.166666666666664 01:15:20\n","Epoch 142: train loss 0.7334166475137075 val loss 1.0145363807678223 Valid accuracy: 54.333333333333336 01:15:53\n","Epoch 143: train loss 0.7244566365083058 val loss 0.7875714898109436 Valid accuracy: 57.166666666666664 01:16:25\n","Epoch 144: train loss 0.7181677718957266 val loss 0.7598962187767029 Valid accuracy: 54.833333333333336 01:16:57\n","Epoch 145: train loss 0.7239824370543162 val loss 1.1738051176071167 Valid accuracy: 54.166666666666664 01:17:29\n","Epoch 146: train loss 0.6640468259652456 val loss 1.1318209171295166 Valid accuracy: 54.166666666666664 01:18:00\n","Epoch 147: train loss 0.7090291265646617 val loss 1.1901708841323853 Valid accuracy: 55.0 01:18:32\n","Epoch 148: train loss 0.7392814421653747 val loss 0.8271089792251587 Valid accuracy: 52.666666666666664 01:19:04\n","Epoch 149: train loss 0.7049096298217773 val loss 1.324878454208374 Valid accuracy: 54.166666666666664 01:19:36\n","Epoch 150: train loss 0.6827528846263885 val loss 0.94268399477005 Valid accuracy: 57.666666666666664 01:20:08\n","Epoch 151: train loss 0.7385728661219279 val loss 1.553898572921753 Valid accuracy: 54.833333333333336 01:20:40\n","Epoch 152: train loss 0.7374500445524852 val loss 0.9516063928604126 Valid accuracy: 54.166666666666664 01:21:12\n","Epoch 153: train loss 0.6623912501335144 val loss 0.9026412963867188 Valid accuracy: 58.5 01:21:44\n","Epoch 154: train loss 0.6833736741542816 val loss 1.0405988693237305 Valid accuracy: 54.0 01:22:16\n","Epoch 155: train loss 0.6608181897799174 val loss 1.0464155673980713 Valid accuracy: 53.0 01:22:48\n","Epoch 156: train loss 0.697857092221578 val loss 1.1526613235473633 Valid accuracy: 55.666666666666664 01:23:20\n","Epoch 157: train loss 0.6777407344182332 val loss 0.7141952514648438 Valid accuracy: 59.166666666666664 01:23:52\n","Epoch 158: train loss 0.6513080108165741 val loss 1.0917736291885376 Valid accuracy: 56.0 01:24:24\n","Epoch 159: train loss 0.6599278628826142 val loss 0.8989605903625488 Valid accuracy: 59.0 01:24:56\n","Epoch 160: train loss 0.646102812687556 val loss 1.0270791053771973 Valid accuracy: 56.166666666666664 01:25:27\n","Epoch 161: train loss 0.6570195146401723 val loss 0.9852450489997864 Valid accuracy: 59.166666666666664 01:25:59\n","Epoch 162: train loss 0.6584759294986725 val loss 1.7474452257156372 Valid accuracy: 56.666666666666664 01:26:31\n","Epoch 163: train loss 0.6515231331189474 val loss 1.5161495208740234 Valid accuracy: 57.333333333333336 01:27:03\n","Epoch 164: train loss 0.6467592557271321 val loss 1.0129622220993042 Valid accuracy: 53.833333333333336 01:27:35\n","Epoch 165: train loss 0.6624678842226664 val loss 0.8573222756385803 Valid accuracy: 57.0 01:28:07\n","Epoch 166: train loss 0.6460337380568186 val loss 1.3847525119781494 Valid accuracy: 55.5 01:28:38\n","Epoch 167: train loss 0.6490538082520168 val loss 1.2079603672027588 Valid accuracy: 54.166666666666664 01:29:10\n","Epoch 168: train loss 0.6274585429827372 val loss 1.184294581413269 Valid accuracy: 59.0 01:29:42\n","Epoch 169: train loss 0.6822388426462809 val loss 0.9962278604507446 Valid accuracy: 62.833333333333336 01:30:14\n","Epoch 170: train loss 0.6365354835987092 val loss 0.5947603583335876 Valid accuracy: 59.666666666666664 01:30:46\n","Epoch 171: train loss 0.6369989399115245 val loss 0.9567850232124329 Valid accuracy: 59.0 01:31:18\n","Epoch 172: train loss 0.6085742342472077 val loss 0.5915693044662476 Valid accuracy: 61.833333333333336 01:31:50\n","Epoch 173: train loss 0.5719084278742472 val loss 1.7537469863891602 Valid accuracy: 59.333333333333336 01:32:22\n","Epoch 174: train loss 0.6061385397116343 val loss 0.7250242233276367 Valid accuracy: 55.333333333333336 01:32:54\n","Epoch 175: train loss 0.6408033525943756 val loss 1.2751270532608032 Valid accuracy: 57.166666666666664 01:33:26\n","Epoch 176: train loss 0.6060140522321066 val loss 0.8718751072883606 Valid accuracy: 58.0 01:33:58\n","Epoch 177: train loss 0.5708072261015574 val loss 1.3454817533493042 Valid accuracy: 60.5 01:34:30\n","Epoch 178: train loss 0.6711014032363891 val loss 0.6556264758110046 Valid accuracy: 58.666666666666664 01:35:02\n","Epoch 179: train loss 0.6162479710578919 val loss 0.855459988117218 Valid accuracy: 59.333333333333336 01:35:34\n","Epoch 180: train loss 0.6288065342108409 val loss 1.9187980890274048 Valid accuracy: 56.666666666666664 01:36:06\n","Epoch 181: train loss 0.5933018243312835 val loss 0.7182992696762085 Valid accuracy: 62.166666666666664 01:36:38\n","Epoch 182: train loss 0.6052723677953085 val loss 1.1926109790802002 Valid accuracy: 57.666666666666664 01:37:11\n","Epoch 183: train loss 0.5771729336182276 val loss 0.7342765927314758 Valid accuracy: 64.0 01:37:42\n","Epoch 184: train loss 0.5531640082597733 val loss 0.7388521432876587 Valid accuracy: 61.833333333333336 01:38:14\n","Epoch 185: train loss 0.5615509382883708 val loss 1.1632684469223022 Valid accuracy: 60.166666666666664 01:38:46\n","Epoch 186: train loss 0.5441304953893026 val loss 1.1993560791015625 Valid accuracy: 62.166666666666664 01:39:18\n","Epoch 187: train loss 0.5625311748186748 val loss 1.0386985540390015 Valid accuracy: 57.833333333333336 01:39:50\n","Epoch 188: train loss 0.532178810040156 val loss 1.2688324451446533 Valid accuracy: 63.166666666666664 01:40:22\n","Epoch 189: train loss 0.534459460179011 val loss 0.7890397310256958 Valid accuracy: 59.166666666666664 01:40:54\n","Epoch 190: train loss 0.5323050093650817 val loss 1.1379923820495605 Valid accuracy: 57.333333333333336 01:41:26\n","Epoch 191: train loss 0.553094965616862 val loss 0.9733360409736633 Valid accuracy: 61.333333333333336 01:41:57\n","Epoch 192: train loss 0.5365780095259348 val loss 1.548541784286499 Valid accuracy: 59.5 01:42:29\n","Epoch 193: train loss 0.5289705850680669 val loss 1.0261296033859253 Valid accuracy: 62.5 01:43:01\n","Epoch 194: train loss 0.5246688600381215 val loss 0.9112051725387573 Valid accuracy: 63.166666666666664 01:43:34\n","Epoch 195: train loss 0.5076314336061478 val loss 1.0665767192840576 Valid accuracy: 62.666666666666664 01:44:06\n","Epoch 196: train loss 0.5567520195245743 val loss 1.008564829826355 Valid accuracy: 61.166666666666664 01:44:39\n","Epoch 197: train loss 0.631383891304334 val loss 0.7656568288803101 Valid accuracy: 62.166666666666664 01:45:10\n","Epoch 198: train loss 0.5864138499895731 val loss 0.9706536531448364 Valid accuracy: 64.16666666666667 01:45:42\n","Epoch 199: train loss 0.5415043487151464 val loss 1.1353957653045654 Valid accuracy: 61.666666666666664 01:46:14\n","Epoch 200: train loss 0.5823940940697988 val loss 1.0271347761154175 Valid accuracy: 60.833333333333336 01:46:47\n","Epoch 201: train loss 0.528886867761612 val loss 0.9895737767219543 Valid accuracy: 63.833333333333336 01:47:18\n","Epoch 202: train loss 0.47580034017562867 val loss 0.5835118889808655 Valid accuracy: 67.5 01:47:51\n","Epoch 203: train loss 0.5430391236146291 val loss 0.8836205005645752 Valid accuracy: 63.5 01:48:23\n","Epoch 204: train loss 0.5391509515047074 val loss 1.1876988410949707 Valid accuracy: 62.5 01:48:55\n","Epoch 205: train loss 0.5273061400651932 val loss 0.9130536317825317 Valid accuracy: 66.16666666666667 01:49:27\n","Epoch 206: train loss 0.5213379242022832 val loss 0.8688943386077881 Valid accuracy: 64.5 01:49:58\n","Epoch 207: train loss 0.5131545313199362 val loss 0.795823335647583 Valid accuracy: 63.5 01:50:31\n","Epoch 208: train loss 0.5015969492991765 val loss 1.3328907489776611 Valid accuracy: 62.833333333333336 01:51:02\n","Epoch 209: train loss 0.516347425977389 val loss 1.251408338546753 Valid accuracy: 66.0 01:51:34\n","Epoch 210: train loss 0.509672457575798 val loss 0.781409502029419 Valid accuracy: 68.33333333333333 01:52:06\n","Epoch 211: train loss 0.5115515452623367 val loss 1.0629533529281616 Valid accuracy: 64.33333333333333 01:52:38\n","Epoch 212: train loss 0.5223019882043203 val loss 0.850322425365448 Valid accuracy: 63.333333333333336 01:53:10\n","Epoch 213: train loss 0.48248294949531556 val loss 0.9493705630302429 Valid accuracy: 67.16666666666667 01:53:42\n","Epoch 214: train loss 0.47403724869092306 val loss 0.8351725339889526 Valid accuracy: 66.16666666666667 01:54:15\n","Epoch 215: train loss 0.4335875638326009 val loss 1.0619300603866577 Valid accuracy: 60.666666666666664 01:54:47\n","Epoch 216: train loss 0.5075697521368663 val loss 1.2310423851013184 Valid accuracy: 68.66666666666667 01:55:19\n","Epoch 217: train loss 0.4878076293071111 val loss 0.679049551486969 Valid accuracy: 66.33333333333333 01:55:52\n","Epoch 218: train loss 0.5507282267014185 val loss 0.9279969930648804 Valid accuracy: 67.0 01:56:24\n","Epoch 219: train loss 0.5584642698367437 val loss 0.8706766963005066 Valid accuracy: 60.833333333333336 01:56:57\n","Epoch 220: train loss 0.49820222159226735 val loss 1.2006971836090088 Valid accuracy: 66.66666666666667 01:57:30\n","Epoch 221: train loss 0.44585433522860207 val loss 1.0457019805908203 Valid accuracy: 67.5 01:58:02\n","Epoch 222: train loss 0.4894214524825414 val loss 1.0136077404022217 Valid accuracy: 63.666666666666664 01:58:34\n","Epoch 223: train loss 0.4884548270702362 val loss 0.71592777967453 Valid accuracy: 68.66666666666667 01:59:06\n","Epoch 224: train loss 0.4677389721075694 val loss 0.9762450456619263 Valid accuracy: 67.33333333333333 01:59:38\n","Epoch 225: train loss 0.4733004860083262 val loss 1.2317084074020386 Valid accuracy: 65.16666666666667 02:00:10\n","Epoch 226: train loss 0.5132716471950213 val loss 1.0164891481399536 Valid accuracy: 64.16666666666667 02:00:42\n","Epoch 227: train loss 0.4347361717621485 val loss 1.001149296760559 Valid accuracy: 66.33333333333333 02:01:14\n","Epoch 228: train loss 0.4323161067565282 val loss 1.176405668258667 Valid accuracy: 69.5 02:01:46\n","Epoch 229: train loss 0.4392173232634862 val loss 1.3684581518173218 Valid accuracy: 67.83333333333333 02:02:18\n","Epoch 230: train loss 0.4874016400178274 val loss 0.6900352835655212 Valid accuracy: 67.0 02:02:50\n","Epoch 231: train loss 0.43228312969207766 val loss 0.5591480135917664 Valid accuracy: 68.83333333333333 02:03:22\n","Epoch 232: train loss 0.4211013813813527 val loss 1.323093056678772 Valid accuracy: 65.5 02:03:54\n","Epoch 233: train loss 0.44886732935905455 val loss 0.7694252133369446 Valid accuracy: 61.5 02:04:27\n","Epoch 234: train loss 0.4373434748252233 val loss 0.7689376473426819 Valid accuracy: 66.66666666666667 02:04:58\n","Epoch 235: train loss 0.4902796186010043 val loss 0.8736050128936768 Valid accuracy: 66.33333333333333 02:05:30\n","Epoch 236: train loss 0.4840949281056722 val loss 0.6648064255714417 Valid accuracy: 67.0 02:06:02\n","Epoch 237: train loss 0.4294326098759969 val loss 0.7228407263755798 Valid accuracy: 68.16666666666667 02:06:34\n","Epoch 238: train loss 0.42841140230496727 val loss 1.0059529542922974 Valid accuracy: 70.33333333333333 02:07:06\n","Epoch 239: train loss 0.4201230428616206 val loss 0.9825820326805115 Valid accuracy: 67.0 02:07:38\n","Epoch 240: train loss 0.3999653043349584 val loss 0.781795859336853 Valid accuracy: 67.33333333333333 02:08:09\n","Epoch 241: train loss 0.4376765437920888 val loss 0.9391087293624878 Valid accuracy: 68.33333333333333 02:08:42\n","Epoch 242: train loss 0.48553584595521293 val loss 0.9734768271446228 Valid accuracy: 71.16666666666667 02:09:14\n","Epoch 243: train loss 0.4601460119088491 val loss 0.9410078525543213 Valid accuracy: 66.33333333333333 02:09:46\n","Epoch 244: train loss 0.44216292510430016 val loss 0.5508054494857788 Valid accuracy: 67.66666666666667 02:10:18\n","Epoch 245: train loss 0.45024994273980457 val loss 0.9744356274604797 Valid accuracy: 69.0 02:10:50\n","Epoch 246: train loss 0.4663299224774043 val loss 0.9949325323104858 Valid accuracy: 69.16666666666667 02:11:22\n","Epoch 247: train loss 0.4008329745133718 val loss 0.7801950573921204 Valid accuracy: 71.66666666666667 02:11:54\n","Epoch 248: train loss 0.44948651214440666 val loss 1.011663556098938 Valid accuracy: 67.16666666666667 02:12:26\n","Epoch 249: train loss 0.42484776536623636 val loss 0.6607937812805176 Valid accuracy: 70.83333333333333 02:12:58\n","Epoch 250: train loss 0.44380046645800275 val loss 1.0794533491134644 Valid accuracy: 65.16666666666667 02:13:30\n","Epoch 251: train loss 0.43398881912231446 val loss 1.0582103729248047 Valid accuracy: 72.16666666666667 02:14:02\n","Epoch 252: train loss 0.3602678006887436 val loss 0.9262908697128296 Valid accuracy: 69.66666666666667 02:14:34\n","Epoch 253: train loss 0.40799236168464026 val loss 0.5867512822151184 Valid accuracy: 71.83333333333333 02:15:06\n","Epoch 254: train loss 0.4129937074581782 val loss 0.7649120688438416 Valid accuracy: 68.5 02:15:38\n","Epoch 255: train loss 0.365333451628685 val loss 0.8917911648750305 Valid accuracy: 70.33333333333333 02:16:10\n","Epoch 256: train loss 0.41809869875510536 val loss 0.7250953912734985 Valid accuracy: 68.16666666666667 02:16:42\n","Epoch 257: train loss 0.41869450608889264 val loss 0.8066158294677734 Valid accuracy: 68.66666666666667 02:17:14\n","Epoch 258: train loss 0.3959444731473923 val loss 0.4219546616077423 Valid accuracy: 67.33333333333333 02:17:46\n","Epoch 259: train loss 0.38180561701456706 val loss 0.39624524116516113 Valid accuracy: 71.66666666666667 02:18:18\n","Epoch 260: train loss 0.46366884718338647 val loss 0.967766284942627 Valid accuracy: 72.16666666666667 02:18:50\n","Epoch 261: train loss 0.4197308333714803 val loss 0.9189448356628418 Valid accuracy: 69.33333333333333 02:19:21\n","Epoch 262: train loss 0.4132405784726143 val loss 0.77764493227005 Valid accuracy: 69.83333333333333 02:19:54\n","Epoch 263: train loss 0.41049729883670805 val loss 0.7515222430229187 Valid accuracy: 68.66666666666667 02:20:25\n","Epoch 264: train loss 0.4137087634205818 val loss 0.687666118144989 Valid accuracy: 71.16666666666667 02:20:58\n","Epoch 265: train loss 0.4229642673333486 val loss 1.1084589958190918 Valid accuracy: 70.33333333333333 02:21:30\n","Epoch 266: train loss 0.3904226312041283 val loss 0.7747049927711487 Valid accuracy: 71.0 02:22:02\n","Epoch 267: train loss 0.41810060342152916 val loss 0.9691253304481506 Valid accuracy: 70.0 02:22:34\n","Epoch 268: train loss 0.38330662856499353 val loss 0.9579794406890869 Valid accuracy: 70.0 02:23:06\n","Epoch 269: train loss 0.40875272363424303 val loss 0.7213531136512756 Valid accuracy: 72.0 02:23:38\n","Epoch 270: train loss 0.39651438921689985 val loss 0.398529589176178 Valid accuracy: 71.83333333333333 02:24:10\n","Epoch 271: train loss 0.3565775508681933 val loss 1.0201334953308105 Valid accuracy: 71.83333333333333 02:24:42\n","Epoch 272: train loss 0.36363847663005194 val loss 1.0263075828552246 Valid accuracy: 70.16666666666667 02:25:13\n","Epoch 273: train loss 0.4041138700644175 val loss 0.7591376900672913 Valid accuracy: 68.33333333333333 02:25:46\n","Epoch 274: train loss 0.355767339070638 val loss 0.7067769765853882 Valid accuracy: 70.5 02:26:18\n","Epoch 275: train loss 0.39952487240235013 val loss 0.9058203101158142 Valid accuracy: 73.66666666666667 02:26:50\n","Epoch 276: train loss 0.3438376134634018 val loss 0.6407626867294312 Valid accuracy: 67.16666666666667 02:27:22\n","Epoch 277: train loss 0.3915424394607544 val loss 0.7148638367652893 Valid accuracy: 75.0 02:27:54\n","Epoch 278: train loss 0.35912987659374873 val loss 0.7667486071586609 Valid accuracy: 75.33333333333333 02:28:26\n","Epoch 279: train loss 0.35515430798133213 val loss 0.5627541542053223 Valid accuracy: 72.5 02:28:58\n","Epoch 280: train loss 0.3776069390773773 val loss 1.1058040857315063 Valid accuracy: 71.5 02:29:30\n","Epoch 281: train loss 0.3363185891509056 val loss 1.0734583139419556 Valid accuracy: 71.0 02:30:02\n","Epoch 282: train loss 0.35079046100378036 val loss 0.8631935715675354 Valid accuracy: 69.5 02:30:34\n","Epoch 283: train loss 0.3630227715770404 val loss 0.7749431133270264 Valid accuracy: 72.83333333333333 02:31:06\n","Epoch 284: train loss 0.38046606053908666 val loss 1.4434154033660889 Valid accuracy: 70.83333333333333 02:31:38\n","Epoch 285: train loss 0.390214023689429 val loss 1.128706693649292 Valid accuracy: 62.833333333333336 02:32:11\n","Epoch 286: train loss 0.37858442644278206 val loss 0.8266187906265259 Valid accuracy: 72.83333333333333 02:32:43\n","Epoch 287: train loss 0.3571257702509562 val loss 0.6957712173461914 Valid accuracy: 72.66666666666667 02:33:15\n","Epoch 288: train loss 0.34411159038543704 val loss 0.9165821075439453 Valid accuracy: 72.83333333333333 02:33:47\n","Epoch 289: train loss 0.37188137431939444 val loss 1.0711790323257446 Valid accuracy: 67.5 02:34:19\n","Epoch 290: train loss 0.3492306410272916 val loss 0.6391768455505371 Valid accuracy: 71.5 02:34:52\n","Epoch 291: train loss 0.29293523748715716 val loss 0.8382874727249146 Valid accuracy: 75.16666666666667 02:35:25\n","Epoch 292: train loss 0.3656602435310682 val loss 1.176027774810791 Valid accuracy: 73.5 02:35:58\n","Epoch 293: train loss 0.3691824903090795 val loss 0.9910958409309387 Valid accuracy: 73.33333333333333 02:36:29\n","Epoch 294: train loss 0.3650473353266716 val loss 1.602089762687683 Valid accuracy: 72.16666666666667 02:37:02\n","Epoch 295: train loss 0.2818058897058169 val loss 0.6867194771766663 Valid accuracy: 73.33333333333333 02:37:34\n","Epoch 296: train loss 0.3211153917511304 val loss 0.923672616481781 Valid accuracy: 71.5 02:38:05\n","Epoch 297: train loss 0.36776252299547196 val loss 0.8980391621589661 Valid accuracy: 72.0 02:38:38\n","Epoch 298: train loss 0.3324947774410248 val loss 0.8498903512954712 Valid accuracy: 72.33333333333333 02:39:09\n","Epoch 299: train loss 0.3825349641839663 val loss 0.6574913859367371 Valid accuracy: 72.83333333333333 02:39:42\n","Epoch 300: train loss 0.3496768588821093 val loss 0.899074375629425 Valid accuracy: 72.0 02:40:13\n","Epoch 301: train loss 0.3645573118329048 val loss 0.8090052008628845 Valid accuracy: 74.83333333333333 02:40:46\n","Epoch 302: train loss 0.31265895267327626 val loss 0.9743708372116089 Valid accuracy: 73.0 02:41:17\n","Epoch 303: train loss 0.3424762790401777 val loss 0.5200636386871338 Valid accuracy: 71.83333333333333 02:41:50\n","Epoch 304: train loss 0.35935957103967664 val loss 0.6143349409103394 Valid accuracy: 71.33333333333333 02:42:22\n","Epoch 305: train loss 0.36049122412999474 val loss 1.1582475900650024 Valid accuracy: 75.16666666666667 02:42:54\n","Epoch 306: train loss 0.33898321181535723 val loss 0.8951182961463928 Valid accuracy: 72.33333333333333 02:43:27\n","Epoch 307: train loss 0.3398686502377192 val loss 1.2240537405014038 Valid accuracy: 73.16666666666667 02:43:59\n","Epoch 308: train loss 0.3133339569965998 val loss 0.9565311074256897 Valid accuracy: 75.66666666666667 02:44:32\n","Epoch 309: train loss 0.3216458841164907 val loss 0.7566832304000854 Valid accuracy: 70.5 02:45:04\n","Epoch 310: train loss 0.28764803349971774 val loss 0.5512399673461914 Valid accuracy: 72.83333333333333 02:45:37\n","Epoch 311: train loss 0.3021543430785338 val loss 1.219822645187378 Valid accuracy: 71.5 02:46:10\n","Epoch 312: train loss 0.31238389790058135 val loss 0.933205783367157 Valid accuracy: 76.0 02:46:42\n","Epoch 313: train loss 0.3300315910577774 val loss 0.8074032664299011 Valid accuracy: 72.33333333333333 02:47:14\n","Epoch 314: train loss 0.31212978531916935 val loss 0.6613097190856934 Valid accuracy: 73.0 02:47:46\n","Epoch 315: train loss 0.3107267939050992 val loss 0.8177490234375 Valid accuracy: 76.16666666666667 02:48:19\n","Epoch 316: train loss 0.31746463119983676 val loss 1.0025453567504883 Valid accuracy: 74.33333333333333 02:48:51\n","Epoch 317: train loss 0.3162677787741025 val loss 0.8038969039916992 Valid accuracy: 75.5 02:49:23\n","Epoch 318: train loss 0.2934786987304687 val loss 0.7282012104988098 Valid accuracy: 76.5 02:49:55\n","Epoch 319: train loss 0.32677200372020404 val loss 0.8384495377540588 Valid accuracy: 74.5 02:50:28\n","Epoch 320: train loss 0.3253382392724355 val loss 0.815385639667511 Valid accuracy: 74.5 02:51:00\n","Epoch 321: train loss 0.3041280260682106 val loss 0.6976335644721985 Valid accuracy: 75.5 02:51:32\n","Epoch 322: train loss 0.30251459578673046 val loss 0.9762765765190125 Valid accuracy: 73.83333333333333 02:52:04\n","Epoch 323: train loss 0.2837526187300682 val loss 0.6279434561729431 Valid accuracy: 76.83333333333333 02:52:36\n","Epoch 324: train loss 0.33409737517436344 val loss 0.9074005484580994 Valid accuracy: 76.5 02:53:09\n","Epoch 325: train loss 0.32280158032973605 val loss 0.7449465394020081 Valid accuracy: 75.0 02:53:41\n","Epoch 326: train loss 0.33205576956272126 val loss 0.4842042028903961 Valid accuracy: 73.5 02:54:13\n","Epoch 327: train loss 0.3067683761318525 val loss 0.6206201314926147 Valid accuracy: 72.16666666666667 02:54:46\n","Epoch 328: train loss 0.29192403584718707 val loss 1.0063503980636597 Valid accuracy: 72.0 02:55:18\n","Epoch 329: train loss 0.3059155678749084 val loss 1.0248252153396606 Valid accuracy: 78.66666666666667 02:55:50\n","Epoch 330: train loss 0.2649639175832272 val loss 0.8115772008895874 Valid accuracy: 74.0 02:56:22\n","Epoch 331: train loss 0.26873923232158026 val loss 0.7486347556114197 Valid accuracy: 77.5 02:56:54\n","Epoch 332: train loss 0.3078772057592869 val loss 0.5421361923217773 Valid accuracy: 76.83333333333333 02:57:26\n","Epoch 333: train loss 0.32081625297665595 val loss 0.5709196925163269 Valid accuracy: 75.33333333333333 02:57:59\n","Epoch 334: train loss 0.2987221196293831 val loss 0.6956754922866821 Valid accuracy: 77.16666666666667 02:58:31\n","Epoch 335: train loss 0.32717680469155314 val loss 0.6176690459251404 Valid accuracy: 77.5 02:59:03\n","Epoch 336: train loss 0.29343848407268525 val loss 0.7347099781036377 Valid accuracy: 76.5 02:59:36\n","Epoch 337: train loss 0.28372298230727516 val loss 0.5638685822486877 Valid accuracy: 75.83333333333333 03:00:08\n","Epoch 338: train loss 0.3129426636795203 val loss 0.8935627341270447 Valid accuracy: 73.66666666666667 03:00:41\n","Epoch 339: train loss 0.2938835845390956 val loss 1.1170276403427124 Valid accuracy: 73.66666666666667 03:01:13\n","Epoch 340: train loss 0.3538435925046603 val loss 0.5577354431152344 Valid accuracy: 75.16666666666667 03:01:46\n","Epoch 341: train loss 0.27432236075401306 val loss 0.8559058308601379 Valid accuracy: 76.16666666666667 03:02:17\n","Epoch 342: train loss 0.22941430469353993 val loss 1.0252902507781982 Valid accuracy: 78.83333333333333 03:02:50\n","Epoch 343: train loss 0.30732772320508955 val loss 0.8452678918838501 Valid accuracy: 76.5 03:03:22\n","Epoch 344: train loss 0.28914292886853216 val loss 0.6476259231567383 Valid accuracy: 76.66666666666667 03:03:55\n","Epoch 345: train loss 0.30091734846433005 val loss 0.6605647802352905 Valid accuracy: 79.0 03:04:27\n","Epoch 346: train loss 0.2993281195561091 val loss 0.9037618637084961 Valid accuracy: 72.33333333333333 03:04:59\n","Epoch 347: train loss 0.2860619855920474 val loss 0.3858594596385956 Valid accuracy: 74.83333333333333 03:05:31\n","Epoch 348: train loss 0.2687230535348256 val loss 0.5972478985786438 Valid accuracy: 75.83333333333333 03:06:03\n","Epoch 349: train loss 0.2522354307770729 val loss 0.8401414155960083 Valid accuracy: 74.5 03:06:36\n","Epoch 350: train loss 0.2792199302216371 val loss 0.5568957328796387 Valid accuracy: 78.5 03:07:07\n","Epoch 351: train loss 0.28713246747851373 val loss 0.8190363645553589 Valid accuracy: 77.16666666666667 03:07:39\n","Epoch 352: train loss 0.26229196657737097 val loss 0.5538878440856934 Valid accuracy: 76.16666666666667 03:08:11\n","Epoch 353: train loss 0.2874405183891455 val loss 0.3862074017524719 Valid accuracy: 75.66666666666667 03:08:44\n","Epoch 354: train loss 0.33689087748527524 val loss 0.6694204807281494 Valid accuracy: 77.33333333333333 03:09:15\n","Epoch 355: train loss 0.28231319506963093 val loss 0.9867870211601257 Valid accuracy: 79.16666666666667 03:09:48\n","Epoch 356: train loss 0.2646990282336871 val loss 0.898827850818634 Valid accuracy: 72.33333333333333 03:10:20\n","Epoch 357: train loss 0.23762473955750466 val loss 0.684864342212677 Valid accuracy: 76.83333333333333 03:10:52\n","Epoch 358: train loss 0.2688138508796692 val loss 1.1585793495178223 Valid accuracy: 75.83333333333333 03:11:24\n","Epoch 359: train loss 0.2685258181889852 val loss 0.6032393574714661 Valid accuracy: 77.33333333333333 03:11:56\n","Epoch 360: train loss 0.23560439179340997 val loss 0.6997619271278381 Valid accuracy: 75.83333333333333 03:12:29\n","Epoch 361: train loss 0.2926785646378994 val loss 0.9426679015159607 Valid accuracy: 77.5 03:13:01\n","Epoch 362: train loss 0.21725180074572564 val loss 1.0054683685302734 Valid accuracy: 79.33333333333333 03:13:33\n","Epoch 363: train loss 0.2488462423781554 val loss 0.8725301027297974 Valid accuracy: 77.5 03:14:05\n","Epoch 364: train loss 0.3001800004641215 val loss 0.7234604954719543 Valid accuracy: 77.5 03:14:37\n","Epoch 365: train loss 0.25091314564148587 val loss 0.764135479927063 Valid accuracy: 77.0 03:15:10\n","Epoch 366: train loss 0.28210298051436744 val loss 0.9596810936927795 Valid accuracy: 76.33333333333333 03:15:42\n","Epoch 367: train loss 0.22908991674582163 val loss 0.9005190134048462 Valid accuracy: 74.83333333333333 03:16:14\n","Epoch 368: train loss 0.25279620920618373 val loss 0.41305017471313477 Valid accuracy: 77.5 03:16:46\n","Epoch 369: train loss 0.27144495248794553 val loss 0.8041914105415344 Valid accuracy: 79.33333333333333 03:17:18\n","Epoch 370: train loss 0.24399406249324482 val loss 1.075868010520935 Valid accuracy: 76.0 03:17:50\n","Epoch 371: train loss 0.2620867023865382 val loss 0.6596526503562927 Valid accuracy: 76.66666666666667 03:18:22\n","Epoch 372: train loss 0.2739177307486534 val loss 0.706919252872467 Valid accuracy: 77.66666666666667 03:18:54\n","Epoch 373: train loss 0.25039986113707224 val loss 1.0519438982009888 Valid accuracy: 76.33333333333333 03:19:26\n","Epoch 374: train loss 0.24447806442777315 val loss 0.8562406897544861 Valid accuracy: 79.33333333333333 03:19:58\n","Epoch 375: train loss 0.2750849224130313 val loss 0.9172042608261108 Valid accuracy: 81.0 03:20:29\n","Epoch 376: train loss 0.2750839426616828 val loss 0.7866824269294739 Valid accuracy: 78.66666666666667 03:21:02\n","Epoch 377: train loss 0.19846851428349813 val loss 0.6325311064720154 Valid accuracy: 71.5 03:21:34\n","Epoch 378: train loss 0.249389408826828 val loss 0.7160288691520691 Valid accuracy: 79.33333333333333 03:22:05\n","Epoch 379: train loss 0.2701593933006128 val loss 0.8197441697120667 Valid accuracy: 77.16666666666667 03:22:38\n","Epoch 380: train loss 0.24960464477539063 val loss 0.9443778395652771 Valid accuracy: 77.0 03:23:10\n","Epoch 381: train loss 0.2477404320240021 val loss 0.5856484770774841 Valid accuracy: 78.83333333333333 03:23:42\n","Epoch 382: train loss 0.23169011722008387 val loss 0.5516937375068665 Valid accuracy: 78.83333333333333 03:24:14\n","Epoch 383: train loss 0.22081254969040554 val loss 0.832588791847229 Valid accuracy: 77.33333333333333 03:24:46\n","Epoch 384: train loss 0.2267722198863824 val loss 1.080968976020813 Valid accuracy: 81.0 03:25:18\n","Epoch 385: train loss 0.25518891677260397 val loss 0.7646189332008362 Valid accuracy: 80.0 03:25:50\n","Epoch 386: train loss 0.25530790080626803 val loss 0.9636725187301636 Valid accuracy: 80.5 03:26:22\n","Epoch 387: train loss 0.2595932831863562 val loss 0.8871129155158997 Valid accuracy: 80.0 03:26:54\n","Epoch 388: train loss 0.21672453314065934 val loss 0.6644766330718994 Valid accuracy: 78.33333333333333 03:27:27\n","Epoch 389: train loss 0.19818035393953323 val loss 1.1424555778503418 Valid accuracy: 79.0 03:27:58\n","Epoch 390: train loss 0.24220726763208708 val loss 0.4745887219905853 Valid accuracy: 77.0 03:28:31\n","Epoch 391: train loss 0.21911030838886897 val loss 0.3691115379333496 Valid accuracy: 77.66666666666667 03:29:02\n","Epoch 392: train loss 0.2742647447188695 val loss 0.5313192009925842 Valid accuracy: 77.16666666666667 03:29:35\n","Epoch 393: train loss 0.22441434601942697 val loss 0.8013907074928284 Valid accuracy: 83.0 03:30:07\n","Epoch 394: train loss 0.19277391175429026 val loss 1.0518558025360107 Valid accuracy: 79.16666666666667 03:30:39\n","Epoch 395: train loss 0.20402862454454104 val loss 0.7104510068893433 Valid accuracy: 79.0 03:31:11\n","Epoch 396: train loss 0.23207952628533046 val loss 0.6521962285041809 Valid accuracy: 80.5 03:31:43\n","Epoch 397: train loss 0.23339184587200482 val loss 0.947736918926239 Valid accuracy: 82.16666666666667 03:32:15\n","Epoch 398: train loss 0.21821951215465862 val loss 0.46963512897491455 Valid accuracy: 79.0 03:32:47\n","Epoch 399: train loss 0.18871814623475075 val loss 0.3841155469417572 Valid accuracy: 80.16666666666667 03:33:19\n","Epoch 400: train loss 0.2657582112153371 val loss 0.4724213480949402 Valid accuracy: 78.0 03:33:51\n","Epoch 401: train loss 0.2584818423787753 val loss 1.0355072021484375 Valid accuracy: 79.83333333333333 03:34:23\n","Epoch 402: train loss 0.22652545377612113 val loss 0.6985903978347778 Valid accuracy: 78.83333333333333 03:34:56\n","Epoch 403: train loss 0.2174111004670461 val loss 0.6765168905258179 Valid accuracy: 80.5 03:35:27\n","Epoch 404: train loss 0.22859819506605467 val loss 0.40091386437416077 Valid accuracy: 79.5 03:36:00\n","Epoch 405: train loss 0.3034949027498563 val loss 0.6068721413612366 Valid accuracy: 78.33333333333333 03:36:32\n","Epoch 406: train loss 0.23222976197799047 val loss 0.6430561542510986 Valid accuracy: 81.83333333333333 03:37:04\n","Epoch 407: train loss 0.20996186728278796 val loss 0.9642642140388489 Valid accuracy: 81.66666666666667 03:37:37\n","Epoch 408: train loss 0.17415584747989973 val loss 0.6183920502662659 Valid accuracy: 80.83333333333333 03:38:08\n","Epoch 409: train loss 0.20422642747561137 val loss 0.8113628625869751 Valid accuracy: 80.83333333333333 03:38:40\n","Epoch 410: train loss 0.23812126939495404 val loss 0.7515640258789062 Valid accuracy: 78.83333333333333 03:39:12\n","Epoch 411: train loss 0.2201118309299151 val loss 0.7742459774017334 Valid accuracy: 78.33333333333333 03:39:44\n","Epoch 412: train loss 0.18704784661531448 val loss 1.0680766105651855 Valid accuracy: 79.0 03:40:16\n","Epoch 413: train loss 0.22242366393407187 val loss 0.8065325617790222 Valid accuracy: 82.33333333333333 03:40:49\n","Epoch 414: train loss 0.2519296333193779 val loss 0.6976363062858582 Valid accuracy: 79.66666666666667 03:41:21\n","Epoch 415: train loss 0.23779463415344557 val loss 0.6739457845687866 Valid accuracy: 83.5 03:41:53\n","Epoch 416: train loss 0.1589822227259477 val loss 1.2365293502807617 Valid accuracy: 83.16666666666667 03:42:26\n","Epoch 417: train loss 0.20269802048802377 val loss 0.710243821144104 Valid accuracy: 83.66666666666667 03:42:57\n","Epoch 418: train loss 0.18528828874230385 val loss 0.5458346009254456 Valid accuracy: 83.83333333333333 03:43:30\n","Epoch 419: train loss 0.20608460947871207 val loss 0.9327706098556519 Valid accuracy: 85.33333333333333 03:44:02\n","Epoch 420: train loss 0.20966484447320302 val loss 0.9302803874015808 Valid accuracy: 79.33333333333333 03:44:34\n","Epoch 421: train loss 0.22767909323175747 val loss 0.8333185911178589 Valid accuracy: 81.33333333333333 03:45:06\n","Epoch 422: train loss 0.22776391267776488 val loss 0.45447513461112976 Valid accuracy: 81.33333333333333 03:45:38\n","Epoch 423: train loss 0.2373919758697351 val loss 0.653968870639801 Valid accuracy: 82.0 03:46:10\n","Epoch 424: train loss 0.2534483593205611 val loss 0.900044858455658 Valid accuracy: 82.0 03:46:44\n","Epoch 425: train loss 0.22870727802316348 val loss 0.5606419444084167 Valid accuracy: 83.83333333333333 03:47:16\n","Epoch 426: train loss 0.19592013090848923 val loss 1.002825140953064 Valid accuracy: 84.5 03:47:48\n","Epoch 427: train loss 0.16474266176422436 val loss 0.355739563703537 Valid accuracy: 83.5 03:48:21\n","Epoch 428: train loss 0.2035076344013214 val loss 0.30845898389816284 Valid accuracy: 82.83333333333333 03:48:53\n","Epoch 429: train loss 0.23520328263441723 val loss 0.4832307994365692 Valid accuracy: 80.5 03:49:26\n","Epoch 430: train loss 0.2220152907570203 val loss 0.6677649617195129 Valid accuracy: 81.16666666666667 03:49:58\n","Epoch 431: train loss 0.1761751994987329 val loss 0.4222859740257263 Valid accuracy: 82.33333333333333 03:50:30\n","Epoch 432: train loss 0.22939135511716208 val loss 0.8062201738357544 Valid accuracy: 86.16666666666667 03:51:03\n","Epoch 433: train loss 0.2359189545114835 val loss 0.4586676061153412 Valid accuracy: 82.83333333333333 03:51:35\n","Epoch 434: train loss 0.214501729508241 val loss 0.7026323080062866 Valid accuracy: 81.5 03:52:08\n","Epoch 435: train loss 0.23291790530085563 val loss 0.44358915090560913 Valid accuracy: 84.33333333333333 03:52:40\n","Epoch 436: train loss 0.2003277647991975 val loss 0.35266685485839844 Valid accuracy: 81.5 03:53:14\n","Epoch 437: train loss 0.15201800917585692 val loss 1.0367860794067383 Valid accuracy: 83.33333333333333 03:53:46\n","Epoch 438: train loss 0.176336596707503 val loss 0.6267922520637512 Valid accuracy: 80.5 03:54:19\n","Epoch 439: train loss 0.1627110394090414 val loss 1.0103614330291748 Valid accuracy: 82.83333333333333 03:54:52\n","Epoch 440: train loss 0.21624293719728788 val loss 0.6587791442871094 Valid accuracy: 81.33333333333333 03:55:25\n","Epoch 441: train loss 0.2208887256681919 val loss 0.6940388679504395 Valid accuracy: 82.66666666666667 03:55:58\n","Epoch 442: train loss 0.20847300623854 val loss 0.44042935967445374 Valid accuracy: 85.16666666666667 03:56:31\n","Epoch 443: train loss 0.16458211302757264 val loss 0.8119961023330688 Valid accuracy: 83.66666666666667 03:57:03\n","Epoch 444: train loss 0.2151146393020948 val loss 0.5255289673805237 Valid accuracy: 81.83333333333333 03:57:35\n","Epoch 445: train loss 0.18505861500898996 val loss 0.45786237716674805 Valid accuracy: 83.83333333333333 03:58:08\n","Epoch 446: train loss 0.18445267394185066 val loss 0.7053973078727722 Valid accuracy: 85.33333333333333 03:58:41\n","Epoch 447: train loss 0.2146508450061083 val loss 0.5677754878997803 Valid accuracy: 83.5 03:59:13\n","Epoch 448: train loss 0.15259940112630527 val loss 0.8289860486984253 Valid accuracy: 84.5 03:59:46\n","Epoch 449: train loss 0.17474342733621598 val loss 0.7871975302696228 Valid accuracy: 80.33333333333333 04:00:18\n","Epoch 450: train loss 0.17505207667748132 val loss 0.5759168267250061 Valid accuracy: 84.33333333333333 04:00:50\n","Epoch 451: train loss 0.20515135765075684 val loss 1.3960249423980713 Valid accuracy: 80.66666666666667 04:01:22\n","Epoch 452: train loss 0.1649191364645958 val loss 0.9275310039520264 Valid accuracy: 82.5 04:01:55\n","Epoch 453: train loss 0.17570329849918684 val loss 0.7011165618896484 Valid accuracy: 85.0 04:02:27\n","Epoch 454: train loss 0.17082404951254526 val loss 0.8308886289596558 Valid accuracy: 81.33333333333333 04:02:59\n","Epoch 455: train loss 0.23458689669768015 val loss 0.38425034284591675 Valid accuracy: 86.16666666666667 04:03:31\n","Epoch 456: train loss 0.22701797371109328 val loss 0.6714738011360168 Valid accuracy: 86.16666666666667 04:04:03\n","Epoch 457: train loss 0.1760936099787553 val loss 0.5934711694717407 Valid accuracy: 85.33333333333333 04:04:35\n","Epoch 458: train loss 0.19892668828368187 val loss 0.6091364622116089 Valid accuracy: 82.83333333333333 04:05:07\n","Epoch 459: train loss 0.17978684132297834 val loss 0.5973995923995972 Valid accuracy: 83.83333333333333 04:05:40\n","Epoch 460: train loss 0.16093167116244633 val loss 0.6100268363952637 Valid accuracy: 84.66666666666667 04:06:12\n","Epoch 461: train loss 0.2233655540148417 val loss 0.6355360746383667 Valid accuracy: 82.16666666666667 04:06:44\n","Epoch 462: train loss 0.1997106643517812 val loss 0.7848001718521118 Valid accuracy: 86.33333333333333 04:07:16\n","Epoch 463: train loss 0.1406025829911232 val loss 0.5366182327270508 Valid accuracy: 86.0 04:07:49\n","Epoch 464: train loss 0.13600961585839588 val loss 0.7890398502349854 Valid accuracy: 83.0 04:08:20\n","Epoch 465: train loss 0.14737249697248142 val loss 0.5673414468765259 Valid accuracy: 83.83333333333333 04:08:53\n","Epoch 466: train loss 0.15516366943717003 val loss 0.7824370861053467 Valid accuracy: 81.83333333333333 04:09:25\n","Epoch 467: train loss 0.1834186397989591 val loss 0.7691459059715271 Valid accuracy: 81.83333333333333 04:09:57\n","Epoch 468: train loss 0.20386009881893793 val loss 0.6196231842041016 Valid accuracy: 81.5 04:10:30\n","Epoch 469: train loss 0.17134559522072473 val loss 0.8184395432472229 Valid accuracy: 82.5 04:11:02\n","Epoch 470: train loss 0.17102875550587973 val loss 0.5801551938056946 Valid accuracy: 82.83333333333333 04:11:34\n","Epoch 471: train loss 0.1623676375548045 val loss 0.999671459197998 Valid accuracy: 85.16666666666667 04:12:06\n","Epoch 472: train loss 0.1880391138792038 val loss 0.6594099402427673 Valid accuracy: 80.66666666666667 04:12:39\n","Epoch 473: train loss 0.160405678798755 val loss 0.742432713508606 Valid accuracy: 83.5 04:13:10\n","Epoch 474: train loss 0.16056462188561757 val loss 0.5893021821975708 Valid accuracy: 84.83333333333333 04:13:43\n","Epoch 475: train loss 0.1900305616358916 val loss 0.5480574369430542 Valid accuracy: 82.0 04:14:15\n","Epoch 476: train loss 0.17730917858580747 val loss 0.7155482769012451 Valid accuracy: 81.66666666666667 04:14:47\n","Epoch 477: train loss 0.15304846381147702 val loss 0.5244786143302917 Valid accuracy: 83.5 04:15:20\n","Epoch 478: train loss 0.16781261667609215 val loss 0.7498635649681091 Valid accuracy: 82.5 04:15:52\n","Epoch 479: train loss 0.19100929712255796 val loss 1.0027709007263184 Valid accuracy: 81.33333333333333 04:16:24\n","Epoch 480: train loss 0.17211919412016868 val loss 0.48975709080696106 Valid accuracy: 80.16666666666667 04:16:57\n","Epoch 481: train loss 0.16521018157402675 val loss 0.5395183563232422 Valid accuracy: 81.5 04:17:29\n","Epoch 482: train loss 0.17709514933327833 val loss 0.859302818775177 Valid accuracy: 84.66666666666667 04:18:01\n","Epoch 483: train loss 0.20024866635600727 val loss 0.44926151633262634 Valid accuracy: 83.5 04:18:33\n","Epoch 484: train loss 0.17301297664642334 val loss 0.7006798386573792 Valid accuracy: 83.0 04:19:06\n","Epoch 485: train loss 0.15715387706955275 val loss 1.0556795597076416 Valid accuracy: 80.16666666666667 04:19:38\n","Epoch 486: train loss 0.16881729319691657 val loss 0.8896701335906982 Valid accuracy: 84.16666666666667 04:20:11\n","Epoch 487: train loss 0.1392455796400706 val loss 0.7940164804458618 Valid accuracy: 84.33333333333333 04:20:43\n","Epoch 488: train loss 0.17520860724151135 val loss 0.5513067841529846 Valid accuracy: 84.33333333333333 04:21:16\n","Epoch 489: train loss 0.1451846225063006 val loss 0.28426307439804077 Valid accuracy: 83.83333333333333 04:21:47\n","Epoch 490: train loss 0.15239331588149072 val loss 0.7171149849891663 Valid accuracy: 82.83333333333333 04:22:20\n","Epoch 491: train loss 0.24028293440739315 val loss 0.7890654802322388 Valid accuracy: 80.16666666666667 04:22:52\n","Epoch 492: train loss 0.16893071894844372 val loss 0.5942818522453308 Valid accuracy: 83.16666666666667 04:23:24\n","Epoch 493: train loss 0.17017955688138803 val loss 0.4969152808189392 Valid accuracy: 82.5 04:23:57\n","Epoch 494: train loss 0.16800899542868136 val loss 0.6181557178497314 Valid accuracy: 78.83333333333333 04:24:29\n","Epoch 495: train loss 0.2122738990187645 val loss 0.30114421248435974 Valid accuracy: 83.16666666666667 04:25:01\n","Epoch 496: train loss 0.14996265664696692 val loss 0.5980380773544312 Valid accuracy: 80.5 04:25:33\n","Epoch 497: train loss 0.17088985373576482 val loss 1.0111188888549805 Valid accuracy: 81.83333333333333 04:26:06\n","Epoch 498: train loss 0.14725294637183348 val loss 0.6108837127685547 Valid accuracy: 83.0 04:26:38\n","Epoch 499: train loss 0.14025454163551332 val loss 0.49620550870895386 Valid accuracy: 84.5 04:27:10\n","Epoch 500: train loss 0.14151321281989415 val loss 0.7997979521751404 Valid accuracy: 82.5 04:27:43\n","Epoch 501: train loss 0.14827411249279976 val loss 0.37885114550590515 Valid accuracy: 81.83333333333333 04:28:14\n","Epoch 502: train loss 0.14996643548210462 val loss 0.44603869318962097 Valid accuracy: 82.66666666666667 04:28:47\n","Epoch 503: train loss 0.1370223680883646 val loss 0.7726561427116394 Valid accuracy: 85.66666666666667 04:29:19\n","Epoch 504: train loss 0.13544723552962143 val loss 0.6700846552848816 Valid accuracy: 84.33333333333333 04:29:51\n","Epoch 505: train loss 0.15711028431852658 val loss 0.964589536190033 Valid accuracy: 83.16666666666667 04:30:23\n","Epoch 506: train loss 0.1583855353295803 val loss 0.6590794324874878 Valid accuracy: 81.66666666666667 04:30:56\n","Epoch 507: train loss 0.1909339775145054 val loss 0.9270661473274231 Valid accuracy: 82.66666666666667 04:31:28\n","Epoch 508: train loss 0.16613171180089314 val loss 0.6475541591644287 Valid accuracy: 83.66666666666667 04:32:00\n","Epoch 509: train loss 0.16117922392984232 val loss 0.6070476174354553 Valid accuracy: 82.16666666666667 04:32:33\n","Epoch 510: train loss 0.19286287193497023 val loss 0.7020729184150696 Valid accuracy: 82.5 04:33:04\n","Epoch 511: train loss 0.13149168878793716 val loss 0.823727011680603 Valid accuracy: 80.66666666666667 04:33:37\n","Epoch 512: train loss 0.12321059075494607 val loss 0.6200238466262817 Valid accuracy: 84.33333333333333 04:34:09\n","Epoch 513: train loss 0.14069803930819036 val loss 0.5214549899101257 Valid accuracy: 83.16666666666667 04:34:41\n","Epoch 514: train loss 0.15683401077985765 val loss 0.8854563236236572 Valid accuracy: 83.16666666666667 04:35:13\n","Epoch 515: train loss 0.15801580722133318 val loss 0.7159015536308289 Valid accuracy: 80.83333333333333 04:35:46\n","Epoch 516: train loss 0.1331969029456377 val loss 0.8724243640899658 Valid accuracy: 80.66666666666667 04:36:18\n","Epoch 517: train loss 0.16912517411013445 val loss 0.677126944065094 Valid accuracy: 86.0 04:36:51\n","Epoch 518: train loss 0.15905463919043542 val loss 0.20811660587787628 Valid accuracy: 79.66666666666667 04:37:24\n","Epoch 519: train loss 0.196178176527222 val loss 0.5514398813247681 Valid accuracy: 80.16666666666667 04:37:56\n","Epoch 520: train loss 0.15383463710546494 val loss 0.8916049599647522 Valid accuracy: 85.33333333333333 04:38:28\n","Epoch 521: train loss 0.21043040057023366 val loss 0.7091060280799866 Valid accuracy: 84.83333333333333 04:39:00\n","Epoch 522: train loss 0.13695106245577335 val loss 0.838983952999115 Valid accuracy: 84.66666666666667 04:39:32\n","Epoch 523: train loss 0.16766150186459222 val loss 0.6003068685531616 Valid accuracy: 83.66666666666667 04:40:04\n","Epoch 524: train loss 0.14897135637700556 val loss 0.7139114737510681 Valid accuracy: 84.33333333333333 04:40:37\n","Epoch 525: train loss 0.10419489155213038 val loss 0.6111545562744141 Valid accuracy: 84.0 04:41:09\n","Epoch 526: train loss 0.1368075868487358 val loss 0.7260505557060242 Valid accuracy: 86.66666666666667 04:41:41\n","Epoch 527: train loss 0.12427366882562638 val loss 0.8565914630889893 Valid accuracy: 82.33333333333333 04:42:14\n","Epoch 528: train loss 0.1565669306119283 val loss 0.6924455761909485 Valid accuracy: 85.66666666666667 04:42:46\n","Epoch 529: train loss 0.14820791048308213 val loss 0.4371144473552704 Valid accuracy: 83.5 04:43:18\n","Epoch 530: train loss 0.1276427996903658 val loss 0.34497663378715515 Valid accuracy: 83.0 04:43:51\n","Epoch 531: train loss 0.10995803793271383 val loss 0.16670739650726318 Valid accuracy: 87.5 04:44:23\n","Epoch 532: train loss 0.13040038225551445 val loss 0.4963153302669525 Valid accuracy: 85.16666666666667 04:44:56\n","Epoch 533: train loss 0.16772097220023474 val loss 0.6022586226463318 Valid accuracy: 82.33333333333333 04:45:28\n","Epoch 534: train loss 0.1662717461089293 val loss 0.8096359968185425 Valid accuracy: 82.5 04:46:01\n","Epoch 535: train loss 0.20273396854599318 val loss 0.49966004490852356 Valid accuracy: 84.0 04:46:33\n","Epoch 536: train loss 0.17838459923863412 val loss 0.41559943556785583 Valid accuracy: 83.0 04:47:06\n","Epoch 537: train loss 0.15020022816956044 val loss 0.6966148614883423 Valid accuracy: 86.16666666666667 04:47:38\n","Epoch 538: train loss 0.1403841229279836 val loss 0.4379451870918274 Valid accuracy: 85.5 04:48:10\n","Epoch 539: train loss 0.13994780811170737 val loss 0.6085104942321777 Valid accuracy: 83.16666666666667 04:48:43\n","Epoch 540: train loss 0.1729988654702902 val loss 0.8354771137237549 Valid accuracy: 82.0 04:49:15\n","Epoch 541: train loss 0.12751673710842928 val loss 0.8471871018409729 Valid accuracy: 83.16666666666667 04:49:48\n","Epoch 542: train loss 0.127766872048378 val loss 0.6467590928077698 Valid accuracy: 85.5 04:50:20\n","Epoch 543: train loss 0.12817723567287126 val loss 0.8167667984962463 Valid accuracy: 86.16666666666667 04:50:52\n","Epoch 544: train loss 0.12222656960288683 val loss 0.4720914959907532 Valid accuracy: 82.33333333333333 04:51:24\n","Epoch 545: train loss 0.15077464977900187 val loss 0.5701099038124084 Valid accuracy: 85.16666666666667 04:51:57\n","Epoch 546: train loss 0.16405679886539778 val loss 0.7981492877006531 Valid accuracy: 84.16666666666667 04:52:29\n","Epoch 547: train loss 0.18968643362323442 val loss 0.6998865604400635 Valid accuracy: 79.83333333333333 04:53:01\n","Epoch 548: train loss 0.1122957011560599 val loss 0.6943389773368835 Valid accuracy: 87.83333333333333 04:53:34\n","Epoch 549: train loss 0.16736672746638456 val loss 0.767947793006897 Valid accuracy: 82.83333333333333 04:54:06\n","Epoch 550: train loss 0.14906910613179206 val loss 0.5264679193496704 Valid accuracy: 87.16666666666667 04:54:39\n","Epoch 551: train loss 0.13731284645696482 val loss 0.5880690813064575 Valid accuracy: 87.33333333333333 04:55:11\n","Epoch 552: train loss 0.15917702816426754 val loss 0.4604625403881073 Valid accuracy: 85.0 04:55:43\n","Epoch 553: train loss 0.15666133855779965 val loss 0.8630557060241699 Valid accuracy: 85.16666666666667 04:56:15\n","Epoch 554: train loss 0.1804211600869894 val loss 0.6060011386871338 Valid accuracy: 86.16666666666667 04:56:48\n","Epoch 555: train loss 0.1436880993594726 val loss 0.4745514988899231 Valid accuracy: 85.5 04:57:20\n","Epoch 556: train loss 0.11741454983750979 val loss 0.4691764712333679 Valid accuracy: 86.0 04:57:53\n","Epoch 557: train loss 0.12563929657141368 val loss 0.6432009339332581 Valid accuracy: 87.5 04:58:25\n","Epoch 558: train loss 0.11178704082965851 val loss 0.3363018333911896 Valid accuracy: 89.0 04:58:57\n","Epoch 559: train loss 0.08152319530646006 val loss 0.48482587933540344 Valid accuracy: 87.5 04:59:30\n","Epoch 560: train loss 0.12186743756135304 val loss 0.6521560549736023 Valid accuracy: 88.0 05:00:02\n","Epoch 561: train loss 0.14776756251851716 val loss 0.8794534206390381 Valid accuracy: 84.83333333333333 05:00:34\n","Epoch 562: train loss 0.16749688404301802 val loss 0.250230073928833 Valid accuracy: 82.83333333333333 05:01:06\n","Epoch 563: train loss 0.19271205549438794 val loss 0.4314613342285156 Valid accuracy: 86.83333333333333 05:01:39\n","Epoch 564: train loss 0.14555946876605352 val loss 0.7142423987388611 Valid accuracy: 86.0 05:02:11\n","Epoch 565: train loss 0.1389007346580426 val loss 0.91153484582901 Valid accuracy: 83.66666666666667 05:02:44\n","Epoch 566: train loss 0.14250894797345 val loss 0.49343785643577576 Valid accuracy: 88.16666666666667 05:03:16\n","Epoch 567: train loss 0.11411205053329468 val loss 0.7034170031547546 Valid accuracy: 86.83333333333333 05:03:48\n","Epoch 568: train loss 0.108528667340676 val loss 0.6175893545150757 Valid accuracy: 84.33333333333333 05:04:21\n","Epoch 569: train loss 0.1293030313650767 val loss 0.6540266275405884 Valid accuracy: 89.16666666666667 05:04:53\n","Epoch 570: train loss 0.11649738252162933 val loss 0.4273339509963989 Valid accuracy: 84.66666666666667 05:05:26\n","Epoch 571: train loss 0.1244689233104388 val loss 0.5057719349861145 Valid accuracy: 84.83333333333333 05:05:59\n","Epoch 572: train loss 0.16123709271351497 val loss 0.5635289549827576 Valid accuracy: 85.33333333333333 05:06:31\n","Epoch 573: train loss 0.13007615658144156 val loss 0.2820027768611908 Valid accuracy: 85.0 05:07:03\n","Epoch 574: train loss 0.1242269225915273 val loss 0.8317452669143677 Valid accuracy: 84.16666666666667 05:07:36\n","Epoch 575: train loss 0.14231858966251215 val loss 0.6288905739784241 Valid accuracy: 86.66666666666667 05:08:08\n","Epoch 576: train loss 0.11584026654561361 val loss 0.4777744710445404 Valid accuracy: 85.33333333333333 05:08:41\n","Epoch 577: train loss 0.1393033307294051 val loss 0.35252854228019714 Valid accuracy: 84.0 05:09:14\n","Epoch 578: train loss 0.12146793698271116 val loss 0.8093756437301636 Valid accuracy: 85.83333333333333 05:09:46\n","Epoch 579: train loss 0.1067527993520101 val loss 0.9011329412460327 Valid accuracy: 86.16666666666667 05:10:19\n","Epoch 580: train loss 0.12117241946359475 val loss 1.000870943069458 Valid accuracy: 88.33333333333333 05:10:51\n","Epoch 581: train loss 0.11369100163380305 val loss 0.6825093626976013 Valid accuracy: 84.66666666666667 05:11:24\n","Epoch 582: train loss 0.11301564536988735 val loss 0.4179494082927704 Valid accuracy: 86.0 05:11:56\n","Epoch 583: train loss 0.16919042013585567 val loss 0.5024120807647705 Valid accuracy: 88.33333333333333 05:12:29\n","Epoch 584: train loss 0.13264833432932696 val loss 0.7974998950958252 Valid accuracy: 85.5 05:13:01\n","Epoch 585: train loss 0.1268547893812259 val loss 0.5162091255187988 Valid accuracy: 84.16666666666667 05:13:33\n","Epoch 586: train loss 0.1771735726793607 val loss 0.6843240261077881 Valid accuracy: 86.5 05:14:06\n","Epoch 587: train loss 0.12027062724033992 val loss 0.5155871510505676 Valid accuracy: 85.5 05:14:38\n","Epoch 588: train loss 0.10932289662460486 val loss 0.6240918636322021 Valid accuracy: 85.5 05:15:11\n","Epoch 589: train loss 0.12105493421355883 val loss 0.8063691854476929 Valid accuracy: 85.66666666666667 05:15:44\n","Epoch 590: train loss 0.12965457471708455 val loss 0.5260894894599915 Valid accuracy: 88.16666666666667 05:16:16\n","Epoch 591: train loss 0.1300946353127559 val loss 0.9118823409080505 Valid accuracy: 84.33333333333333 05:16:48\n","Epoch 592: train loss 0.1217387347916762 val loss 0.553640604019165 Valid accuracy: 87.5 05:17:20\n","Epoch 593: train loss 0.09673395236333211 val loss 0.6671870946884155 Valid accuracy: 88.5 05:17:53\n","Epoch 594: train loss 0.1302358426898718 val loss 0.426596462726593 Valid accuracy: 82.5 05:18:25\n","Epoch 595: train loss 0.15478704176843167 val loss 0.18839485943317413 Valid accuracy: 86.33333333333333 05:18:57\n","Epoch 596: train loss 0.1265281612922748 val loss 0.48347207903862 Valid accuracy: 85.83333333333333 05:19:29\n","Epoch 597: train loss 0.11199834518134594 val loss 0.3617854416370392 Valid accuracy: 90.66666666666667 05:20:01\n","Epoch 598: train loss 0.10105129318932692 val loss 1.1271730661392212 Valid accuracy: 87.33333333333333 05:20:33\n","Epoch 599: train loss 0.12021521468957265 val loss 0.5741031765937805 Valid accuracy: 87.0 05:21:05\n","Epoch 600: train loss 0.11803557003537814 val loss 0.5820779204368591 Valid accuracy: 88.66666666666667 05:21:38\n","Epoch 601: train loss 0.1019519226749738 val loss 0.7210940718650818 Valid accuracy: 87.33333333333333 05:22:09\n","Epoch 602: train loss 0.12582241234680017 val loss 0.5163583755493164 Valid accuracy: 85.83333333333333 05:22:42\n","Epoch 603: train loss 0.11517691733936469 val loss 0.36917564272880554 Valid accuracy: 85.0 05:23:14\n","Epoch 604: train loss 0.1301244942843914 val loss 0.7189376354217529 Valid accuracy: 85.0 05:23:47\n","Epoch 605: train loss 0.1038609087963899 val loss 0.46257615089416504 Valid accuracy: 81.83333333333333 05:24:19\n","Epoch 606: train loss 0.08241400599479676 val loss 0.35623642802238464 Valid accuracy: 87.5 05:24:51\n","Epoch 607: train loss 0.10655437869330248 val loss 0.48490631580352783 Valid accuracy: 84.5 05:25:24\n","Epoch 608: train loss 0.12659807334343592 val loss 0.9163020849227905 Valid accuracy: 87.16666666666667 05:25:56\n","Epoch 609: train loss 0.11223113559186458 val loss 0.5963406562805176 Valid accuracy: 89.0 05:26:28\n","Epoch 610: train loss 0.19169210587938626 val loss 0.6935790777206421 Valid accuracy: 83.0 05:27:00\n","Epoch 611: train loss 0.14844078334669272 val loss 0.8575344085693359 Valid accuracy: 83.5 05:27:33\n","Epoch 612: train loss 0.14244472806652386 val loss 0.38216084241867065 Valid accuracy: 80.66666666666667 05:28:05\n","Epoch 613: train loss 0.1404707096517086 val loss 0.5714057087898254 Valid accuracy: 85.5 05:28:37\n","Epoch 614: train loss 0.1162574936946233 val loss 0.6765521168708801 Valid accuracy: 86.5 05:29:09\n","Epoch 615: train loss 0.10077811626096567 val loss 0.7490194439888 Valid accuracy: 87.5 05:29:42\n","Epoch 616: train loss 0.16249428679545722 val loss 0.6713611483573914 Valid accuracy: 80.33333333333333 05:30:14\n","Epoch 617: train loss 0.13795122769971688 val loss 0.6563919186592102 Valid accuracy: 87.66666666666667 05:30:46\n","Epoch 618: train loss 0.10024063011010488 val loss 0.7282900214195251 Valid accuracy: 89.83333333333333 05:31:19\n","Epoch 619: train loss 0.10617546898623308 val loss 0.6066993474960327 Valid accuracy: 86.16666666666667 05:31:51\n","Epoch 620: train loss 0.11854299247264861 val loss 0.6721121072769165 Valid accuracy: 87.5 05:32:23\n","Epoch 621: train loss 0.11723657794296742 val loss 0.6559962034225464 Valid accuracy: 87.66666666666667 05:32:56\n","Epoch 622: train loss 0.11832668349146842 val loss 0.32671454548835754 Valid accuracy: 89.5 05:33:28\n","Epoch 623: train loss 0.1399779210239649 val loss 1.133087396621704 Valid accuracy: 85.83333333333333 05:34:00\n","Epoch 624: train loss 0.11749975726008416 val loss 0.4025397300720215 Valid accuracy: 88.16666666666667 05:34:33\n","Epoch 625: train loss 0.16165657974779607 val loss 0.3317214250564575 Valid accuracy: 88.33333333333333 05:35:05\n","Epoch 626: train loss 0.13071519951025645 val loss 0.29790401458740234 Valid accuracy: 85.83333333333333 05:35:38\n","Epoch 627: train loss 0.15702902793884277 val loss 0.5953328013420105 Valid accuracy: 86.83333333333333 05:36:10\n","Epoch 628: train loss 0.11682112276554107 val loss 0.5083850622177124 Valid accuracy: 85.83333333333333 05:36:43\n","Epoch 629: train loss 0.10419870654741924 val loss 0.6104735136032104 Valid accuracy: 88.83333333333333 05:37:15\n","Epoch 630: train loss 0.11647071982423464 val loss 0.7276079058647156 Valid accuracy: 87.5 05:37:47\n","Epoch 631: train loss 0.12931044553716978 val loss 0.3116292357444763 Valid accuracy: 83.83333333333333 05:38:20\n","Epoch 632: train loss 0.1049049978951613 val loss 0.7103704214096069 Valid accuracy: 89.0 05:38:52\n","Epoch 633: train loss 0.08109432304898898 val loss 0.5019003748893738 Valid accuracy: 87.33333333333333 05:39:24\n","Epoch 634: train loss 0.07391370157400767 val loss 0.701073169708252 Valid accuracy: 86.5 05:39:57\n","Epoch 635: train loss 0.08533372802038987 val loss 0.3289538621902466 Valid accuracy: 89.33333333333333 05:40:29\n","Epoch 636: train loss 0.10408501227696737 val loss 0.5314081311225891 Valid accuracy: 87.83333333333333 05:41:01\n","Epoch 637: train loss 0.10066933870315552 val loss 0.16111119091510773 Valid accuracy: 85.66666666666667 05:41:33\n","Epoch 638: train loss 0.12363097190856934 val loss 0.20673295855522156 Valid accuracy: 86.33333333333333 05:42:06\n","Epoch 639: train loss 0.09732776992022991 val loss 0.6337561011314392 Valid accuracy: 86.5 05:42:38\n","Epoch 640: train loss 0.09088626801967621 val loss 0.4341038465499878 Valid accuracy: 88.5 05:43:10\n","Epoch 641: train loss 0.13093518229822318 val loss 0.4396269619464874 Valid accuracy: 89.16666666666667 05:43:42\n","Epoch 642: train loss 0.11468123542765776 val loss 0.4376874566078186 Valid accuracy: 89.16666666666667 05:44:14\n","Epoch 643: train loss 0.11583454040189584 val loss 0.521516740322113 Valid accuracy: 85.83333333333333 05:44:47\n","Epoch 644: train loss 0.12574246861040592 val loss 0.6711254715919495 Valid accuracy: 84.33333333333333 05:45:19\n","Epoch 645: train loss 0.16851492683092753 val loss 0.3146519660949707 Valid accuracy: 84.33333333333333 05:45:51\n","Epoch 646: train loss 0.11502144150435925 val loss 0.46226611733436584 Valid accuracy: 85.5 05:46:23\n","Epoch 647: train loss 0.10595077844957511 val loss 0.6873214244842529 Valid accuracy: 87.16666666666667 05:46:56\n","Epoch 648: train loss 0.13520120220879714 val loss 0.514818549156189 Valid accuracy: 86.5 05:47:28\n","Epoch 649: train loss 0.12875617889066537 val loss 0.3288179934024811 Valid accuracy: 86.16666666666667 05:48:01\n","Epoch 650: train loss 0.09622909578184287 val loss 0.6953195333480835 Valid accuracy: 88.83333333333333 05:48:33\n","Epoch 651: train loss 0.12233626934389273 val loss 0.38049307465553284 Valid accuracy: 86.16666666666667 05:49:05\n","Epoch 652: train loss 0.10458501175045967 val loss 0.4048869013786316 Valid accuracy: 87.5 05:49:37\n","Epoch 653: train loss 0.12590115621685982 val loss 0.4492146372795105 Valid accuracy: 88.83333333333333 05:50:09\n","Epoch 654: train loss 0.1033339861035347 val loss 0.5497291684150696 Valid accuracy: 88.33333333333333 05:50:42\n","Epoch 655: train loss 0.0956356655061245 val loss 0.16140273213386536 Valid accuracy: 85.5 05:51:14\n","Epoch 656: train loss 0.11961795488993326 val loss 0.5538904070854187 Valid accuracy: 88.66666666666667 05:51:47\n","Epoch 657: train loss 0.08747684920827548 val loss 0.517886757850647 Valid accuracy: 89.33333333333333 05:52:19\n","Epoch 658: train loss 0.09166878203550975 val loss 0.20551882684230804 Valid accuracy: 88.5 05:52:52\n","Epoch 659: train loss 0.10712140006323656 val loss 0.6198296546936035 Valid accuracy: 88.16666666666667 05:53:24\n","Epoch 660: train loss 0.1407975040624539 val loss 0.49378177523612976 Valid accuracy: 88.33333333333333 05:53:57\n","Epoch 661: train loss 0.10378126263618469 val loss 0.536919355392456 Valid accuracy: 90.66666666666667 05:54:29\n","Epoch 662: train loss 0.0929471713801225 val loss 0.3186527490615845 Valid accuracy: 88.16666666666667 05:55:01\n","Epoch 663: train loss 0.07344443927208583 val loss 0.9953948855400085 Valid accuracy: 88.83333333333333 05:55:34\n","Epoch 664: train loss 0.11118166993061701 val loss 0.5371167659759521 Valid accuracy: 87.0 05:56:06\n","Epoch 665: train loss 0.16184463093678156 val loss 1.4173712730407715 Valid accuracy: 88.5 05:56:38\n","Epoch 666: train loss 0.12176050946116447 val loss 0.6690967082977295 Valid accuracy: 87.16666666666667 05:57:10\n","Epoch 667: train loss 0.12500525996088982 val loss 0.4245106875896454 Valid accuracy: 89.0 05:57:43\n","Epoch 668: train loss 0.1154467698931694 val loss 0.49502798914909363 Valid accuracy: 90.16666666666667 05:58:16\n","Epoch 669: train loss 0.11429888255894184 val loss 0.5719961524009705 Valid accuracy: 90.16666666666667 05:58:48\n","Epoch 670: train loss 0.11399046165247759 val loss 0.6399480700492859 Valid accuracy: 89.16666666666667 05:59:21\n","Epoch 671: train loss 0.0823157511651516 val loss 0.32667723298072815 Valid accuracy: 90.83333333333333 05:59:53\n","Epoch 672: train loss 0.10553375907242298 val loss 0.6381394267082214 Valid accuracy: 89.5 06:00:25\n","Epoch 673: train loss 0.09003362827003002 val loss 0.32228246331214905 Valid accuracy: 88.83333333333333 06:00:58\n","Epoch 674: train loss 0.1202757350107034 val loss 0.8588340282440186 Valid accuracy: 87.33333333333333 06:01:30\n","Epoch 675: train loss 0.13789142022530237 val loss 0.6392703652381897 Valid accuracy: 90.16666666666667 06:02:02\n","Epoch 676: train loss 0.10638599470257759 val loss 0.5341634154319763 Valid accuracy: 89.33333333333333 06:02:35\n","Epoch 677: train loss 0.12851358778774738 val loss 0.18380224704742432 Valid accuracy: 86.83333333333333 06:03:08\n","Epoch 678: train loss 0.10139437941213449 val loss 0.46060997247695923 Valid accuracy: 86.66666666666667 06:03:41\n","Epoch 679: train loss 0.14665578658382097 val loss 0.30341216921806335 Valid accuracy: 82.66666666666667 06:04:13\n","Epoch 680: train loss 0.11412617119650047 val loss 0.29092496633529663 Valid accuracy: 88.5 06:04:45\n","Epoch 681: train loss 0.08786327933271726 val loss 0.7983231544494629 Valid accuracy: 87.83333333333333 06:05:18\n","Epoch 682: train loss 0.10892540745437146 val loss 0.38482412695884705 Valid accuracy: 89.5 06:05:50\n","Epoch 683: train loss 0.09283535425861676 val loss 0.9163685441017151 Valid accuracy: 87.33333333333333 06:06:23\n","Epoch 684: train loss 0.121067769775788 val loss 0.63230961561203 Valid accuracy: 87.33333333333333 06:06:55\n","Epoch 685: train loss 0.09395766663054625 val loss 0.6887710094451904 Valid accuracy: 89.33333333333333 06:07:28\n","Epoch 686: train loss 0.10233165927231312 val loss 0.6214777231216431 Valid accuracy: 89.66666666666667 06:08:00\n","Epoch 687: train loss 0.08232636590798696 val loss 0.569277822971344 Valid accuracy: 88.83333333333333 06:08:32\n","Epoch 688: train loss 0.10132543963690599 val loss 0.7775004506111145 Valid accuracy: 88.16666666666667 06:09:05\n","Epoch 689: train loss 0.12224074775973956 val loss 0.6420084238052368 Valid accuracy: 85.16666666666667 06:09:37\n","Epoch 690: train loss 0.11345340244472027 val loss 0.5075470209121704 Valid accuracy: 86.83333333333333 06:10:09\n","Epoch 691: train loss 0.09749582385023435 val loss 0.9250378608703613 Valid accuracy: 89.66666666666667 06:10:42\n","Epoch 692: train loss 0.09747744056085746 val loss 0.34081321954727173 Valid accuracy: 89.5 06:11:14\n","Epoch 693: train loss 0.11922676871220271 val loss 0.4310559928417206 Valid accuracy: 89.16666666666667 06:11:46\n","Epoch 694: train loss 0.1053290138890346 val loss 0.5004739165306091 Valid accuracy: 87.33333333333333 06:12:18\n","Epoch 695: train loss 0.09401661897699039 val loss 1.1356571912765503 Valid accuracy: 89.66666666666667 06:12:51\n","Epoch 696: train loss 0.11741780921816826 val loss 0.5207006335258484 Valid accuracy: 86.83333333333333 06:13:23\n","Epoch 697: train loss 0.09974548727273941 val loss 0.310339093208313 Valid accuracy: 90.83333333333333 06:13:55\n","Epoch 698: train loss 0.10437070474028587 val loss 0.30969756841659546 Valid accuracy: 90.83333333333333 06:14:28\n","Epoch 699: train loss 0.08417364838222663 val loss 0.9844160676002502 Valid accuracy: 88.33333333333333 06:15:00\n","Epoch 700: train loss 0.12337572743495305 val loss 0.2522238790988922 Valid accuracy: 88.33333333333333 06:15:32\n","Epoch 701: train loss 0.1069181927293539 val loss 0.4801427721977234 Valid accuracy: 87.66666666666667 06:16:04\n","Epoch 702: train loss 0.07238145006199678 val loss 0.3582994341850281 Valid accuracy: 89.5 06:16:37\n","Epoch 703: train loss 0.09289220303297042 val loss 0.35596027970314026 Valid accuracy: 90.33333333333333 06:17:09\n","Epoch 704: train loss 0.08439798163870971 val loss 0.6738620400428772 Valid accuracy: 89.33333333333333 06:17:42\n","Epoch 705: train loss 0.1246986681719621 val loss 0.43898653984069824 Valid accuracy: 90.5 06:18:14\n","Epoch 706: train loss 0.12518199644982814 val loss 0.48687243461608887 Valid accuracy: 87.33333333333333 06:18:47\n","Epoch 707: train loss 0.11331350636978944 val loss 0.6474739909172058 Valid accuracy: 91.33333333333333 06:19:19\n","Epoch 708: train loss 0.08814175933599472 val loss 0.17237843573093414 Valid accuracy: 89.5 06:19:51\n","Epoch 709: train loss 0.10847169297436873 val loss 0.15918654203414917 Valid accuracy: 88.83333333333333 06:20:24\n","Epoch 710: train loss 0.08395236164331436 val loss 0.18905526399612427 Valid accuracy: 89.16666666666667 06:20:56\n","Epoch 711: train loss 0.14261109260221322 val loss 0.4441009759902954 Valid accuracy: 86.33333333333333 06:21:29\n","Epoch 712: train loss 0.12524073732395966 val loss 0.5389766693115234 Valid accuracy: 88.83333333333333 06:22:01\n","Epoch 713: train loss 0.10510639160871506 val loss 0.6942127346992493 Valid accuracy: 90.33333333333333 06:22:34\n","Epoch 714: train loss 0.08607075365881126 val loss 0.4107605516910553 Valid accuracy: 89.83333333333333 06:23:06\n","Epoch 715: train loss 0.11027079304059346 val loss 0.2165503352880478 Valid accuracy: 91.5 06:23:39\n","Epoch 716: train loss 0.08849431740740935 val loss 0.4713980257511139 Valid accuracy: 91.0 06:24:11\n","Epoch 717: train loss 0.0781630748262008 val loss 0.6174003481864929 Valid accuracy: 92.16666666666667 06:24:44\n","Epoch 718: train loss 0.10886960638066133 val loss 1.0094027519226074 Valid accuracy: 91.83333333333333 06:25:17\n","Epoch 719: train loss 0.07575417454044024 val loss 0.4304397404193878 Valid accuracy: 92.0 06:25:49\n","Epoch 720: train loss 0.06441893520454565 val loss 0.44888973236083984 Valid accuracy: 90.83333333333333 06:26:21\n","Epoch 721: train loss 0.07056012888749441 val loss 0.8574981093406677 Valid accuracy: 91.33333333333333 06:26:54\n","Epoch 722: train loss 0.09074253184099992 val loss 0.7336517572402954 Valid accuracy: 87.83333333333333 06:27:26\n","Epoch 723: train loss 0.11856082576016586 val loss 0.6551061272621155 Valid accuracy: 89.5 06:27:59\n","Epoch 724: train loss 0.07786305718123913 val loss 0.5082271099090576 Valid accuracy: 89.0 06:28:31\n","Epoch 725: train loss 0.06510642766952515 val loss 0.37777936458587646 Valid accuracy: 90.66666666666667 06:29:04\n","Epoch 726: train loss 0.0975811292231083 val loss 0.2207290679216385 Valid accuracy: 91.83333333333333 06:29:36\n","Epoch 727: train loss 0.14018451509376367 val loss 0.5796467661857605 Valid accuracy: 89.16666666666667 06:30:09\n","Epoch 728: train loss 0.11806841482718786 val loss 0.8426694273948669 Valid accuracy: 89.5 06:30:41\n","Epoch 729: train loss 0.09248402891059716 val loss 0.3496910333633423 Valid accuracy: 90.33333333333333 06:31:15\n","Epoch 730: train loss 0.09498425285021464 val loss 0.5639597177505493 Valid accuracy: 86.5 06:31:47\n","Epoch 731: train loss 0.0803374179204305 val loss 0.4652603268623352 Valid accuracy: 88.16666666666667 06:32:20\n","Epoch 732: train loss 0.05875676142672698 val loss 0.33301910758018494 Valid accuracy: 90.0 06:32:53\n","Epoch 733: train loss 0.12262014505763849 val loss 0.5655689835548401 Valid accuracy: 87.16666666666667 06:33:26\n","Epoch 734: train loss 0.09733977836867173 val loss 0.5191181302070618 Valid accuracy: 88.16666666666667 06:33:59\n","Epoch 735: train loss 0.12285678674777349 val loss 0.1488223671913147 Valid accuracy: 87.33333333333333 06:34:32\n","Epoch 736: train loss 0.09580782622098923 val loss 0.34009039402008057 Valid accuracy: 88.0 06:35:05\n","Epoch 737: train loss 0.09965828955173492 val loss 0.3676512837409973 Valid accuracy: 87.66666666666667 06:35:37\n","Epoch 738: train loss 0.11890052013099194 val loss 0.6479418277740479 Valid accuracy: 89.0 06:36:11\n","Epoch 739: train loss 0.10314542564253013 val loss 0.6032416820526123 Valid accuracy: 87.66666666666667 06:36:44\n","Epoch 740: train loss 0.10480714323620001 val loss 0.4523872137069702 Valid accuracy: 89.83333333333333 06:37:17\n","Epoch 741: train loss 0.0948916395008564 val loss 0.623135507106781 Valid accuracy: 92.33333333333333 06:37:50\n","Epoch 742: train loss 0.07391331108907859 val loss 0.6493964195251465 Valid accuracy: 89.33333333333333 06:38:23\n","Epoch 743: train loss 0.10863090455532073 val loss 0.4732436537742615 Valid accuracy: 89.16666666666667 06:38:55\n","Epoch 744: train loss 0.08024891590078671 val loss 0.3817284107208252 Valid accuracy: 87.5 06:39:28\n","Epoch 745: train loss 0.12147342311839263 val loss 0.33193662762641907 Valid accuracy: 90.66666666666667 06:40:01\n","Epoch 746: train loss 0.08851325410107772 val loss 0.8165446519851685 Valid accuracy: 85.33333333333333 06:40:34\n","Epoch 747: train loss 0.08992814406752586 val loss 0.6939213871955872 Valid accuracy: 89.66666666666667 06:41:08\n","Epoch 748: train loss 0.08086452891429265 val loss 0.43060731887817383 Valid accuracy: 90.33333333333333 06:41:41\n","Epoch 749: train loss 0.1313718742132187 val loss 0.7543896436691284 Valid accuracy: 89.5 06:42:14\n","Epoch 750: train loss 0.10378995425999164 val loss 1.0266022682189941 Valid accuracy: 89.0 06:42:47\n","Epoch 751: train loss 0.0795081434895595 val loss 0.5027786493301392 Valid accuracy: 92.33333333333333 06:43:19\n","Epoch 752: train loss 0.07985841244459152 val loss 0.7033741474151611 Valid accuracy: 91.5 06:43:53\n","Epoch 753: train loss 0.1148882631212473 val loss 0.6854122877120972 Valid accuracy: 87.5 06:44:25\n","Epoch 754: train loss 0.10404734854896863 val loss 0.5062604546546936 Valid accuracy: 87.83333333333333 06:44:59\n","Epoch 755: train loss 0.09113717389603455 val loss 0.4692619740962982 Valid accuracy: 89.16666666666667 06:45:31\n","Epoch 756: train loss 0.1079408639172713 val loss 0.5439904928207397 Valid accuracy: 91.0 06:46:04\n","Epoch 757: train loss 0.0989107246696949 val loss 0.42547574639320374 Valid accuracy: 89.66666666666667 06:46:37\n","Epoch 758: train loss 0.0787798813978831 val loss 0.2794663608074188 Valid accuracy: 89.0 06:47:10\n","Epoch 759: train loss 0.0762982398023208 val loss 0.6854946613311768 Valid accuracy: 91.83333333333333 06:47:42\n","Epoch 760: train loss 0.08408448877433936 val loss 0.338443785905838 Valid accuracy: 89.16666666666667 06:48:15\n","Epoch 761: train loss 0.07176159078876178 val loss 0.4991758167743683 Valid accuracy: 90.5 06:48:47\n","Epoch 762: train loss 0.08720227951804797 val loss 0.6004143953323364 Valid accuracy: 90.0 06:49:20\n","Epoch 763: train loss 0.09105640545487403 val loss 0.3447774648666382 Valid accuracy: 92.16666666666667 06:49:53\n","Epoch 764: train loss 0.09221055140097936 val loss 0.6146228909492493 Valid accuracy: 93.33333333333333 06:50:26\n","Epoch 765: train loss 0.08533385711411635 val loss 1.0532352924346924 Valid accuracy: 89.66666666666667 06:50:59\n","Epoch 766: train loss 0.06996232427656651 val loss 0.13286803662776947 Valid accuracy: 91.16666666666667 06:51:32\n","Epoch 767: train loss 0.08138939539591471 val loss 0.8105571866035461 Valid accuracy: 90.33333333333333 06:52:06\n","Epoch 768: train loss 0.09853975499669711 val loss 0.5827898979187012 Valid accuracy: 86.83333333333333 06:52:39\n","Epoch 769: train loss 0.09067882222433885 val loss 0.3970707356929779 Valid accuracy: 89.66666666666667 06:53:12\n","Epoch 770: train loss 0.11647684325774511 val loss 0.3303956091403961 Valid accuracy: 90.33333333333333 06:53:45\n","Epoch 771: train loss 0.09632219396531581 val loss 0.2049596756696701 Valid accuracy: 89.33333333333333 06:54:18\n","Epoch 772: train loss 0.12119769476354122 val loss 0.5605320930480957 Valid accuracy: 89.83333333333333 06:54:50\n","Epoch 773: train loss 0.08991918715337913 val loss 0.6292016506195068 Valid accuracy: 87.83333333333333 06:55:23\n","Epoch 774: train loss 0.09285541678468387 val loss 0.3198765814304352 Valid accuracy: 89.5 06:55:56\n","Epoch 775: train loss 0.1042004360506932 val loss 0.6657655239105225 Valid accuracy: 85.0 06:56:29\n","Epoch 776: train loss 0.08475145777066549 val loss 0.8992071747779846 Valid accuracy: 87.33333333333333 06:57:02\n","Epoch 777: train loss 0.07993225815395515 val loss 0.33935630321502686 Valid accuracy: 89.66666666666667 06:57:34\n","Epoch 778: train loss 0.0974905805538098 val loss 0.574033260345459 Valid accuracy: 88.0 06:58:08\n","Epoch 779: train loss 0.09557245415945848 val loss 0.9320061206817627 Valid accuracy: 88.16666666666667 06:58:41\n","Epoch 780: train loss 0.07628445523480575 val loss 0.6067245006561279 Valid accuracy: 87.83333333333333 06:59:13\n","Epoch 781: train loss 0.07744408411284288 val loss 0.7027779817581177 Valid accuracy: 89.16666666666667 06:59:47\n","Epoch 782: train loss 0.07272736122210821 val loss 0.6405338048934937 Valid accuracy: 90.5 07:00:19\n","Epoch 783: train loss 0.06286809501548608 val loss 0.19419950246810913 Valid accuracy: 89.5 07:00:52\n","Epoch 784: train loss 0.0883714563647906 val loss 0.25381407141685486 Valid accuracy: 91.5 07:01:25\n","Epoch 785: train loss 0.1288867003719012 val loss 0.5486717820167542 Valid accuracy: 87.16666666666667 07:01:58\n","Epoch 786: train loss 0.13686845945815246 val loss 0.4790257513523102 Valid accuracy: 88.83333333333333 07:02:30\n","Epoch 787: train loss 0.08134168756504853 val loss 0.3030639886856079 Valid accuracy: 90.5 07:03:03\n","Epoch 788: train loss 0.07267598720888296 val loss 0.5529161691665649 Valid accuracy: 92.66666666666667 07:03:36\n","Epoch 789: train loss 0.07994828954339027 val loss 0.26117244362831116 Valid accuracy: 90.0 07:04:09\n","Epoch 790: train loss 0.0889613318691651 val loss 0.5454199314117432 Valid accuracy: 91.0 07:04:42\n","Epoch 791: train loss 0.0833279533435901 val loss 0.23961855471134186 Valid accuracy: 92.16666666666667 07:05:14\n","Epoch 792: train loss 0.0884271185596784 val loss 0.31667065620422363 Valid accuracy: 88.66666666666667 07:05:48\n","Epoch 793: train loss 0.07372676206131776 val loss 0.24785222113132477 Valid accuracy: 91.83333333333333 07:06:20\n","Epoch 794: train loss 0.0589498217155536 val loss 0.24703602492809296 Valid accuracy: 90.66666666666667 07:06:53\n","Epoch 795: train loss 0.05855464724202951 val loss 0.24867035448551178 Valid accuracy: 89.83333333333333 07:07:25\n","Epoch 796: train loss 0.08337374073763688 val loss 0.32911139726638794 Valid accuracy: 89.33333333333333 07:07:58\n","Epoch 797: train loss 0.09184841173390547 val loss 0.4598570466041565 Valid accuracy: 90.16666666666667 07:08:30\n","Epoch 798: train loss 0.0627738802631696 val loss 0.747244119644165 Valid accuracy: 90.0 07:09:04\n","Epoch 799: train loss 0.0925730257978042 val loss 0.5187888741493225 Valid accuracy: 90.0 07:09:37\n","Epoch 800: train loss 0.11366420440375805 val loss 0.19486820697784424 Valid accuracy: 86.16666666666667 07:10:09\n","Epoch 801: train loss 0.07891552043457827 val loss 0.4095512926578522 Valid accuracy: 91.16666666666667 07:10:43\n","Epoch 802: train loss 0.10128367677330971 val loss 0.3838629424571991 Valid accuracy: 92.5 07:11:15\n","Epoch 803: train loss 0.05644996479153633 val loss 0.47422605752944946 Valid accuracy: 90.83333333333333 07:11:48\n","Epoch 804: train loss 0.09559699033697446 val loss 0.6740001440048218 Valid accuracy: 91.66666666666667 07:12:20\n","Epoch 805: train loss 0.09943001409371693 val loss 0.7546730637550354 Valid accuracy: 92.33333333333333 07:12:54\n","Epoch 806: train loss 0.08492620535194874 val loss 0.3735329210758209 Valid accuracy: 91.16666666666667 07:13:27\n","Epoch 807: train loss 0.10416686654090881 val loss 0.18554635345935822 Valid accuracy: 89.16666666666667 07:14:00\n","Epoch 808: train loss 0.1221441916624705 val loss 0.6951513290405273 Valid accuracy: 90.66666666666667 07:14:34\n","Epoch 809: train loss 0.1280561605344216 val loss 0.5521578192710876 Valid accuracy: 91.33333333333333 07:15:07\n","Epoch 810: train loss 0.1221077136695385 val loss 0.6045669317245483 Valid accuracy: 88.5 07:15:40\n","Epoch 811: train loss 0.08566052578389645 val loss 0.5283454060554504 Valid accuracy: 87.5 07:16:12\n","Epoch 812: train loss 0.062234980737169585 val loss 0.35050538182258606 Valid accuracy: 92.33333333333333 07:16:45\n","Epoch 813: train loss 0.09602730380992094 val loss 0.31593242287635803 Valid accuracy: 90.33333333333333 07:17:17\n","Epoch 814: train loss 0.06335033039251964 val loss 0.27269184589385986 Valid accuracy: 92.0 07:17:51\n","Epoch 815: train loss 0.07371117445329825 val loss 0.25931042432785034 Valid accuracy: 91.33333333333333 07:18:23\n","Epoch 816: train loss 0.0756915633380413 val loss 0.7263931035995483 Valid accuracy: 91.16666666666667 07:18:56\n","Epoch 817: train loss 0.047721117784579596 val loss 0.5055455565452576 Valid accuracy: 92.5 07:19:29\n","Epoch 818: train loss 0.06876092620193958 val loss 0.3761120140552521 Valid accuracy: 92.0 07:20:02\n","Epoch 819: train loss 0.06592923057576021 val loss 0.8643274307250977 Valid accuracy: 89.5 07:20:35\n","Epoch 820: train loss 0.05664070357879003 val loss 0.4534434676170349 Valid accuracy: 85.66666666666667 07:21:08\n","Epoch 821: train loss 0.0878975372761488 val loss 0.49313727021217346 Valid accuracy: 88.5 07:21:41\n","Epoch 822: train loss 0.10423722011347612 val loss 0.5852149724960327 Valid accuracy: 87.83333333333333 07:22:13\n","Epoch 823: train loss 0.11578368393083413 val loss 0.5599120855331421 Valid accuracy: 90.5 07:22:46\n","Epoch 824: train loss 0.08823866747319699 val loss 0.42727893590927124 Valid accuracy: 90.66666666666667 07:23:18\n","Epoch 825: train loss 0.07004751895864804 val loss 0.374813437461853 Valid accuracy: 92.33333333333333 07:23:51\n","Epoch 826: train loss 0.0724128328760465 val loss 0.557447612285614 Valid accuracy: 91.5 07:24:24\n","Epoch 827: train loss 0.05136894427239895 val loss 0.34325891733169556 Valid accuracy: 92.0 07:24:57\n","Epoch 828: train loss 0.06798369539280733 val loss 0.9378620982170105 Valid accuracy: 89.83333333333333 07:25:30\n","Epoch 829: train loss 0.10636791413029036 val loss 0.4944303631782532 Valid accuracy: 92.83333333333333 07:26:03\n","Epoch 830: train loss 0.10728278584778309 val loss 0.3402984142303467 Valid accuracy: 91.5 07:26:36\n","Epoch 831: train loss 0.08917407127718131 val loss 0.6469829678535461 Valid accuracy: 94.0 07:27:08\n","Epoch 832: train loss 0.08989010229706765 val loss 0.35194289684295654 Valid accuracy: 91.83333333333333 07:27:41\n","Epoch 833: train loss 0.08114827379584312 val loss 0.5550882816314697 Valid accuracy: 92.83333333333333 07:28:13\n","Epoch 834: train loss 0.11331664221982161 val loss 0.12130539864301682 Valid accuracy: 91.83333333333333 07:28:47\n","Epoch 835: train loss 0.09619051553308963 val loss 0.5306448340415955 Valid accuracy: 91.16666666666667 07:29:19\n","Epoch 836: train loss 0.10570144437253476 val loss 0.8278958797454834 Valid accuracy: 84.5 07:29:52\n","Epoch 837: train loss 0.14007192827761172 val loss 0.25064679980278015 Valid accuracy: 90.16666666666667 07:30:26\n","Epoch 838: train loss 0.08341284739474455 val loss 0.2959383428096771 Valid accuracy: 93.16666666666667 07:30:58\n","Epoch 839: train loss 0.06430007127424081 val loss 0.2973874509334564 Valid accuracy: 92.33333333333333 07:31:32\n","Epoch 840: train loss 0.06375972745319207 val loss 0.7144850492477417 Valid accuracy: 90.16666666666667 07:32:04\n","Epoch 841: train loss 0.08244909942150117 val loss 0.38600465655326843 Valid accuracy: 91.5 07:32:37\n","Epoch 842: train loss 0.08138289337356885 val loss 0.5136171579360962 Valid accuracy: 89.83333333333333 07:33:10\n","Epoch 843: train loss 0.05878618083894253 val loss 0.2993532419204712 Valid accuracy: 90.5 07:33:42\n","Epoch 844: train loss 0.08062001590927442 val loss 0.6935584545135498 Valid accuracy: 89.83333333333333 07:34:15\n","Epoch 845: train loss 0.06675897963345051 val loss 0.45531246066093445 Valid accuracy: 92.0 07:34:48\n","Epoch 846: train loss 0.0858893654992183 val loss 0.26547789573669434 Valid accuracy: 91.16666666666667 07:35:20\n","Epoch 847: train loss 0.056622423231601715 val loss 0.34399718046188354 Valid accuracy: 92.83333333333333 07:35:54\n","Epoch 848: train loss 0.06045044096807639 val loss 0.37682807445526123 Valid accuracy: 90.5 07:36:27\n","Epoch 849: train loss 0.11564893133938313 val loss 0.4635718762874603 Valid accuracy: 93.0 07:36:59\n","Epoch 850: train loss 0.1089395052442948 val loss 0.34119197726249695 Valid accuracy: 92.83333333333333 07:37:32\n","Epoch 851: train loss 0.10301484130322933 val loss 0.5836907625198364 Valid accuracy: 88.33333333333333 07:38:04\n","Epoch 852: train loss 0.0836229636023442 val loss 0.5296987891197205 Valid accuracy: 94.16666666666667 07:38:37\n","Epoch 853: train loss 0.06080855389436086 val loss 0.45245295763015747 Valid accuracy: 94.66666666666667 07:39:10\n","Epoch 854: train loss 0.06387755014002323 val loss 0.20780082046985626 Valid accuracy: 93.83333333333333 07:39:43\n","Epoch 855: train loss 0.06390611208975315 val loss 0.4071774184703827 Valid accuracy: 93.16666666666667 07:40:15\n","Epoch 856: train loss 0.06042674086987972 val loss 0.4238274395465851 Valid accuracy: 93.5 07:40:48\n","Epoch 857: train loss 0.08550255720814069 val loss 0.12948378920555115 Valid accuracy: 93.66666666666667 07:41:22\n","Epoch 858: train loss 0.059316479886571565 val loss 0.24545973539352417 Valid accuracy: 94.5 07:41:54\n","Epoch 859: train loss 0.06806694271663825 val loss 0.6222559213638306 Valid accuracy: 92.83333333333333 07:42:27\n","Epoch 860: train loss 0.08868700896700223 val loss 0.7924321293830872 Valid accuracy: 91.5 07:43:00\n","Epoch 861: train loss 0.04909743495285511 val loss 0.23863746225833893 Valid accuracy: 92.0 07:43:33\n","Epoch 862: train loss 0.05791625410318375 val loss 0.22518174350261688 Valid accuracy: 92.0 07:44:05\n","Epoch 863: train loss 0.05596322412292162 val loss 0.5340467691421509 Valid accuracy: 93.33333333333333 07:44:39\n","Epoch 864: train loss 0.07394383323689302 val loss 0.6283990144729614 Valid accuracy: 92.33333333333333 07:45:11\n","Epoch 865: train loss 0.09023447694877783 val loss 0.591949462890625 Valid accuracy: 91.5 07:45:44\n","Epoch 866: train loss 0.10595799890657266 val loss 0.527001678943634 Valid accuracy: 90.83333333333333 07:46:17\n","Epoch 867: train loss 0.10505168673892816 val loss 0.381171315908432 Valid accuracy: 94.83333333333333 07:46:50\n","Epoch 868: train loss 0.06712775401771069 val loss 0.3373890519142151 Valid accuracy: 94.16666666666667 07:47:23\n","Epoch 869: train loss 0.0668079429368178 val loss 0.2983548939228058 Valid accuracy: 92.66666666666667 07:47:56\n","Epoch 870: train loss 0.08443467974662781 val loss 0.4307844340801239 Valid accuracy: 92.83333333333333 07:48:29\n","Epoch 871: train loss 0.059122491851449015 val loss 0.5619926452636719 Valid accuracy: 95.16666666666667 07:49:01\n","Epoch 872: train loss 0.0810426207135121 val loss 0.48151639103889465 Valid accuracy: 92.16666666666667 07:49:34\n","Epoch 873: train loss 0.08168020161489646 val loss 0.28353071212768555 Valid accuracy: 93.16666666666667 07:50:07\n","Epoch 874: train loss 0.07930271831651528 val loss 1.4789869785308838 Valid accuracy: 91.33333333333333 07:50:40\n","Epoch 875: train loss 0.08129914191861948 val loss 0.3227466940879822 Valid accuracy: 92.16666666666667 07:51:13\n","Epoch 876: train loss 0.08272476144134998 val loss 0.7412468194961548 Valid accuracy: 92.5 07:51:46\n","Epoch 877: train loss 0.06670172462860743 val loss 0.29853901267051697 Valid accuracy: 92.5 07:52:19\n","Epoch 878: train loss 0.08017678034802278 val loss 0.3639185130596161 Valid accuracy: 93.33333333333333 07:52:52\n","Epoch 879: train loss 0.08509852034350236 val loss 0.5787209868431091 Valid accuracy: 93.83333333333333 07:53:25\n","Epoch 880: train loss 0.08128061980009078 val loss 0.5130252242088318 Valid accuracy: 92.33333333333333 07:53:57\n","Epoch 881: train loss 0.10474213473498821 val loss 0.538362979888916 Valid accuracy: 92.0 07:54:30\n","Epoch 882: train loss 0.06577401841680208 val loss 0.47615790367126465 Valid accuracy: 93.33333333333333 07:55:03\n","Epoch 883: train loss 0.08661757861574491 val loss 0.4369947612285614 Valid accuracy: 90.5 07:55:36\n","Epoch 884: train loss 0.06554377565781276 val loss 0.14733362197875977 Valid accuracy: 94.5 07:56:09\n","Epoch 885: train loss 0.05884266746540864 val loss 0.39171385765075684 Valid accuracy: 92.33333333333333 07:56:42\n","Epoch 886: train loss 0.06852694412072499 val loss 0.31510642170906067 Valid accuracy: 91.0 07:57:15\n","Epoch 887: train loss 0.09433992167313894 val loss 0.6832062005996704 Valid accuracy: 92.33333333333333 07:57:47\n","Epoch 888: train loss 0.12345686346292496 val loss 0.30957600474357605 Valid accuracy: 93.5 07:58:20\n","Epoch 889: train loss 0.06807038123408954 val loss 0.20577238500118256 Valid accuracy: 92.0 07:58:53\n","Epoch 890: train loss 0.06611909781893094 val loss 0.239577978849411 Valid accuracy: 94.33333333333333 07:59:26\n","Epoch 891: train loss 0.09462618676324686 val loss 0.24005398154258728 Valid accuracy: 90.5 07:59:58\n","Epoch 892: train loss 0.10442998146017392 val loss 0.41576138138771057 Valid accuracy: 91.5 08:00:31\n","Epoch 893: train loss 0.07022407313187917 val loss 0.6782934665679932 Valid accuracy: 94.0 08:01:04\n","Epoch 894: train loss 0.07067461545268694 val loss 0.5176299214363098 Valid accuracy: 95.5 08:01:37\n","Epoch 895: train loss 0.07238628258307775 val loss 0.48451027274131775 Valid accuracy: 92.66666666666667 08:02:10\n","Epoch 896: train loss 0.06692409440875054 val loss 0.5281633138656616 Valid accuracy: 91.16666666666667 08:02:42\n","Epoch 897: train loss 0.0750922241806984 val loss 0.17517565190792084 Valid accuracy: 91.83333333333333 08:03:16\n","Epoch 898: train loss 0.07481569603085518 val loss 0.3678642809391022 Valid accuracy: 92.5 08:03:48\n","Epoch 899: train loss 0.06168099527557691 val loss 0.26959413290023804 Valid accuracy: 93.16666666666667 08:04:21\n","Epoch 900: train loss 0.03727130542198817 val loss 0.25270628929138184 Valid accuracy: 93.5 08:04:54\n","Epoch 901: train loss 0.03924797438085079 val loss 0.4400387108325958 Valid accuracy: 95.33333333333333 08:05:27\n","Epoch 902: train loss 0.0684874362250169 val loss 0.6070460677146912 Valid accuracy: 92.16666666666667 08:05:59\n","Epoch 903: train loss 0.11088636755943299 val loss 0.7397156357765198 Valid accuracy: 89.66666666666667 08:06:32\n","Epoch 904: train loss 0.11776872985064983 val loss 0.4415246248245239 Valid accuracy: 88.16666666666667 08:07:05\n","Epoch 905: train loss 0.08962253081301848 val loss 0.6398473381996155 Valid accuracy: 91.16666666666667 08:07:38\n","Epoch 906: train loss 0.08735812596976757 val loss 0.24014823138713837 Valid accuracy: 92.33333333333333 08:08:11\n","Epoch 907: train loss 0.07237298707167307 val loss 0.4552399814128876 Valid accuracy: 92.83333333333333 08:08:44\n","Epoch 908: train loss 0.04755765549838543 val loss 0.385852575302124 Valid accuracy: 92.33333333333333 08:09:17\n","Epoch 909: train loss 0.080469536408782 val loss 0.4010043740272522 Valid accuracy: 93.0 08:09:50\n","Epoch 910: train loss 0.046938338950276375 val loss 0.24558724462985992 Valid accuracy: 93.83333333333333 08:10:23\n","Epoch 911: train loss 0.07615579821169377 val loss 0.2266308218240738 Valid accuracy: 94.0 08:10:55\n","Epoch 912: train loss 0.08372780735294025 val loss 0.17196884751319885 Valid accuracy: 94.5 08:11:28\n","Epoch 913: train loss 0.06893159801761309 val loss 0.6950795650482178 Valid accuracy: 91.0 08:12:01\n","Epoch 914: train loss 0.06873162113130092 val loss 0.2641605734825134 Valid accuracy: 92.16666666666667 08:12:34\n","Epoch 915: train loss 0.061466818327705064 val loss 0.6224472522735596 Valid accuracy: 90.16666666666667 08:13:07\n","Epoch 916: train loss 0.06279699581364791 val loss 0.4001195430755615 Valid accuracy: 92.5 08:13:40\n","Epoch 917: train loss 0.05643116968373458 val loss 0.30124354362487793 Valid accuracy: 93.33333333333333 08:14:14\n","Epoch 918: train loss 0.044034945964813235 val loss 0.3947211503982544 Valid accuracy: 94.5 08:14:47\n","Epoch 919: train loss 0.05894744160274665 val loss 0.24452494084835052 Valid accuracy: 93.0 08:15:20\n","Epoch 920: train loss 0.060462901070714 val loss 0.41112327575683594 Valid accuracy: 90.5 08:15:52\n","Epoch 921: train loss 0.055420924201607706 val loss 0.4373212456703186 Valid accuracy: 92.83333333333333 08:16:25\n","Epoch 922: train loss 0.08003888761003812 val loss 0.6224179863929749 Valid accuracy: 93.16666666666667 08:16:58\n","Epoch 923: train loss 0.09041449358065923 val loss 0.4386117458343506 Valid accuracy: 92.33333333333333 08:17:31\n","Epoch 924: train loss 0.08296313285827636 val loss 0.846347451210022 Valid accuracy: 89.33333333333333 08:18:04\n","Epoch 925: train loss 0.08847990294297536 val loss 0.1721162050962448 Valid accuracy: 90.16666666666667 08:18:37\n","Epoch 926: train loss 0.10695831894874573 val loss 0.4187064468860626 Valid accuracy: 88.0 08:19:11\n","Epoch 927: train loss 0.09191211059689522 val loss 0.7205682396888733 Valid accuracy: 90.83333333333333 08:19:44\n","Epoch 928: train loss 0.09494537867605686 val loss 0.16906090080738068 Valid accuracy: 92.83333333333333 08:20:17\n","Epoch 929: train loss 0.07522868894040585 val loss 0.23452849686145782 Valid accuracy: 90.5 08:20:49\n","Epoch 930: train loss 0.078422393972675 val loss 0.47834712266921997 Valid accuracy: 91.0 08:21:22\n","Epoch 931: train loss 0.06837096797923246 val loss 0.18939752876758575 Valid accuracy: 93.33333333333333 08:21:55\n","Epoch 932: train loss 0.07019719677666823 val loss 0.3903248906135559 Valid accuracy: 91.83333333333333 08:22:28\n","Epoch 933: train loss 0.04832267868022124 val loss 0.5243958234786987 Valid accuracy: 94.16666666666667 08:23:01\n","Epoch 934: train loss 0.07642089207967122 val loss 0.7833834290504456 Valid accuracy: 92.66666666666667 08:23:34\n","Epoch 935: train loss 0.07278993462522824 val loss 0.3176770806312561 Valid accuracy: 91.33333333333333 08:24:07\n","Epoch 936: train loss 0.04721801911791166 val loss 0.5249202251434326 Valid accuracy: 93.0 08:24:40\n","Epoch 937: train loss 0.09675041238466899 val loss 0.2293820083141327 Valid accuracy: 93.5 08:25:13\n","Epoch 938: train loss 0.07720293449858824 val loss 0.30762165784835815 Valid accuracy: 93.16666666666667 08:25:46\n","Epoch 939: train loss 0.07713699827591579 val loss 0.3783990144729614 Valid accuracy: 91.16666666666667 08:26:19\n","Epoch 940: train loss 0.06269261986017227 val loss 0.4457017779350281 Valid accuracy: 93.66666666666667 08:26:52\n","Epoch 941: train loss 0.04395629271864891 val loss 0.3676295280456543 Valid accuracy: 93.5 08:27:25\n","Epoch 942: train loss 0.04906713142991066 val loss 0.44738420844078064 Valid accuracy: 93.83333333333333 08:27:58\n","Epoch 943: train loss 0.05955933394531409 val loss 0.7004169225692749 Valid accuracy: 93.83333333333333 08:28:31\n","Epoch 944: train loss 0.1052747930586338 val loss 0.46049773693084717 Valid accuracy: 86.33333333333333 08:29:04\n","Epoch 945: train loss 0.07234576125939687 val loss 0.4003342390060425 Valid accuracy: 91.83333333333333 08:29:37\n","Epoch 946: train loss 0.0657394652813673 val loss 0.21103090047836304 Valid accuracy: 93.5 08:30:10\n","Epoch 947: train loss 0.07243628866970539 val loss 0.33216771483421326 Valid accuracy: 93.0 08:30:43\n","Epoch 948: train loss 0.045481297721465426 val loss 0.5011560320854187 Valid accuracy: 93.16666666666667 08:31:16\n","Epoch 949: train loss 0.04615647805233796 val loss 0.4901936650276184 Valid accuracy: 93.33333333333333 08:31:49\n","Epoch 950: train loss 0.07169905856251717 val loss 0.4661664366722107 Valid accuracy: 95.66666666666667 08:32:22\n","Epoch 951: train loss 0.0645308178414901 val loss 0.36186712980270386 Valid accuracy: 94.0 08:32:55\n","Epoch 952: train loss 0.061953222726782164 val loss 0.3538067042827606 Valid accuracy: 94.66666666666667 08:33:28\n","Epoch 953: train loss 0.10818518079817295 val loss 0.23504483699798584 Valid accuracy: 93.66666666666667 08:34:01\n","Epoch 954: train loss 0.060587510963280994 val loss 0.5224325060844421 Valid accuracy: 94.83333333333333 08:34:34\n","Epoch 955: train loss 0.1009561637043953 val loss 0.2462652027606964 Valid accuracy: 93.66666666666667 08:35:08\n","Epoch 956: train loss 0.06245647964378198 val loss 0.4410414695739746 Valid accuracy: 93.66666666666667 08:35:41\n","Epoch 957: train loss 0.05183942357699076 val loss 0.18734245002269745 Valid accuracy: 95.33333333333333 08:36:13\n","Epoch 958: train loss 0.05948933030168215 val loss 0.7234424352645874 Valid accuracy: 90.0 08:36:46\n","Epoch 959: train loss 0.05935005662341913 val loss 0.381883829832077 Valid accuracy: 94.16666666666667 08:37:19\n","Epoch 960: train loss 0.07048647473255794 val loss 0.46908026933670044 Valid accuracy: 91.66666666666667 08:37:52\n","Epoch 961: train loss 0.1306550653030475 val loss 0.4056592881679535 Valid accuracy: 90.33333333333333 08:38:25\n","Epoch 962: train loss 0.07911577194929123 val loss 0.45835256576538086 Valid accuracy: 92.33333333333333 08:38:58\n","Epoch 963: train loss 0.08450825790564219 val loss 0.42805716395378113 Valid accuracy: 89.83333333333333 08:39:31\n","Epoch 964: train loss 0.06513992697000504 val loss 0.7335464954376221 Valid accuracy: 94.0 08:40:04\n","Epoch 965: train loss 0.06263330606122812 val loss 0.648284375667572 Valid accuracy: 93.83333333333333 08:40:37\n","Epoch 966: train loss 0.10850916209320227 val loss 0.6055553555488586 Valid accuracy: 91.0 08:41:10\n","Epoch 967: train loss 0.080810521915555 val loss 0.6288987398147583 Valid accuracy: 91.33333333333333 08:41:44\n","Epoch 968: train loss 0.059389183620611824 val loss 0.3795453608036041 Valid accuracy: 94.66666666666667 08:42:16\n","Epoch 969: train loss 0.12143144416312376 val loss 0.32563477754592896 Valid accuracy: 92.33333333333333 08:42:49\n","Epoch 970: train loss 0.06543298304080963 val loss 0.42172330617904663 Valid accuracy: 93.33333333333333 08:43:22\n","Epoch 971: train loss 0.07394703788061936 val loss 0.31140077114105225 Valid accuracy: 94.0 08:43:55\n","Epoch 972: train loss 0.18015874460339545 val loss 0.673056960105896 Valid accuracy: 93.83333333333333 08:44:28\n","Epoch 973: train loss 0.10505411148071289 val loss 0.5093393325805664 Valid accuracy: 94.83333333333333 08:45:02\n","Epoch 974: train loss 0.06969739702840647 val loss 0.24935686588287354 Valid accuracy: 92.83333333333333 08:45:34\n","Epoch 975: train loss 0.05449643914898237 val loss 0.45641177892684937 Valid accuracy: 95.16666666666667 08:46:08\n","Epoch 976: train loss 0.05791496805846691 val loss 0.4180019199848175 Valid accuracy: 94.0 08:46:41\n","Epoch 977: train loss 0.052846454953153925 val loss 0.49602580070495605 Valid accuracy: 95.33333333333333 08:47:14\n","Epoch 978: train loss 0.08166317445536454 val loss 0.5410597920417786 Valid accuracy: 93.66666666666667 08:47:47\n","Epoch 979: train loss 0.0683826860288779 val loss 0.46258437633514404 Valid accuracy: 93.66666666666667 08:48:20\n","Epoch 980: train loss 0.08143342785537243 val loss 0.8387560248374939 Valid accuracy: 93.5 08:48:53\n","Epoch 981: train loss 0.07222391632695993 val loss 0.35010644793510437 Valid accuracy: 94.16666666666667 08:49:26\n","Epoch 982: train loss 0.0582227306564649 val loss 0.21627554297447205 Valid accuracy: 93.0 08:49:59\n","Epoch 983: train loss 0.04749976947903633 val loss 0.0848584920167923 Valid accuracy: 90.16666666666667 08:50:31\n","Epoch 984: train loss 0.06967638589441777 val loss 0.4866156578063965 Valid accuracy: 91.66666666666667 08:51:03\n","Epoch 985: train loss 0.09440236744781336 val loss 0.7152930498123169 Valid accuracy: 92.5 08:51:36\n","Epoch 986: train loss 0.06568661563098431 val loss 0.5289170742034912 Valid accuracy: 92.5 08:52:09\n","Epoch 987: train loss 0.0582333837946256 val loss 0.3739633560180664 Valid accuracy: 92.16666666666667 08:52:42\n","Epoch 988: train loss 0.05645477781693141 val loss 0.650470495223999 Valid accuracy: 93.33333333333333 08:53:14\n","Epoch 989: train loss 0.05184455568591754 val loss 0.3362292945384979 Valid accuracy: 93.83333333333333 08:53:47\n","Epoch 990: train loss 0.04427839651703835 val loss 0.3803555965423584 Valid accuracy: 94.16666666666667 08:54:19\n","Epoch 991: train loss 0.045990210225184756 val loss 0.31064435839653015 Valid accuracy: 93.66666666666667 08:54:51\n","Epoch 992: train loss 0.06523091649015744 val loss 0.6110599637031555 Valid accuracy: 94.33333333333333 08:55:24\n","Epoch 993: train loss 0.11610917434096336 val loss 0.31145134568214417 Valid accuracy: 90.83333333333333 08:55:56\n","Epoch 994: train loss 0.09165435756246249 val loss 0.26594436168670654 Valid accuracy: 93.33333333333333 08:56:29\n","Epoch 995: train loss 0.05410212861994902 val loss 0.7032431364059448 Valid accuracy: 93.0 08:57:01\n","Epoch 996: train loss 0.062229609712958336 val loss 0.23869630694389343 Valid accuracy: 92.33333333333333 08:57:34\n","Epoch 997: train loss 0.06752044394612312 val loss 0.20864401757717133 Valid accuracy: 90.83333333333333 08:58:06\n","Epoch 998: train loss 0.05307629704475403 val loss 0.393760085105896 Valid accuracy: 92.33333333333333 08:58:39\n","Epoch 999: train loss 0.07740623543659846 val loss 0.5208548903465271 Valid accuracy: 90.83333333333333 08:59:11\n","Epoch 1000: train loss 0.08639304089049499 val loss 0.3269414007663727 Valid accuracy: 92.0 08:59:44\n","Epoch 1001: train loss 0.08177964992821217 val loss 0.3057020902633667 Valid accuracy: 87.5 09:00:16\n","Epoch 1002: train loss 0.07827090655763944 val loss 0.7585610747337341 Valid accuracy: 90.66666666666667 09:00:49\n","Epoch 1003: train loss 0.07567982065180938 val loss 0.62281334400177 Valid accuracy: 91.5 09:01:22\n","Epoch 1004: train loss 0.085816301604112 val loss 0.4620456099510193 Valid accuracy: 90.0 09:01:54\n","Epoch 1005: train loss 0.05626312516629696 val loss 0.5488268733024597 Valid accuracy: 92.83333333333333 09:02:26\n","Epoch 1006: train loss 0.047248346731066704 val loss 0.3960014283657074 Valid accuracy: 93.83333333333333 09:02:59\n","Epoch 1007: train loss 0.05447281986474991 val loss 0.32803234457969666 Valid accuracy: 89.66666666666667 09:03:32\n","Epoch 1008: train loss 0.035347996403773625 val loss 0.3698287308216095 Valid accuracy: 94.16666666666667 09:04:04\n","Epoch 1009: train loss 0.05588339887559414 val loss 0.24763645231723785 Valid accuracy: 92.5 09:04:37\n","Epoch 1010: train loss 0.06956858664751053 val loss 0.27832821011543274 Valid accuracy: 93.0 09:05:09\n","Epoch 1011: train loss 0.08144821929434935 val loss 0.5732729434967041 Valid accuracy: 92.33333333333333 09:05:42\n","Epoch 1012: train loss 0.08384398649136225 val loss 0.5472758412361145 Valid accuracy: 92.0 09:06:14\n","Epoch 1013: train loss 0.07880188601712386 val loss 0.3535982370376587 Valid accuracy: 89.66666666666667 09:06:47\n","Epoch 1014: train loss 0.06427094938854376 val loss 0.27161502838134766 Valid accuracy: 88.83333333333333 09:07:19\n","Epoch 1015: train loss 0.08054411873221397 val loss 0.5338497161865234 Valid accuracy: 89.83333333333333 09:07:52\n","Epoch 1016: train loss 0.05196532609562079 val loss 0.23123639822006226 Valid accuracy: 91.83333333333333 09:08:25\n","Epoch 1017: train loss 0.048966144745548563 val loss 0.36368322372436523 Valid accuracy: 92.5 09:08:57\n","Epoch 1018: train loss 0.07358177562554677 val loss 0.36988210678100586 Valid accuracy: 91.5 09:09:30\n","Epoch 1019: train loss 0.05580912361542384 val loss 0.36087900400161743 Valid accuracy: 91.5 09:10:02\n","Epoch 1020: train loss 0.06774219989776611 val loss 0.2852262258529663 Valid accuracy: 90.83333333333333 09:10:35\n","Epoch 1021: train loss 0.08909583451847235 val loss 0.3213357627391815 Valid accuracy: 89.66666666666667 09:11:07\n","Epoch 1022: train loss 0.07305321708321572 val loss 0.607912540435791 Valid accuracy: 90.5 09:11:40\n","Epoch 1023: train loss 0.06822341154019038 val loss 0.5630196928977966 Valid accuracy: 95.16666666666667 09:12:12\n","Epoch 1024: train loss 0.08238131865859032 val loss 0.926490068435669 Valid accuracy: 92.5 09:12:45\n","Epoch 1025: train loss 0.0770190717279911 val loss 0.24739910662174225 Valid accuracy: 91.33333333333333 09:13:17\n","Epoch 1026: train loss 0.060967366248369216 val loss 0.45106321573257446 Valid accuracy: 94.16666666666667 09:13:50\n","Epoch 1027: train loss 0.0639553906271855 val loss 0.47145697474479675 Valid accuracy: 92.5 09:14:22\n","Epoch 1028: train loss 0.05243448386589686 val loss 0.2994459271430969 Valid accuracy: 92.83333333333333 09:14:54\n","Epoch 1029: train loss 0.059590285594264665 val loss 0.7112308740615845 Valid accuracy: 92.5 09:15:27\n","Epoch 1030: train loss 0.042223542481660846 val loss 0.42825499176979065 Valid accuracy: 93.5 09:15:59\n","Epoch 1031: train loss 0.052229507714509966 val loss 0.5248215794563293 Valid accuracy: 93.33333333333333 09:16:31\n","Epoch 1032: train loss 0.09180322818458081 val loss 0.3211265802383423 Valid accuracy: 93.0 09:17:03\n","Epoch 1033: train loss 0.06762845233082772 val loss 0.6266480088233948 Valid accuracy: 86.5 09:17:35\n","Epoch 1034: train loss 0.09795116563638051 val loss 1.2445582151412964 Valid accuracy: 90.0 09:18:07\n","Epoch 1035: train loss 0.09317467326919238 val loss 0.2148764729499817 Valid accuracy: 90.66666666666667 09:18:39\n","Epoch 1036: train loss 0.07201491785546144 val loss 0.20229415595531464 Valid accuracy: 92.66666666666667 09:19:12\n","Epoch 1037: train loss 0.04627039015293121 val loss 0.4567062556743622 Valid accuracy: 94.83333333333333 09:19:44\n","Epoch 1038: train loss 0.0636088632295529 val loss 0.2120785117149353 Valid accuracy: 93.0 09:20:16\n","Epoch 1039: train loss 0.060492802783846854 val loss 0.5471054315567017 Valid accuracy: 91.0 09:20:49\n","Epoch 1040: train loss 0.047395123566190404 val loss 0.4233175814151764 Valid accuracy: 93.66666666666667 09:21:21\n","Epoch 1041: train loss 0.08238734213014444 val loss 0.3376493453979492 Valid accuracy: 90.0 09:21:53\n","Epoch 1042: train loss 0.07715413766602675 val loss 0.2567979693412781 Valid accuracy: 93.16666666666667 09:22:25\n","Epoch 1043: train loss 0.06036955955127875 val loss 0.15567606687545776 Valid accuracy: 93.83333333333333 09:22:57\n","Epoch 1044: train loss 0.06832950229446093 val loss 0.47344517707824707 Valid accuracy: 91.83333333333333 09:23:29\n","Epoch 1045: train loss 0.049726440509160356 val loss 0.23083877563476562 Valid accuracy: 93.0 09:24:01\n","Epoch 1046: train loss 0.02978517363468806 val loss 0.17961657047271729 Valid accuracy: 93.16666666666667 09:24:33\n","Epoch 1047: train loss 0.050865825563669205 val loss 0.4459644854068756 Valid accuracy: 91.83333333333333 09:25:05\n","Epoch 1048: train loss 0.07821171122292678 val loss 0.2042662501335144 Valid accuracy: 93.33333333333333 09:25:37\n","Epoch 1049: train loss 0.06191623012224833 val loss 0.6303489804267883 Valid accuracy: 94.0 09:26:09\n","Epoch 1050: train loss 0.058706806773940724 val loss 0.5221162438392639 Valid accuracy: 93.66666666666667 09:26:42\n","Epoch 1051: train loss 0.056026761184136076 val loss 0.21431267261505127 Valid accuracy: 94.33333333333333 09:27:14\n","Epoch 1052: train loss 0.07101227963964145 val loss 0.2894441485404968 Valid accuracy: 94.0 09:27:46\n","Epoch 1053: train loss 0.07159241477648418 val loss 0.3867322504520416 Valid accuracy: 91.66666666666667 09:28:18\n","Epoch 1054: train loss 0.061306276122728987 val loss 0.297913521528244 Valid accuracy: 96.16666666666667 09:28:50\n","Epoch 1055: train loss 0.06797922412554423 val loss 0.2757108509540558 Valid accuracy: 92.5 09:29:22\n","Epoch 1056: train loss 0.06657966566582521 val loss 0.3466416895389557 Valid accuracy: 94.0 09:29:55\n","Epoch 1057: train loss 0.06935107082128525 val loss 0.6593892574310303 Valid accuracy: 92.16666666666667 09:30:27\n","Epoch 1058: train loss 0.0950156840433677 val loss 0.756126344203949 Valid accuracy: 92.5 09:30:59\n","Epoch 1059: train loss 0.06088392831385136 val loss 0.6728529334068298 Valid accuracy: 93.16666666666667 09:31:31\n","Epoch 1060: train loss 0.10447844682882229 val loss 0.16733816266059875 Valid accuracy: 88.0 09:32:03\n","Epoch 1061: train loss 0.11107976963122686 val loss 0.1910526156425476 Valid accuracy: 90.16666666666667 09:32:35\n","Epoch 1062: train loss 0.08147868933777014 val loss 0.41497698426246643 Valid accuracy: 90.0 09:33:07\n","Epoch 1063: train loss 0.05420597506066163 val loss 0.8881805539131165 Valid accuracy: 92.83333333333333 09:33:39\n","Epoch 1064: train loss 0.06571782015264034 val loss 0.7417198419570923 Valid accuracy: 91.5 09:34:11\n","Epoch 1065: train loss 0.06276277715961139 val loss 0.31030166149139404 Valid accuracy: 89.33333333333333 09:34:43\n","Epoch 1066: train loss 0.0577809822311004 val loss 0.9364669322967529 Valid accuracy: 94.16666666666667 09:35:16\n","Epoch 1067: train loss 0.056292197071015834 val loss 0.570637583732605 Valid accuracy: 93.83333333333333 09:35:48\n","Epoch 1068: train loss 0.06668265389899412 val loss 0.6744523048400879 Valid accuracy: 90.66666666666667 09:36:20\n","Epoch 1069: train loss 0.06682519403596719 val loss 0.2336503565311432 Valid accuracy: 92.16666666666667 09:36:52\n","Epoch 1070: train loss 0.06484196849167347 val loss 0.5105864405632019 Valid accuracy: 91.16666666666667 09:37:24\n","Epoch 1071: train loss 0.051167049407958985 val loss 0.2844031751155853 Valid accuracy: 92.5 09:37:56\n","Epoch 1072: train loss 0.07253406018018722 val loss 0.1675313413143158 Valid accuracy: 92.5 09:38:29\n","Epoch 1073: train loss 0.08179478404422601 val loss 0.5144878625869751 Valid accuracy: 93.16666666666667 09:39:01\n","Epoch 1074: train loss 0.0551951934893926 val loss 0.42420655488967896 Valid accuracy: 92.83333333333333 09:39:33\n","Epoch 1075: train loss 0.06183838819464048 val loss 0.37439829111099243 Valid accuracy: 92.16666666666667 09:40:05\n","Epoch 1076: train loss 0.06847197614610195 val loss 0.5391867756843567 Valid accuracy: 91.5 09:40:37\n","Epoch 1077: train loss 0.06249610841274261 val loss 0.394674688577652 Valid accuracy: 90.16666666666667 09:41:10\n","Epoch 1078: train loss 0.060839552457133926 val loss 0.5991506576538086 Valid accuracy: 91.66666666666667 09:41:42\n","Epoch 1079: train loss 0.08477670711775621 val loss 0.26125913858413696 Valid accuracy: 93.16666666666667 09:42:14\n","Epoch 1080: train loss 0.07152141958475113 val loss 0.17111828923225403 Valid accuracy: 93.0 09:42:46\n","Epoch 1081: train loss 0.052562272995710375 val loss 0.5383732318878174 Valid accuracy: 91.66666666666667 09:43:18\n","Epoch 1082: train loss 0.048076504493753114 val loss 0.5837354063987732 Valid accuracy: 94.5 09:43:50\n","Epoch 1083: train loss 0.05034957100947698 val loss 0.3166709244251251 Valid accuracy: 90.66666666666667 09:44:22\n","Epoch 1084: train loss 0.05475448744992415 val loss 0.26623836159706116 Valid accuracy: 94.33333333333333 09:44:54\n","Epoch 1085: train loss 0.04706333155433337 val loss 0.29295411705970764 Valid accuracy: 94.16666666666667 09:45:26\n","Epoch 1086: train loss 0.05639724854379893 val loss 0.6448408365249634 Valid accuracy: 91.83333333333333 09:45:58\n","Epoch 1087: train loss 0.08570536884168783 val loss 0.6042017340660095 Valid accuracy: 89.66666666666667 09:46:31\n","Epoch 1088: train loss 0.08476492270827293 val loss 0.16491569578647614 Valid accuracy: 93.0 09:47:02\n","Epoch 1089: train loss 0.047511951103806495 val loss 0.4130312204360962 Valid accuracy: 94.5 09:47:35\n","Epoch 1090: train loss 0.0519060047964255 val loss 0.5878693461418152 Valid accuracy: 90.33333333333333 09:48:06\n","Epoch 1091: train loss 0.040924829915165904 val loss 0.386865496635437 Valid accuracy: 93.66666666666667 09:48:39\n","Epoch 1092: train loss 0.04680117746194204 val loss 0.25783735513687134 Valid accuracy: 94.33333333333333 09:49:10\n","Epoch 1093: train loss 0.04044217812518279 val loss 0.399996817111969 Valid accuracy: 94.83333333333333 09:49:43\n","Epoch 1094: train loss 0.03745865873992443 val loss 0.2199384868144989 Valid accuracy: 93.5 09:50:14\n","Epoch 1095: train loss 0.04559322199473778 val loss 0.5329835414886475 Valid accuracy: 92.83333333333333 09:50:47\n","Epoch 1096: train loss 0.059740291411678 val loss 0.25396034121513367 Valid accuracy: 93.33333333333333 09:51:19\n","Epoch 1097: train loss 0.0490687341739734 val loss 0.3561784029006958 Valid accuracy: 93.33333333333333 09:51:51\n","Epoch 1098: train loss 0.07075834430754185 val loss 0.47707024216651917 Valid accuracy: 88.66666666666667 09:52:23\n","Epoch 1099: train loss 0.0758407540867726 val loss 0.4217798113822937 Valid accuracy: 93.16666666666667 09:52:55\n","Epoch 1100: train loss 0.0660506551961104 val loss 0.08687884360551834 Valid accuracy: 93.5 09:53:27\n","Epoch 1101: train loss 0.07452850952744484 val loss 0.3640419542789459 Valid accuracy: 92.66666666666667 09:53:59\n","Epoch 1102: train loss 0.07977418904503186 val loss 0.5042480826377869 Valid accuracy: 92.5 09:54:32\n","Epoch 1103: train loss 0.06881812411050002 val loss 0.3440973162651062 Valid accuracy: 92.16666666666667 09:55:04\n","Epoch 1104: train loss 0.05585615113377571 val loss 0.4732973575592041 Valid accuracy: 92.16666666666667 09:55:36\n","Epoch 1105: train loss 0.05984885461628437 val loss 0.4230394959449768 Valid accuracy: 93.5 09:56:08\n","Epoch 1106: train loss 0.050790315320094426 val loss 0.3715592622756958 Valid accuracy: 93.83333333333333 09:56:41\n","Epoch 1107: train loss 0.0458309463908275 val loss 0.42219969630241394 Valid accuracy: 94.0 09:57:13\n","Epoch 1108: train loss 0.05302194767942031 val loss 0.2936933934688568 Valid accuracy: 94.5 09:57:45\n","Epoch 1109: train loss 0.0609650448958079 val loss 0.5265794992446899 Valid accuracy: 93.0 09:58:17\n","Epoch 1110: train loss 0.06796674196918806 val loss 0.3047632873058319 Valid accuracy: 93.33333333333333 09:58:50\n","Epoch 1111: train loss 0.07056271801392237 val loss 0.3861984610557556 Valid accuracy: 90.66666666666667 09:59:22\n","Epoch 1112: train loss 0.06606553889811038 val loss 0.4871191084384918 Valid accuracy: 92.66666666666667 09:59:54\n","Epoch 1113: train loss 0.0576114463309447 val loss 0.34462970495224 Valid accuracy: 95.16666666666667 10:00:26\n","Epoch 1114: train loss 0.05704707962771257 val loss 0.24486033618450165 Valid accuracy: 93.33333333333333 10:00:58\n","Epoch 1115: train loss 0.054610167120893796 val loss 0.1821533441543579 Valid accuracy: 91.5 10:01:30\n","Epoch 1116: train loss 0.09534334701796372 val loss 0.3291965425014496 Valid accuracy: 91.5 10:02:03\n","Epoch 1117: train loss 0.06199272409081459 val loss 0.2962631285190582 Valid accuracy: 90.33333333333333 10:02:35\n","Epoch 1118: train loss 0.0733745011438926 val loss 0.46322646737098694 Valid accuracy: 91.66666666666667 10:03:07\n","Epoch 1119: train loss 0.056601426030198736 val loss 0.3326844274997711 Valid accuracy: 94.33333333333333 10:03:39\n","Epoch 1120: train loss 0.08752092535297076 val loss 0.4238645136356354 Valid accuracy: 92.5 10:04:11\n","Epoch 1121: train loss 0.06830255389213562 val loss 0.38314494490623474 Valid accuracy: 92.16666666666667 10:04:43\n","Epoch 1122: train loss 0.03405620789776246 val loss 0.30899468064308167 Valid accuracy: 96.33333333333333 10:05:15\n","Epoch 1123: train loss 0.053907835458715754 val loss 0.2628367245197296 Valid accuracy: 95.0 10:05:47\n","Epoch 1124: train loss 0.03584823356320461 val loss 0.7430781126022339 Valid accuracy: 95.5 10:06:19\n","Epoch 1125: train loss 0.04511625119795402 val loss 0.542176365852356 Valid accuracy: 93.16666666666667 10:06:51\n","Epoch 1126: train loss 0.06888445563614369 val loss 0.4867174029350281 Valid accuracy: 93.5 10:07:23\n","Epoch 1127: train loss 0.04084308562179406 val loss 0.298913836479187 Valid accuracy: 94.66666666666667 10:07:55\n","Epoch 1128: train loss 0.04266629648705324 val loss 0.26215940713882446 Valid accuracy: 93.83333333333333 10:08:28\n","Epoch 1129: train loss 0.08488037552684545 val loss 0.4607844054698944 Valid accuracy: 91.66666666666667 10:08:59\n","Epoch 1130: train loss 0.12326453015208244 val loss 0.4064258635044098 Valid accuracy: 90.5 10:09:31\n","Epoch 1131: train loss 0.048662063777446744 val loss 0.2093515396118164 Valid accuracy: 94.83333333333333 10:10:03\n","Epoch 1132: train loss 0.05908923091987769 val loss 0.29490095376968384 Valid accuracy: 94.16666666666667 10:10:36\n","Epoch 1133: train loss 0.06279251193006834 val loss 0.2742370367050171 Valid accuracy: 93.0 10:11:08\n","Epoch 1134: train loss 0.053642624119917555 val loss 0.5193551182746887 Valid accuracy: 93.83333333333333 10:11:40\n","Epoch 1135: train loss 0.05153417489180962 val loss 0.5144265294075012 Valid accuracy: 95.33333333333333 10:12:12\n","Epoch 1136: train loss 0.06667107419421275 val loss 0.3182142674922943 Valid accuracy: 95.16666666666667 10:12:44\n","Epoch 1137: train loss 0.04039831062157949 val loss 0.4243651032447815 Valid accuracy: 94.66666666666667 10:13:17\n","Epoch 1138: train loss 0.05703915717701117 val loss 0.5126960873603821 Valid accuracy: 94.5 10:13:49\n","Epoch 1139: train loss 0.07702139925211668 val loss 0.32043221592903137 Valid accuracy: 95.66666666666667 10:14:21\n","Epoch 1140: train loss 0.05970079990724723 val loss 0.5565597414970398 Valid accuracy: 94.83333333333333 10:14:53\n","Epoch 1141: train loss 0.04276799791802963 val loss 0.16703961789608002 Valid accuracy: 95.33333333333333 10:15:25\n","Epoch 1142: train loss 0.06383856726189455 val loss 0.23239904642105103 Valid accuracy: 92.66666666666667 10:15:58\n","Epoch 1143: train loss 0.07039897188544274 val loss 0.17846959829330444 Valid accuracy: 94.16666666666667 10:16:30\n","Epoch 1144: train loss 0.07491335943341255 val loss 0.4477105736732483 Valid accuracy: 93.5 10:17:02\n","Epoch 1145: train loss 0.09464240546027819 val loss 0.34541505575180054 Valid accuracy: 92.83333333333333 10:17:34\n","Epoch 1146: train loss 0.06380007023612658 val loss 0.4856078028678894 Valid accuracy: 94.66666666666667 10:18:07\n","Epoch 1147: train loss 0.04824560691912969 val loss 0.14619705080986023 Valid accuracy: 95.5 10:18:39\n","Epoch 1148: train loss 0.04215901526312033 val loss 0.41270142793655396 Valid accuracy: 94.33333333333333 10:19:11\n","Epoch 1149: train loss 0.04385131840904554 val loss 0.41614583134651184 Valid accuracy: 95.0 10:19:43\n","Epoch 1150: train loss 0.04387888352076213 val loss 0.26127374172210693 Valid accuracy: 95.16666666666667 10:20:15\n","Epoch 1151: train loss 0.05590135739495357 val loss 0.5376696586608887 Valid accuracy: 95.5 10:20:47\n","Epoch 1152: train loss 0.06840955653538307 val loss 0.4249536991119385 Valid accuracy: 94.5 10:21:19\n","Epoch 1153: train loss 0.0681193903585275 val loss 0.3703157901763916 Valid accuracy: 94.83333333333333 10:21:51\n","Epoch 1154: train loss 0.06652208209037781 val loss 0.3682025969028473 Valid accuracy: 92.83333333333333 10:22:23\n","Epoch 1155: train loss 0.0428414140517513 val loss 0.320668488740921 Valid accuracy: 94.83333333333333 10:22:55\n","Epoch 1156: train loss 0.04986226862917344 val loss 0.35512590408325195 Valid accuracy: 92.33333333333333 10:23:27\n","Epoch 1157: train loss 0.06772324937085311 val loss 0.33045563101768494 Valid accuracy: 94.16666666666667 10:23:59\n","Epoch 1158: train loss 0.06312494265536467 val loss 0.5482608675956726 Valid accuracy: 93.83333333333333 10:24:31\n","Epoch 1159: train loss 0.08450637385249138 val loss 0.4088841378688812 Valid accuracy: 93.16666666666667 10:25:03\n","Epoch 1160: train loss 0.07495442453771829 val loss 0.627458393573761 Valid accuracy: 95.16666666666667 10:25:35\n","Epoch 1161: train loss 0.06257115172843139 val loss 0.37320056557655334 Valid accuracy: 92.16666666666667 10:26:07\n","Epoch 1162: train loss 0.051994512155652046 val loss 0.15286025404930115 Valid accuracy: 93.0 10:26:39\n","Epoch 1163: train loss 0.03944083360334238 val loss 0.4843575656414032 Valid accuracy: 94.83333333333333 10:27:11\n","Epoch 1164: train loss 0.04394145915905635 val loss 0.37531042098999023 Valid accuracy: 95.0 10:27:44\n","Epoch 1165: train loss 0.0480138506864508 val loss 0.4336198568344116 Valid accuracy: 95.66666666666667 10:28:15\n","Epoch 1166: train loss 0.039758236532409987 val loss 0.29612699151039124 Valid accuracy: 96.0 10:28:48\n","Epoch 1167: train loss 0.04256493420650562 val loss 0.2578471899032593 Valid accuracy: 94.0 10:29:20\n","Epoch 1168: train loss 0.07132724878688654 val loss 0.560123860836029 Valid accuracy: 94.16666666666667 10:29:52\n","Epoch 1169: train loss 0.04054737251251936 val loss 0.15665042400360107 Valid accuracy: 93.5 10:30:24\n","Epoch 1170: train loss 0.039452647206683955 val loss 0.13994035124778748 Valid accuracy: 92.16666666666667 10:30:56\n","Epoch 1171: train loss 0.07569599065929651 val loss 0.1550782471895218 Valid accuracy: 93.66666666666667 10:31:29\n","Epoch 1172: train loss 0.055632871985435484 val loss 0.46724820137023926 Valid accuracy: 91.5 10:32:00\n","Epoch 1173: train loss 0.05671014081686735 val loss 0.36817237734794617 Valid accuracy: 94.66666666666667 10:32:32\n","Epoch 1174: train loss 0.07908964211742084 val loss 0.28640037775039673 Valid accuracy: 91.16666666666667 10:33:04\n","Epoch 1175: train loss 0.0378966499119997 val loss 0.32800930738449097 Valid accuracy: 97.0 10:33:36\n","Epoch 1176: train loss 0.05633494441707929 val loss 0.6123586297035217 Valid accuracy: 97.0 10:34:09\n","Epoch 1177: train loss 0.03554171790679296 val loss 0.19293390214443207 Valid accuracy: 92.16666666666667 10:34:41\n","Epoch 1178: train loss 0.038945253863930704 val loss 0.1208464652299881 Valid accuracy: 95.66666666666667 10:35:13\n","Epoch 1179: train loss 0.05340585177143415 val loss 0.28943711519241333 Valid accuracy: 93.33333333333333 10:35:46\n","Epoch 1180: train loss 0.06034079367915789 val loss 0.15134160220623016 Valid accuracy: 96.0 10:36:18\n","Epoch 1181: train loss 0.04858635661502679 val loss 0.259230375289917 Valid accuracy: 94.83333333333333 10:36:50\n","Epoch 1182: train loss 0.05805619622270266 val loss 0.392929345369339 Valid accuracy: 96.0 10:37:22\n","Epoch 1183: train loss 0.06718618060151736 val loss 0.1139858290553093 Valid accuracy: 93.66666666666667 10:37:54\n","Epoch 1184: train loss 0.06397803694009781 val loss 0.5760964155197144 Valid accuracy: 93.83333333333333 10:38:26\n","Epoch 1185: train loss 0.07660750458637873 val loss 0.309677392244339 Valid accuracy: 91.33333333333333 10:38:58\n","Epoch 1186: train loss 0.05850073379774889 val loss 0.4001804292201996 Valid accuracy: 93.0 10:39:30\n","Epoch 1187: train loss 0.08446825961271921 val loss 0.5921537280082703 Valid accuracy: 91.33333333333333 10:40:03\n","Epoch 1188: train loss 0.04740786398450533 val loss 0.5136399269104004 Valid accuracy: 91.83333333333333 10:40:35\n","Epoch 1189: train loss 0.04084757511814435 val loss 0.469739705324173 Valid accuracy: 95.16666666666667 10:41:07\n","Epoch 1190: train loss 0.0729401678716143 val loss 0.28292757272720337 Valid accuracy: 93.83333333333333 10:41:39\n","Epoch 1191: train loss 0.06346739448606968 val loss 0.24603930115699768 Valid accuracy: 93.83333333333333 10:42:11\n","Epoch 1192: train loss 0.07819848118970792 val loss 0.4219955503940582 Valid accuracy: 87.16666666666667 10:42:43\n","Epoch 1193: train loss 0.048132170538107553 val loss 0.5471246242523193 Valid accuracy: 92.83333333333333 10:43:15\n","Epoch 1194: train loss 0.06009852949529886 val loss 0.2991384267807007 Valid accuracy: 95.16666666666667 10:43:48\n","Epoch 1195: train loss 0.049227877706289294 val loss 0.43183669447898865 Valid accuracy: 95.0 10:44:19\n","Epoch 1196: train loss 0.06315049007534981 val loss 0.526210606098175 Valid accuracy: 91.33333333333333 10:44:52\n","Epoch 1197: train loss 0.04509455575297276 val loss 0.7770223021507263 Valid accuracy: 91.83333333333333 10:45:24\n","Epoch 1198: train loss 0.05440544938047727 val loss 0.30239567160606384 Valid accuracy: 93.5 10:45:57\n","Epoch 1199: train loss 0.04917517155408859 val loss 0.41464895009994507 Valid accuracy: 91.66666666666667 10:46:29\n","Epoch 1200: train loss 0.0467562381674846 val loss 0.3195497989654541 Valid accuracy: 92.16666666666667 10:47:01\n","Epoch 1201: train loss 0.036142010738452274 val loss 0.4727177321910858 Valid accuracy: 95.16666666666667 10:47:34\n","Epoch 1202: train loss 0.044992984036604566 val loss 0.05934276431798935 Valid accuracy: 95.83333333333333 10:48:06\n","Epoch 1203: train loss 0.05967554472386837 val loss 0.16392692923545837 Valid accuracy: 94.33333333333333 10:48:39\n","Epoch 1204: train loss 0.06855380857984225 val loss 0.15026134252548218 Valid accuracy: 95.16666666666667 10:49:11\n","Epoch 1205: train loss 0.04969896888981263 val loss 0.2639079988002777 Valid accuracy: 92.83333333333333 10:49:43\n","Epoch 1206: train loss 0.0804404849310716 val loss 0.4922734200954437 Valid accuracy: 93.83333333333333 10:50:15\n","Epoch 1207: train loss 0.045496191071967285 val loss 0.32005277276039124 Valid accuracy: 95.66666666666667 10:50:47\n","Epoch 1208: train loss 0.0656404305746158 val loss 0.12365322560071945 Valid accuracy: 93.83333333333333 10:51:20\n","Epoch 1209: train loss 0.04061048299074173 val loss 0.20488661527633667 Valid accuracy: 91.33333333333333 10:51:52\n","Epoch 1210: train loss 0.07920639718572299 val loss 0.39446303248405457 Valid accuracy: 91.0 10:52:24\n","Epoch 1211: train loss 0.0891064295421044 val loss 0.2124265730381012 Valid accuracy: 91.66666666666667 10:52:56\n","Epoch 1212: train loss 0.06899041522294283 val loss 0.23488736152648926 Valid accuracy: 93.5 10:53:28\n","Epoch 1213: train loss 0.05154970937718948 val loss 0.38701963424682617 Valid accuracy: 93.16666666666667 10:54:00\n","Epoch 1214: train loss 0.07116362447539966 val loss 0.48566752672195435 Valid accuracy: 90.33333333333333 10:54:33\n","Epoch 1215: train loss 0.08229668236027161 val loss 0.6370835900306702 Valid accuracy: 88.0 10:55:05\n","Epoch 1216: train loss 0.06484712433069945 val loss 0.27145352959632874 Valid accuracy: 91.83333333333333 10:55:37\n","Epoch 1217: train loss 0.07720315476258596 val loss 0.6847912073135376 Valid accuracy: 91.33333333333333 10:56:09\n","Epoch 1218: train loss 0.05630847359697024 val loss 0.563228189945221 Valid accuracy: 94.0 10:56:41\n","Epoch 1219: train loss 0.05693262539803982 val loss 0.53081876039505 Valid accuracy: 93.5 10:57:14\n","Epoch 1220: train loss 0.06062517782052358 val loss 0.6088073253631592 Valid accuracy: 91.66666666666667 10:57:46\n","Epoch 1221: train loss 0.04974002413451672 val loss 0.3663625717163086 Valid accuracy: 93.66666666666667 10:58:18\n","Epoch 1222: train loss 0.05181668943415085 val loss 0.6289371252059937 Valid accuracy: 93.33333333333333 10:58:51\n","Epoch 1223: train loss 0.03446945715695619 val loss 0.2393038421869278 Valid accuracy: 94.16666666666667 10:59:23\n","Epoch 1224: train loss 0.050169200636446476 val loss 0.6445170044898987 Valid accuracy: 94.16666666666667 10:59:55\n","Epoch 1225: train loss 0.04715288687497377 val loss 0.24350807070732117 Valid accuracy: 93.66666666666667 11:00:27\n","Epoch 1226: train loss 0.06286959966023763 val loss 0.4415161609649658 Valid accuracy: 93.33333333333333 11:01:00\n","Epoch 1227: train loss 0.06958784949034452 val loss 0.540015697479248 Valid accuracy: 91.83333333333333 11:01:32\n","Epoch 1228: train loss 0.04017853181809187 val loss 0.43476882576942444 Valid accuracy: 94.16666666666667 11:02:04\n","Epoch 1229: train loss 0.06846599740286669 val loss 0.6911720633506775 Valid accuracy: 92.66666666666667 11:02:37\n","Epoch 1230: train loss 0.05109960866471132 val loss 0.39494195580482483 Valid accuracy: 93.33333333333333 11:03:09\n","Epoch 1231: train loss 0.062181756049394604 val loss 0.6930313110351562 Valid accuracy: 95.16666666666667 11:03:41\n","Epoch 1232: train loss 0.042909042661388716 val loss 0.5550116300582886 Valid accuracy: 96.33333333333333 11:04:13\n","Epoch 1233: train loss 0.04733125530183315 val loss 0.7467390894889832 Valid accuracy: 95.33333333333333 11:04:46\n","Epoch 1234: train loss 0.05273844627042611 val loss 0.17322194576263428 Valid accuracy: 95.33333333333333 11:05:18\n","Epoch 1235: train loss 0.06794056502481302 val loss 0.421964555978775 Valid accuracy: 95.16666666666667 11:05:50\n","Epoch 1236: train loss 0.07710006110370159 val loss 0.45610204339027405 Valid accuracy: 91.83333333333333 11:06:22\n","Epoch 1237: train loss 0.08846153315156698 val loss 0.7016414403915405 Valid accuracy: 91.16666666666667 11:06:54\n","Epoch 1238: train loss 0.059155561551451685 val loss 0.7338975071907043 Valid accuracy: 92.83333333333333 11:07:27\n","Epoch 1239: train loss 0.05872212629765272 val loss 0.3822132349014282 Valid accuracy: 94.66666666666667 11:07:58\n","Epoch 1240: train loss 0.0630038047581911 val loss 0.2661772668361664 Valid accuracy: 94.5 11:08:31\n","Epoch 1241: train loss 0.04942401219159365 val loss 0.4769152104854584 Valid accuracy: 95.33333333333333 11:09:03\n","Epoch 1242: train loss 0.07781017822523911 val loss 0.8287054896354675 Valid accuracy: 93.0 11:09:36\n","Epoch 1243: train loss 0.04666063737124205 val loss 0.6235718131065369 Valid accuracy: 95.5 11:10:07\n","Epoch 1244: train loss 0.03279500409960747 val loss 0.46059104800224304 Valid accuracy: 94.0 11:10:40\n","Epoch 1245: train loss 0.08549419196943442 val loss 0.3981214165687561 Valid accuracy: 91.66666666666667 11:11:11\n","Epoch 1246: train loss 0.058047294405599435 val loss 1.081161379814148 Valid accuracy: 91.66666666666667 11:11:44\n","Epoch 1247: train loss 0.04664370217670997 val loss 0.20701859891414642 Valid accuracy: 92.0 11:12:16\n","Epoch 1248: train loss 0.0606133505081137 val loss 0.4440399408340454 Valid accuracy: 93.83333333333333 11:12:48\n","Epoch 1249: train loss 0.0696923249711593 val loss 0.4279455244541168 Valid accuracy: 91.33333333333333 11:13:21\n","Epoch 1250: train loss 0.07064618207514287 val loss 0.2741864025592804 Valid accuracy: 93.5 11:13:53\n","Epoch 1251: train loss 0.052411379888653756 val loss 0.6352326273918152 Valid accuracy: 95.0 11:14:25\n","Epoch 1252: train loss 0.04011064192901055 val loss 0.7535795569419861 Valid accuracy: 95.0 11:14:57\n","Epoch 1253: train loss 0.0459597800920407 val loss 0.39494913816452026 Valid accuracy: 94.16666666666667 11:15:29\n","Epoch 1254: train loss 0.049032084171970684 val loss 0.23707395792007446 Valid accuracy: 91.66666666666667 11:16:01\n","Epoch 1255: train loss 0.03625406105071306 val loss 0.31152620911598206 Valid accuracy: 93.66666666666667 11:16:33\n","Epoch 1256: train loss 0.045219097832838694 val loss 0.2555350363254547 Valid accuracy: 95.16666666666667 11:17:06\n","Epoch 1257: train loss 0.059535066336393355 val loss 0.15032200515270233 Valid accuracy: 94.66666666666667 11:17:38\n","Epoch 1258: train loss 0.046268916179736455 val loss 0.27760156989097595 Valid accuracy: 95.33333333333333 11:18:11\n","Epoch 1259: train loss 0.03622096359729767 val loss 0.4719081521034241 Valid accuracy: 92.16666666666667 11:18:43\n","Epoch 1260: train loss 0.06178528096526861 val loss 0.632591962814331 Valid accuracy: 93.33333333333333 11:19:15\n","Epoch 1261: train loss 0.04045716162770987 val loss 0.31511247158050537 Valid accuracy: 96.0 11:19:47\n","Epoch 1262: train loss 0.04498207325736681 val loss 0.34680402278900146 Valid accuracy: 94.83333333333333 11:20:19\n","Epoch 1263: train loss 0.0512685883914431 val loss 0.5051211714744568 Valid accuracy: 94.33333333333333 11:20:52\n","Epoch 1264: train loss 0.04770567328979572 val loss 0.492641806602478 Valid accuracy: 93.66666666666667 11:21:24\n","Epoch 1265: train loss 0.03724458046257496 val loss 0.4518730044364929 Valid accuracy: 94.5 11:21:56\n","Epoch 1266: train loss 0.04027972956498464 val loss 0.33185186982154846 Valid accuracy: 94.66666666666667 11:22:28\n","Epoch 1267: train loss 0.05812556773424148 val loss 0.23390206694602966 Valid accuracy: 92.83333333333333 11:23:00\n","Epoch 1268: train loss 0.04629511410991351 val loss 0.2513832151889801 Valid accuracy: 95.33333333333333 11:23:32\n","Epoch 1269: train loss 0.049757983932892484 val loss 0.2749314308166504 Valid accuracy: 91.33333333333333 11:24:04\n","Epoch 1270: train loss 0.07860360372811556 val loss 0.37817132472991943 Valid accuracy: 94.33333333333333 11:24:37\n","Epoch 1271: train loss 0.047262397781014445 val loss 0.41736480593681335 Valid accuracy: 95.5 11:25:08\n","Epoch 1272: train loss 0.07808981797347467 val loss 0.18349064886569977 Valid accuracy: 94.83333333333333 11:25:41\n","Epoch 1273: train loss 0.06057003416121006 val loss 0.27075955271720886 Valid accuracy: 95.66666666666667 11:26:13\n","Epoch 1274: train loss 0.05076152378072341 val loss 0.16959309577941895 Valid accuracy: 91.16666666666667 11:26:45\n","Epoch 1275: train loss 0.057825220897793767 val loss 0.37597891688346863 Valid accuracy: 95.0 11:27:17\n","Epoch 1276: train loss 0.04763266832878192 val loss 0.23819600045681 Valid accuracy: 95.66666666666667 11:27:50\n","Epoch 1277: train loss 0.04763893278936545 val loss 0.4603860080242157 Valid accuracy: 95.0 11:28:21\n","Epoch 1278: train loss 0.05530026221026977 val loss 0.468558132648468 Valid accuracy: 93.16666666666667 11:28:53\n","Epoch 1279: train loss 0.05200593676418066 val loss 0.5847647190093994 Valid accuracy: 93.0 11:29:26\n","Epoch 1280: train loss 0.04810221340507269 val loss 0.5659457445144653 Valid accuracy: 95.5 11:29:58\n","Epoch 1281: train loss 0.060163013786077496 val loss 0.5617438554763794 Valid accuracy: 92.83333333333333 11:30:30\n","Epoch 1282: train loss 0.05398603537430366 val loss 0.5494334697723389 Valid accuracy: 95.16666666666667 11:31:02\n","Epoch 1283: train loss 0.036951598214606446 val loss 0.2768080532550812 Valid accuracy: 95.83333333333333 11:31:35\n","Epoch 1284: train loss 0.048879574500024316 val loss 0.4092477560043335 Valid accuracy: 92.0 11:32:07\n","Epoch 1285: train loss 0.03534794863313437 val loss 0.6510440111160278 Valid accuracy: 95.66666666666667 11:32:39\n","Epoch 1286: train loss 0.038620554382602375 val loss 0.3244535028934479 Valid accuracy: 94.83333333333333 11:33:11\n","Epoch 1287: train loss 0.0650557846451799 val loss 0.25974997878074646 Valid accuracy: 92.5 11:33:43\n","Epoch 1288: train loss 0.0348274714872241 val loss 0.3292161524295807 Valid accuracy: 96.0 11:34:16\n","Epoch 1289: train loss 0.04816269483417272 val loss 0.41356968879699707 Valid accuracy: 96.5 11:34:48\n","Epoch 1290: train loss 0.05474134410421053 val loss 0.42295822501182556 Valid accuracy: 94.16666666666667 11:35:20\n","Epoch 1291: train loss 0.050667763352394105 val loss 0.335360050201416 Valid accuracy: 93.83333333333333 11:35:52\n","Epoch 1292: train loss 0.06000089434285959 val loss 0.6159690618515015 Valid accuracy: 92.66666666666667 11:36:24\n","Epoch 1293: train loss 0.04257229920476675 val loss 0.4856734573841095 Valid accuracy: 95.0 11:36:56\n","Epoch 1294: train loss 0.03345479457328717 val loss 0.15806449949741364 Valid accuracy: 93.0 11:37:29\n","Epoch 1295: train loss 0.05973573597768943 val loss 0.15040361881256104 Valid accuracy: 94.33333333333333 11:38:01\n","Epoch 1296: train loss 0.049476538623372715 val loss 0.20834960043430328 Valid accuracy: 95.5 11:38:33\n","Epoch 1297: train loss 0.05182898487895727 val loss 0.4467243552207947 Valid accuracy: 96.66666666666667 11:39:06\n","Epoch 1298: train loss 0.04993849385529756 val loss 0.4175451993942261 Valid accuracy: 96.0 11:39:38\n","Epoch 1299: train loss 0.04757361630598704 val loss 0.28440287709236145 Valid accuracy: 94.66666666666667 11:40:11\n","Epoch 1300: train loss 0.06627486934264501 val loss 0.3218657970428467 Valid accuracy: 94.16666666666667 11:40:43\n","Epoch 1301: train loss 0.08620722475151221 val loss 0.22425495088100433 Valid accuracy: 93.66666666666667 11:41:16\n","Epoch 1302: train loss 0.0735088309024771 val loss 0.2752645015716553 Valid accuracy: 95.16666666666667 11:41:48\n","Epoch 1303: train loss 0.05000299888352553 val loss 0.4616526961326599 Valid accuracy: 91.5 11:42:20\n","Epoch 1304: train loss 0.05632049430161715 val loss 0.42087915539741516 Valid accuracy: 92.66666666666667 11:42:53\n","Epoch 1305: train loss 0.0464122407262524 val loss 0.2806202173233032 Valid accuracy: 92.66666666666667 11:43:25\n","Epoch 1306: train loss 0.03552415183434884 val loss 0.7554303407669067 Valid accuracy: 95.16666666666667 11:43:58\n","Epoch 1307: train loss 0.044753109340866404 val loss 0.3471534848213196 Valid accuracy: 92.66666666666667 11:44:30\n","Epoch 1308: train loss 0.057376858306427796 val loss 0.3121758699417114 Valid accuracy: 93.5 11:45:02\n","Epoch 1309: train loss 0.04117721170186996 val loss 0.39641815423965454 Valid accuracy: 94.16666666666667 11:45:35\n","Epoch 1310: train loss 0.024367567375302313 val loss 0.22814098000526428 Valid accuracy: 95.33333333333333 11:46:08\n","Epoch 1311: train loss 0.045569190457463264 val loss 0.4394574761390686 Valid accuracy: 94.83333333333333 11:46:40\n","Epoch 1312: train loss 0.04532065590222677 val loss 0.4255043864250183 Valid accuracy: 92.83333333333333 11:47:12\n","Epoch 1313: train loss 0.05389258480320374 val loss 0.6454619765281677 Valid accuracy: 95.0 11:47:45\n","Epoch 1314: train loss 0.04865707034866015 val loss 0.3676159977912903 Valid accuracy: 94.0 11:48:16\n","Epoch 1315: train loss 0.040606105861564476 val loss 0.22494608163833618 Valid accuracy: 92.16666666666667 11:48:50\n","Epoch 1316: train loss 0.03543860594431559 val loss 0.47677934169769287 Valid accuracy: 96.66666666666667 11:49:21\n","Epoch 1317: train loss 0.038289184843500454 val loss 0.16447719931602478 Valid accuracy: 95.16666666666667 11:49:54\n","Epoch 1318: train loss 0.053619435938696065 val loss 0.3420752286911011 Valid accuracy: 93.33333333333333 11:50:26\n","Epoch 1319: train loss 0.06149523125340541 val loss 0.18439388275146484 Valid accuracy: 95.5 11:50:58\n","Epoch 1320: train loss 0.059385637069741884 val loss 0.6772274374961853 Valid accuracy: 92.83333333333333 11:51:31\n","Epoch 1321: train loss 0.0630507207289338 val loss 0.3118486702442169 Valid accuracy: 94.83333333333333 11:52:03\n","Epoch 1322: train loss 0.03320737359424432 val loss 0.2675727903842926 Valid accuracy: 93.33333333333333 11:52:35\n","Epoch 1323: train loss 0.05322415181746085 val loss 0.35487520694732666 Valid accuracy: 93.83333333333333 11:53:07\n","Epoch 1324: train loss 0.030478494229416054 val loss 0.33175185322761536 Valid accuracy: 95.5 11:53:40\n","Epoch 1325: train loss 0.03127580121159554 val loss 0.3897198438644409 Valid accuracy: 95.5 11:54:12\n","Epoch 1326: train loss 0.03230056061098973 val loss 0.37819984555244446 Valid accuracy: 94.33333333333333 11:54:44\n","Epoch 1327: train loss 0.0677393868441383 val loss 0.22112736105918884 Valid accuracy: 95.33333333333333 11:55:16\n","Epoch 1328: train loss 0.04015050146728754 val loss 0.30735260248184204 Valid accuracy: 96.16666666666667 11:55:49\n","Epoch 1329: train loss 0.04636044072608153 val loss 0.2962097227573395 Valid accuracy: 94.5 11:56:22\n","Epoch 1330: train loss 0.06374891692151625 val loss 0.6088297367095947 Valid accuracy: 91.66666666666667 11:56:54\n","Epoch 1331: train loss 0.05728139873594046 val loss 0.16525675356388092 Valid accuracy: 93.66666666666667 11:57:27\n","Epoch 1332: train loss 0.05796212530384461 val loss 0.4168674945831299 Valid accuracy: 92.16666666666667 11:57:59\n","Epoch 1333: train loss 0.03710568414380153 val loss 0.5149495005607605 Valid accuracy: 94.16666666666667 11:58:32\n","Epoch 1334: train loss 0.05573381430159013 val loss 0.363494336605072 Valid accuracy: 95.16666666666667 11:59:04\n","Epoch 1335: train loss 0.026698142848908903 val loss 0.5287843942642212 Valid accuracy: 95.16666666666667 11:59:36\n","Epoch 1336: train loss 0.04404191340009372 val loss 0.21286512911319733 Valid accuracy: 96.0 12:00:08\n","Epoch 1337: train loss 0.06229586655894915 val loss 0.4646992087364197 Valid accuracy: 92.5 12:00:41\n","Epoch 1338: train loss 0.06951025592784087 val loss 0.35780924558639526 Valid accuracy: 95.66666666666667 12:01:13\n","Epoch 1339: train loss 0.07268416182448467 val loss 0.055935390293598175 Valid accuracy: 94.66666666666667 12:01:45\n","Epoch 1340: train loss 0.03861603830009699 val loss 0.31057584285736084 Valid accuracy: 94.5 12:02:18\n","Epoch 1341: train loss 0.07952556536843379 val loss 0.5390874743461609 Valid accuracy: 89.83333333333333 12:02:51\n","Epoch 1342: train loss 0.061697399740417797 val loss 0.4772361218929291 Valid accuracy: 92.5 12:03:23\n","Epoch 1343: train loss 0.056490842153628665 val loss 0.8575816750526428 Valid accuracy: 92.16666666666667 12:03:56\n","Epoch 1344: train loss 0.03987104040880998 val loss 0.586543619632721 Valid accuracy: 95.16666666666667 12:04:29\n","Epoch 1345: train loss 0.07885233586033186 val loss 0.7096366286277771 Valid accuracy: 87.66666666666667 12:05:01\n","Epoch 1346: train loss 0.06257600785543521 val loss 0.24118228256702423 Valid accuracy: 94.0 12:05:34\n","Epoch 1347: train loss 0.04154437304784854 val loss 1.147540807723999 Valid accuracy: 94.16666666666667 12:06:06\n","Epoch 1348: train loss 0.055698350432018436 val loss 0.2535090446472168 Valid accuracy: 96.0 12:06:38\n","Epoch 1349: train loss 0.060548343708117805 val loss 0.3494303226470947 Valid accuracy: 93.83333333333333 12:07:12\n","Epoch 1350: train loss 0.04220082266877095 val loss 0.6440528035163879 Valid accuracy: 93.33333333333333 12:07:44\n","Epoch 1351: train loss 0.05872619395454725 val loss 0.6390702128410339 Valid accuracy: 93.0 12:08:17\n","Epoch 1352: train loss 0.03619034132609765 val loss 0.6859439015388489 Valid accuracy: 94.0 12:08:49\n","Epoch 1353: train loss 0.04044283247242371 val loss 0.09675252437591553 Valid accuracy: 96.0 12:09:22\n","Epoch 1354: train loss 0.044198440363009774 val loss 0.42115768790245056 Valid accuracy: 94.16666666666667 12:09:55\n","Epoch 1355: train loss 0.03784412816166878 val loss 0.3429822027683258 Valid accuracy: 93.66666666666667 12:10:27\n","Epoch 1356: train loss 0.06754538673907519 val loss 0.3843991756439209 Valid accuracy: 94.66666666666667 12:10:59\n","Epoch 1357: train loss 0.058645405446489655 val loss 0.27593207359313965 Valid accuracy: 89.83333333333333 12:11:32\n","Epoch 1358: train loss 0.034113707281649114 val loss 0.31926316022872925 Valid accuracy: 95.33333333333333 12:12:04\n","Epoch 1359: train loss 0.0634691197797656 val loss 0.3562220335006714 Valid accuracy: 93.83333333333333 12:12:36\n","Epoch 1360: train loss 0.07878465222815673 val loss 0.12979985773563385 Valid accuracy: 94.5 12:13:09\n","Epoch 1361: train loss 0.07091355916112661 val loss 0.6284958124160767 Valid accuracy: 91.0 12:13:42\n","Epoch 1362: train loss 0.0628716807688276 val loss 0.5105115175247192 Valid accuracy: 90.66666666666667 12:14:14\n","Epoch 1363: train loss 0.059066371495525044 val loss 0.25813576579093933 Valid accuracy: 92.0 12:14:47\n","Epoch 1364: train loss 0.04439056451121966 val loss 0.5278813242912292 Valid accuracy: 94.0 12:15:19\n","Epoch 1365: train loss 0.053807681339482466 val loss 0.46414104104042053 Valid accuracy: 91.83333333333333 12:15:52\n","Epoch 1366: train loss 0.045331232932706675 val loss 0.3259233832359314 Valid accuracy: 95.0 12:16:23\n","Epoch 1367: train loss 0.027565910083552202 val loss 0.35163742303848267 Valid accuracy: 95.33333333333333 12:16:56\n","Epoch 1368: train loss 0.04486381503442923 val loss 0.2893303334712982 Valid accuracy: 93.83333333333333 12:17:28\n","Epoch 1369: train loss 0.03671656563878059 val loss 0.6532401442527771 Valid accuracy: 93.16666666666667 12:18:00\n","Epoch 1370: train loss 0.04788000925133626 val loss 0.45043492317199707 Valid accuracy: 97.33333333333333 12:18:33\n","Epoch 1371: train loss 0.042852266790966195 val loss 0.2210390269756317 Valid accuracy: 95.0 12:19:05\n","Epoch 1372: train loss 0.041061733638246854 val loss 0.21519887447357178 Valid accuracy: 95.5 12:19:38\n","Epoch 1373: train loss 0.04752235180387894 val loss 0.4707617163658142 Valid accuracy: 91.0 12:20:10\n","Epoch 1374: train loss 0.04426634548852841 val loss 0.4508199095726013 Valid accuracy: 94.0 12:20:43\n","Epoch 1375: train loss 0.05921062314261993 val loss 0.39962852001190186 Valid accuracy: 97.33333333333333 12:21:15\n","Epoch 1376: train loss 0.051772994635005794 val loss 0.3444037139415741 Valid accuracy: 97.0 12:21:48\n","Epoch 1377: train loss 0.04862188806136449 val loss 0.37337812781333923 Valid accuracy: 95.66666666666667 12:22:20\n","Epoch 1378: train loss 0.07087186273187399 val loss 0.44552454352378845 Valid accuracy: 95.16666666666667 12:22:53\n","Epoch 1379: train loss 0.056703900918364525 val loss 0.7103204727172852 Valid accuracy: 93.5 12:23:25\n","Epoch 1380: train loss 0.058665893288950124 val loss 0.35880762338638306 Valid accuracy: 91.0 12:23:57\n","Epoch 1381: train loss 0.032024502803881964 val loss 0.3689171373844147 Valid accuracy: 92.5 12:24:30\n","Epoch 1382: train loss 0.04098230733225743 val loss 0.3213195204734802 Valid accuracy: 93.5 12:25:02\n","Epoch 1383: train loss 0.07113269532720248 val loss 0.5967110991477966 Valid accuracy: 92.83333333333333 12:25:35\n","Epoch 1384: train loss 0.036441061943769455 val loss 0.2980459928512573 Valid accuracy: 94.5 12:26:07\n","Epoch 1385: train loss 0.0459860889489452 val loss 0.4984416961669922 Valid accuracy: 95.0 12:26:39\n","Epoch 1386: train loss 0.033684536466995874 val loss 0.24349519610404968 Valid accuracy: 93.0 12:27:11\n","Epoch 1387: train loss 0.04620266565432151 val loss 0.4158007502555847 Valid accuracy: 94.5 12:27:44\n","Epoch 1388: train loss 0.046202387164036435 val loss 0.40619274973869324 Valid accuracy: 91.83333333333333 12:28:16\n","Epoch 1389: train loss 0.041057447555164495 val loss 0.10677985846996307 Valid accuracy: 94.16666666666667 12:28:49\n","Epoch 1390: train loss 0.030741833485662937 val loss 0.351394385099411 Valid accuracy: 96.0 12:29:21\n","Epoch 1391: train loss 0.06934627991169691 val loss 0.4847930371761322 Valid accuracy: 91.33333333333333 12:29:53\n","Epoch 1392: train loss 0.04450261902064085 val loss 0.27966153621673584 Valid accuracy: 95.16666666666667 12:30:25\n","Epoch 1393: train loss 0.04765304149438938 val loss 0.4084945619106293 Valid accuracy: 93.66666666666667 12:30:57\n","Epoch 1394: train loss 0.045013486854732034 val loss 0.5306400656700134 Valid accuracy: 93.0 12:31:29\n","Epoch 1395: train loss 0.026048257475097973 val loss 0.12731783092021942 Valid accuracy: 94.83333333333333 12:32:01\n","Epoch 1396: train loss 0.030327777738372485 val loss 0.3715977668762207 Valid accuracy: 95.66666666666667 12:32:33\n","Epoch 1397: train loss 0.032492098212242124 val loss 0.45321086049079895 Valid accuracy: 96.0 12:33:05\n","Epoch 1398: train loss 0.04569391892602046 val loss 0.34301161766052246 Valid accuracy: 92.83333333333333 12:33:37\n","Epoch 1399: train loss 0.051089844380815826 val loss 0.4440250098705292 Valid accuracy: 96.5 12:34:10\n","Epoch 1400: train loss 0.05738820200165113 val loss 0.31833669543266296 Valid accuracy: 93.66666666666667 12:34:42\n","Epoch 1401: train loss 0.07039178849508365 val loss 0.29057374596595764 Valid accuracy: 93.16666666666667 12:35:14\n","Epoch 1402: train loss 0.053366888016462326 val loss 0.7563318014144897 Valid accuracy: 93.0 12:35:46\n","Epoch 1403: train loss 0.05033138625323772 val loss 0.6717376112937927 Valid accuracy: 93.16666666666667 12:36:18\n","Epoch 1404: train loss 0.06029525698473056 val loss 0.6970296502113342 Valid accuracy: 92.16666666666667 12:36:50\n","Epoch 1405: train loss 0.04373953953385353 val loss 0.5491132736206055 Valid accuracy: 94.83333333333333 12:37:22\n","Epoch 1406: train loss 0.04782889777173598 val loss 0.46095511317253113 Valid accuracy: 96.0 12:37:54\n","Epoch 1407: train loss 0.0778094316025575 val loss 0.27198120951652527 Valid accuracy: 94.83333333333333 12:38:26\n","Epoch 1408: train loss 0.039794509895145894 val loss 0.2054111510515213 Valid accuracy: 96.0 12:38:58\n","Epoch 1409: train loss 0.04492817789316177 val loss 0.4059198498725891 Valid accuracy: 95.5 12:39:30\n","Epoch 1410: train loss 0.045514459100862346 val loss 0.34931886196136475 Valid accuracy: 91.83333333333333 12:40:02\n","Epoch 1411: train loss 0.052208804364005726 val loss 0.37868601083755493 Valid accuracy: 93.83333333333333 12:40:34\n","Epoch 1412: train loss 0.05891370682666699 val loss 0.7169793248176575 Valid accuracy: 94.16666666666667 12:41:06\n","Epoch 1413: train loss 0.04217129179586967 val loss 0.14087095856666565 Valid accuracy: 94.0 12:41:38\n","Epoch 1414: train loss 0.0292481425901254 val loss 0.18965643644332886 Valid accuracy: 94.5 12:42:10\n","Epoch 1415: train loss 0.033473321894804633 val loss 0.3472135663032532 Valid accuracy: 94.16666666666667 12:42:42\n","Epoch 1416: train loss 0.04975753004352252 val loss 0.6258061528205872 Valid accuracy: 93.5 12:43:13\n","Epoch 1417: train loss 0.04775556288659573 val loss 0.23975087702274323 Valid accuracy: 93.83333333333333 12:43:46\n","Epoch 1418: train loss 0.05209198563049237 val loss 0.43262937664985657 Valid accuracy: 91.5 12:44:17\n","Epoch 1419: train loss 0.03438347158332666 val loss 0.3842483162879944 Valid accuracy: 93.33333333333333 12:44:50\n","Epoch 1420: train loss 0.05176231837520997 val loss 0.2903858423233032 Valid accuracy: 93.5 12:45:22\n","Epoch 1421: train loss 0.05977981039633354 val loss 0.5576954483985901 Valid accuracy: 95.33333333333333 12:45:54\n","Epoch 1422: train loss 0.035972374727328615 val loss 0.12703832983970642 Valid accuracy: 90.33333333333333 12:46:26\n","Epoch 1423: train loss 0.05808108502378066 val loss 0.22995221614837646 Valid accuracy: 90.5 12:46:58\n","Epoch 1424: train loss 0.04049728792160749 val loss 0.26089268922805786 Valid accuracy: 93.16666666666667 12:47:30\n","Epoch 1425: train loss 0.06308901354670525 val loss 0.3272269666194916 Valid accuracy: 93.66666666666667 12:48:02\n","Epoch 1426: train loss 0.05787688251584768 val loss 0.25181832909584045 Valid accuracy: 92.33333333333333 12:48:34\n","Epoch 1427: train loss 0.04255136943111817 val loss 0.7218347787857056 Valid accuracy: 94.83333333333333 12:49:05\n","Epoch 1428: train loss 0.040153560029963654 val loss 0.5210814476013184 Valid accuracy: 96.33333333333333 12:49:38\n","Epoch 1429: train loss 0.04360922683030367 val loss 0.7639527320861816 Valid accuracy: 91.33333333333333 12:50:10\n","Epoch 1430: train loss 0.055765812508761885 val loss 0.26535677909851074 Valid accuracy: 96.33333333333333 12:50:42\n","Epoch 1431: train loss 0.03946726327141126 val loss 0.606776237487793 Valid accuracy: 95.83333333333333 12:51:14\n","Epoch 1432: train loss 0.04394762900968393 val loss 0.48347365856170654 Valid accuracy: 95.66666666666667 12:51:46\n","Epoch 1433: train loss 0.0557715559626619 val loss 0.7334948778152466 Valid accuracy: 91.5 12:52:18\n","Epoch 1434: train loss 0.03701840812961261 val loss 0.253267377614975 Valid accuracy: 95.5 12:52:50\n","Epoch 1435: train loss 0.055188446591297784 val loss 0.6334079504013062 Valid accuracy: 92.5 12:53:22\n","Epoch 1436: train loss 0.07738395063827436 val loss 0.2894844114780426 Valid accuracy: 94.66666666666667 12:53:54\n","Epoch 1437: train loss 0.0530590104435881 val loss 0.2231420874595642 Valid accuracy: 92.0 12:54:26\n","Epoch 1438: train loss 0.032596234617133936 val loss 0.5534961819648743 Valid accuracy: 92.5 12:54:59\n","Epoch 1439: train loss 0.02939477576563756 val loss 0.19862748682498932 Valid accuracy: 96.0 12:55:30\n","Epoch 1440: train loss 0.031797107284267746 val loss 0.5048539042472839 Valid accuracy: 95.66666666666667 12:56:03\n","Epoch 1441: train loss 0.07718381495525439 val loss 0.300187349319458 Valid accuracy: 95.0 12:56:35\n","Epoch 1442: train loss 0.07371238867441814 val loss 0.16180074214935303 Valid accuracy: 95.0 12:57:07\n","Epoch 1443: train loss 0.04977463290095329 val loss 0.32331469655036926 Valid accuracy: 96.16666666666667 12:57:39\n","Epoch 1444: train loss 0.03393295682966709 val loss 0.16942831873893738 Valid accuracy: 94.16666666666667 12:58:10\n","Epoch 1445: train loss 0.061106272141138715 val loss 0.7858980298042297 Valid accuracy: 94.66666666666667 12:58:43\n","Epoch 1446: train loss 0.04384272360553344 val loss 0.4263964295387268 Valid accuracy: 92.5 12:59:14\n","Epoch 1447: train loss 0.0391138773659865 val loss 0.30058643221855164 Valid accuracy: 93.5 12:59:47\n","Epoch 1448: train loss 0.06540149603039026 val loss 0.6829302310943604 Valid accuracy: 93.83333333333333 13:00:18\n","Epoch 1449: train loss 0.044734398586054644 val loss 0.6130608320236206 Valid accuracy: 94.0 13:00:51\n","Epoch 1450: train loss 0.04045691024512053 val loss 0.6002077460289001 Valid accuracy: 96.0 13:01:23\n","Epoch 1451: train loss 0.06627473877122005 val loss 0.49209749698638916 Valid accuracy: 91.83333333333333 13:01:55\n","Epoch 1452: train loss 0.05457483027130365 val loss 0.3490786850452423 Valid accuracy: 91.83333333333333 13:02:27\n","Epoch 1453: train loss 0.057356494540969534 val loss 0.16056689620018005 Valid accuracy: 92.33333333333333 13:02:59\n","Epoch 1454: train loss 0.04999567431708177 val loss 0.24677912890911102 Valid accuracy: 96.0 13:03:31\n","Epoch 1455: train loss 0.04526111713300149 val loss 0.19512471556663513 Valid accuracy: 94.66666666666667 13:04:03\n","Epoch 1456: train loss 0.04811523252477248 val loss 0.43518775701522827 Valid accuracy: 95.16666666666667 13:04:35\n","Epoch 1457: train loss 0.0713151995340983 val loss 0.1571938395500183 Valid accuracy: 94.16666666666667 13:05:07\n","Epoch 1458: train loss 0.032718257047235966 val loss 0.19780680537223816 Valid accuracy: 92.16666666666667 13:05:39\n","Epoch 1459: train loss 0.07556368333597978 val loss 0.3257286846637726 Valid accuracy: 94.66666666666667 13:06:11\n","Epoch 1460: train loss 0.051674658643702666 val loss 0.615272581577301 Valid accuracy: 93.83333333333333 13:06:43\n","Epoch 1461: train loss 0.07627963480850061 val loss 0.30603328347206116 Valid accuracy: 92.5 13:07:16\n","Epoch 1462: train loss 0.07530844164391359 val loss 0.45826199650764465 Valid accuracy: 93.66666666666667 13:07:48\n","Epoch 1463: train loss 0.04215113011499246 val loss 0.43818747997283936 Valid accuracy: 92.66666666666667 13:08:20\n","Epoch 1464: train loss 0.032433180660009386 val loss 0.4040919542312622 Valid accuracy: 94.83333333333333 13:08:53\n","Epoch 1465: train loss 0.038477229947845144 val loss 0.43009528517723083 Valid accuracy: 94.33333333333333 13:09:25\n","Epoch 1466: train loss 0.05091461921731631 val loss 0.2493467628955841 Valid accuracy: 92.5 13:09:57\n","Epoch 1467: train loss 0.0552853624522686 val loss 0.30881446599960327 Valid accuracy: 93.33333333333333 13:10:29\n","Epoch 1468: train loss 0.04370689562211434 val loss 0.2642194628715515 Valid accuracy: 96.5 13:11:01\n","Epoch 1469: train loss 0.027603349573910238 val loss 0.31610745191574097 Valid accuracy: 96.66666666666667 13:11:33\n","Epoch 1470: train loss 0.04461710633089145 val loss 0.3054359555244446 Valid accuracy: 95.0 13:12:05\n","Epoch 1471: train loss 0.03811021116872629 val loss 0.20632466673851013 Valid accuracy: 88.0 13:12:37\n","Epoch 1472: train loss 0.05393533110618591 val loss 0.5734066963195801 Valid accuracy: 95.16666666666667 13:13:09\n","Epoch 1473: train loss 0.03293326587726673 val loss 0.34340181946754456 Valid accuracy: 94.33333333333333 13:13:41\n","Epoch 1474: train loss 0.033375134853025276 val loss 0.3410049080848694 Valid accuracy: 96.33333333333333 13:14:13\n","Epoch 1475: train loss 0.03156677026301622 val loss 0.36028000712394714 Valid accuracy: 96.0 13:14:45\n","Epoch 1476: train loss 0.04078246134022872 val loss 0.42545852065086365 Valid accuracy: 95.5 13:15:17\n","Epoch 1477: train loss 0.030610126517713068 val loss 0.5099262595176697 Valid accuracy: 96.5 13:15:49\n","Epoch 1478: train loss 0.06142746866991122 val loss 0.2350732535123825 Valid accuracy: 94.0 13:16:21\n","Epoch 1479: train loss 0.040406099247435726 val loss 0.42698565125465393 Valid accuracy: 93.5 13:16:54\n","Epoch 1480: train loss 0.05294370152056217 val loss 0.195744588971138 Valid accuracy: 95.33333333333333 13:17:25\n","Epoch 1481: train loss 0.07231653355062008 val loss 0.5013911724090576 Valid accuracy: 94.83333333333333 13:17:58\n","Epoch 1482: train loss 0.07853801038116216 val loss 0.5680558085441589 Valid accuracy: 94.16666666666667 13:18:30\n","Epoch 1483: train loss 0.04366963977615038 val loss 0.2979801297187805 Valid accuracy: 95.83333333333333 13:19:01\n","Epoch 1484: train loss 0.04516006854673227 val loss 0.35814449191093445 Valid accuracy: 95.5 13:19:34\n","Epoch 1485: train loss 0.040774966788788634 val loss 0.4179594814777374 Valid accuracy: 96.0 13:20:05\n","Epoch 1486: train loss 0.0459733438367645 val loss 0.5116040706634521 Valid accuracy: 92.16666666666667 13:20:37\n","Epoch 1487: train loss 0.04505212602516016 val loss 0.493468701839447 Valid accuracy: 95.33333333333333 13:21:09\n","Epoch 1488: train loss 0.03614474592109521 val loss 0.2053547203540802 Valid accuracy: 94.83333333333333 13:21:41\n","Epoch 1489: train loss 0.039391661795477075 val loss 0.2851254642009735 Valid accuracy: 96.16666666666667 13:22:13\n","Epoch 1490: train loss 0.032939773090183734 val loss 0.33803096413612366 Valid accuracy: 93.5 13:22:46\n","Epoch 1491: train loss 0.043777999704082804 val loss 0.35537612438201904 Valid accuracy: 94.16666666666667 13:23:18\n","Epoch 1492: train loss 0.036834946274757384 val loss 0.22075335681438446 Valid accuracy: 93.16666666666667 13:23:50\n","Epoch 1493: train loss 0.05375819114347299 val loss 0.320252388715744 Valid accuracy: 90.0 13:24:22\n","Epoch 1494: train loss 0.06206967207292716 val loss 0.25652995705604553 Valid accuracy: 94.0 13:24:54\n","Epoch 1495: train loss 0.06307872382303079 val loss 0.323392391204834 Valid accuracy: 94.33333333333333 13:25:26\n","Epoch 1496: train loss 0.05497728619724512 val loss 0.20726893842220306 Valid accuracy: 94.33333333333333 13:25:58\n","Epoch 1497: train loss 0.04584009516984224 val loss 0.19998136162757874 Valid accuracy: 94.33333333333333 13:26:30\n","Epoch 1498: train loss 0.07800387622167666 val loss 0.13674037158489227 Valid accuracy: 90.66666666666667 13:27:02\n","Epoch 1499: train loss 0.07481873606642088 val loss 0.42596080899238586 Valid accuracy: 93.66666666666667 13:27:35\n","Epoch 1500: train loss 0.06334773005296787 val loss 0.1115744560956955 Valid accuracy: 94.16666666666667 13:28:07\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"4ihkj2Q_mOsm","executionInfo":{"status":"ok","timestamp":1627623682477,"user_tz":-180,"elapsed":10,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"c3b6c08f-d784-4997-d7f9-7784da435066"},"source":["ax = plt.figure().gca()\n","\n","ax.plot(history['train'][2:])\n","ax.plot(history['val'][2:])\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['train', 'test'])\n","plt.title('Loss over training epochs')\n","plt.show();"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"QN3JLlMAXTdE","executionInfo":{"status":"ok","timestamp":1627623683025,"user_tz":-180,"elapsed":553,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"783be2bd-eda0-4cdf-aad0-a395f540d938"},"source":["ax = plt.figure().gca()\n","\n","ax.plot(history['val_acc'][2:])\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy over training epochs')\n","plt.show();"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"D9NDuvP-_MZ3"},"source":["# Оценка качества работы модели:"]},{"cell_type":"code","metadata":{"id":"9tg9uoUxlrg8"},"source":["from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jAC-IH9IRsbI","executionInfo":{"status":"ok","timestamp":1627623683028,"user_tz":-180,"elapsed":25,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"af4a4298-14c9-48b8-f076-a70105ffc692"},"source":["model = PointNet()\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/pointnet.pth'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"UggmfhMVb5Qe"},"source":["Оценка на объектах из категории test:"]},{"cell_type":"code","metadata":{"id":"xYkFchvK-3D-"},"source":["y_test=[]\n","y_pred_test=[]\n","model.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","  for i in PointCloudData(data_dir='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/test', class_dict=class_dict):\n","    xyz, labels = i\n","    y_test.append(labels)\n","    y_pred, _, _, _ = model(torch.tensor(np.expand_dims(xyz.numpy(),0)))\n","    y_pred_test.append(np.argmax(y_pred.numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXUB5-CGZSfV","executionInfo":{"status":"ok","timestamp":1627623978041,"user_tz":-180,"elapsed":48,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"cfc8b82a-9a86-42a3-abfa-98a98b361df1"},"source":["print(classification_report(y_test, y_pred_test, target_names=class_dict.keys()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        cube       0.89      0.93      0.91       100\n","    cylinder       0.97      0.94      0.95       100\n","       plane       0.86      0.95      0.90       100\n","        cone       1.00      0.93      0.96       100\n","   uv_sphere       0.96      1.00      0.98       100\n","       torus       1.00      0.90      0.95       100\n","\n","    accuracy                           0.94       600\n","   macro avg       0.95      0.94      0.94       600\n","weighted avg       0.95      0.94      0.94       600\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbepz1kXjeiX"},"source":["Проверка valid наборt:"]},{"cell_type":"code","metadata":{"id":"aAzV0ynxh0y3"},"source":["y_val=[]\n","y_pred_val=[]\n","model.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","  for i in PointCloudData(data_dir='/content/drive/MyDrive/Colab Notebooks/Test 3dML/Task3/dataset-v2/valid', class_dict=class_dict):\n","    xyz, labels = i\n","    y_val.append(labels)\n","    y_pred, _, _, _ = model(torch.tensor(np.expand_dims(xyz.numpy(),0)))\n","    y_pred_val.append(np.argmax(y_pred.numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBsGdDMiqRZG","executionInfo":{"status":"ok","timestamp":1627624240262,"user_tz":-180,"elapsed":23,"user":{"displayName":"Павел Количко","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizKiPovlCJw_xET_aXAqLlCvb42QmQw8EMS4ry=s64","userId":"13751770969531115784"}},"outputId":"de464005-56e5-42c1-fa07-666ccf29eb7e"},"source":["print(classification_report(y_val, y_pred_val, target_names=class_dict.keys()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        cube       0.85      1.00      0.92        50\n","    cylinder       1.00      0.84      0.91        50\n","       plane       0.89      0.96      0.92        50\n","        cone       0.98      1.00      0.99        50\n","   uv_sphere       1.00      1.00      1.00        50\n","       torus       1.00      0.88      0.94        50\n","\n","    accuracy                           0.95       300\n","   macro avg       0.95      0.95      0.95       300\n","weighted avg       0.95      0.95      0.95       300\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGk-meK5eh0P"},"source":["Точность модели 94% при базовой точности случайного распределения 15% для 6 классов. Модель работает довольно хорошо если добавить в функцию тренеровки вывод наилучшей модели по accuracy то думаю точность будет около 97%. \n","\n","По значениям precision можено сказать что модель часто относит к кубу то что кубом не является. Определение сферы самое точное, я думаю что это связано с количеством и размером граней куб и плоскость полностью состоят из граней и по этой причине определяются хуже, шар и тор в идеальном состоянии граней не имеют и по этому определяются более однозначно, в пользу этой теории так же можно представить среднии случаи конус определяется лучше целиндра.\n","\n","Повысить точность модели, как мне кажется можно улучшив предобработку данных,напремер если семплинг производить не по объему а по поверхностям фигуры то точность должна вырасти, а еще думаю хорошим способом было бы добавлять точки только на ребра(по замкнутым концентрическим линиям на поверхности в случае гладких фигур) в этом случае мы бы получили каркас который, скорее всего определялся бы еще лучше.\n","\n","Дополнительно в ходе эксперементоы было выявлено что модель очень чувствительна к коэффиценту регуляризации(alfa в функции потерь) и к количеству подаваемых в модель точек. При неподходящих гиперпараметрах точность модели не привыщала 50% что лучше базового случая, но не достаточно точно."]}]}